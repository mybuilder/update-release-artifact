{"version":3,"file":"index.js","sources":["../webpack://update-release-artifact/./index.js","../webpack://update-release-artifact/./node_modules/@actions/core/lib/command.js","../webpack://update-release-artifact/./node_modules/@actions/core/lib/core.js","../webpack://update-release-artifact/./node_modules/@actions/core/lib/file-command.js","../webpack://update-release-artifact/./node_modules/@actions/core/lib/utils.js","../webpack://update-release-artifact/./node_modules/@octokit/action/dist-node/index.js","../webpack://update-release-artifact/./node_modules/@octokit/auth-action/dist-node/index.js","../webpack://update-release-artifact/./node_modules/@octokit/auth-token/dist-node/index.js","../webpack://update-release-artifact/./node_modules/@octokit/core/dist-node/index.js","../webpack://update-release-artifact/./node_modules/@octokit/endpoint/dist-node/index.js","../webpack://update-release-artifact/./node_modules/@octokit/graphql/dist-node/index.js","../webpack://update-release-artifact/./node_modules/@octokit/plugin-paginate-rest/dist-node/index.js","../webpack://update-release-artifact/./node_modules/@octokit/plugin-rest-endpoint-methods/dist-node/index.js","../webpack://update-release-artifact/./node_modules/@octokit/request-error/dist-node/index.js","../webpack://update-release-artifact/./node_modules/@octokit/request/dist-node/index.js","../webpack://update-release-artifact/./node_modules/adm-zip/adm-zip.js","../webpack://update-release-artifact/./node_modules/adm-zip/headers/entryHeader.js","../webpack://update-release-artifact/./node_modules/adm-zip/headers/index.js","../webpack://update-release-artifact/./node_modules/adm-zip/headers/mainHeader.js","../webpack://update-release-artifact/./node_modules/adm-zip/methods/deflater.js","../webpack://update-release-artifact/./node_modules/adm-zip/methods/index.js","../webpack://update-release-artifact/./node_modules/adm-zip/methods/inflater.js","../webpack://update-release-artifact/./node_modules/adm-zip/methods/zipcrypto.js","../webpack://update-release-artifact/./node_modules/adm-zip/util/constants.js","../webpack://update-release-artifact/./node_modules/adm-zip/util/errors.js","../webpack://update-release-artifact/./node_modules/adm-zip/util/fattr.js","../webpack://update-release-artifact/./node_modules/adm-zip/util/fileSystem.js","../webpack://update-release-artifact/./node_modules/adm-zip/util/index.js","../webpack://update-release-artifact/./node_modules/adm-zip/util/utils.js","../webpack://update-release-artifact/./node_modules/adm-zip/zipEntry.js","../webpack://update-release-artifact/./node_modules/adm-zip/zipFile.js","../webpack://update-release-artifact/./node_modules/before-after-hook/index.js","../webpack://update-release-artifact/./node_modules/before-after-hook/lib/add.js","../webpack://update-release-artifact/./node_modules/before-after-hook/lib/register.js","../webpack://update-release-artifact/./node_modules/before-after-hook/lib/remove.js","../webpack://update-release-artifact/./node_modules/deprecation/dist-node/index.js","../webpack://update-release-artifact/./node_modules/encoding/lib/encoding.js","../webpack://update-release-artifact/./node_modules/iconv-lite/encodings/dbcs-codec.js","../webpack://update-release-artifact/./node_modules/iconv-lite/encodings/dbcs-data.js","../webpack://update-release-artifact/./node_modules/iconv-lite/encodings/index.js","../webpack://update-release-artifact/./node_modules/iconv-lite/encodings/internal.js","../webpack://update-release-artifact/./node_modules/iconv-lite/encodings/sbcs-codec.js","../webpack://update-release-artifact/./node_modules/iconv-lite/encodings/sbcs-data-generated.js","../webpack://update-release-artifact/./node_modules/iconv-lite/encodings/sbcs-data.js","../webpack://update-release-artifact/./node_modules/iconv-lite/encodings/utf16.js","../webpack://update-release-artifact/./node_modules/iconv-lite/encodings/utf32.js","../webpack://update-release-artifact/./node_modules/iconv-lite/encodings/utf7.js","../webpack://update-release-artifact/./node_modules/iconv-lite/lib/bom-handling.js","../webpack://update-release-artifact/./node_modules/iconv-lite/lib/index.js","../webpack://update-release-artifact/./node_modules/iconv-lite/lib/streams.js","../webpack://update-release-artifact/./node_modules/is-plain-object/dist/is-plain-object.js","../webpack://update-release-artifact/./node_modules/node-fetch/lib/index.js","../webpack://update-release-artifact/./node_modules/once/once.js","../webpack://update-release-artifact/./node_modules/safer-buffer/safer.js","../webpack://update-release-artifact/./node_modules/universal-user-agent/dist-node/index.js","../webpack://update-release-artifact/./node_modules/wrappy/wrappy.js","../webpack://update-release-artifact/./node_modules/@vercel/ncc/dist/ncc/@@notfound.js","../webpack://update-release-artifact/external \"buffer\"","../webpack://update-release-artifact/external \"crypto\"","../webpack://update-release-artifact/external \"fs\"","../webpack://update-release-artifact/external \"http\"","../webpack://update-release-artifact/external \"https\"","../webpack://update-release-artifact/external \"os\"","../webpack://update-release-artifact/external \"path\"","../webpack://update-release-artifact/external \"stream\"","../webpack://update-release-artifact/external \"string_decoder\"","../webpack://update-release-artifact/external \"url\"","../webpack://update-release-artifact/external \"zlib\"","../webpack://update-release-artifact/webpack/bootstrap","../webpack://update-release-artifact/webpack/runtime/compat","../webpack://update-release-artifact/webpack/startup"],"sourcesContent":["const fs = require('fs');\nconst core = require('@actions/core');\nconst { Octokit } = require('@octokit/action');\nconst AdmZip = require('adm-zip');\n\nconst sleep = seconds =>\n  new Promise(r => setTimeout(r, seconds * 1000));\n\nconst findWorkflowRunArtifactId = async (\n  workflow,\n  workflowCommit,\n  artifactName,\n  pollingAttempts = 60\n) => {\n  const octokit = new Octokit();\n  const [owner, repo] = process.env.GITHUB_REPOSITORY.split('/');\n\n  if (pollingAttempts < 1) {\n    throw new Error(\n      'Failed to find workflow run... exceeded attempts'\n    );\n  }\n\n  for await (const runs of octokit.paginate.iterator(\n    octokit.actions.listWorkflowRuns,\n    {\n      owner,\n      repo,\n      workflow_id: workflow,\n      status: 'completed,success',\n    }\n  )) {\n    const run = runs.data.find(r => r.head_sha === workflowCommit);\n    if (run) {\n      const artifacts =\n        await octokit.actions.listWorkflowRunArtifacts({\n          owner,\n          repo,\n          run_id: run.id,\n        });\n      const artifact = artifacts.data.artifacts.find(\n        a => a.name === artifactName\n      );\n      if (artifact) return artifact.id;\n    }\n  }\n\n  await sleep(1);\n\n  console.log('- Failed to find workflow run... retrying');\n\n  return await findWorkflowRunArtifactId(\n    workflow,\n    workflowCommit,\n    artifactName,\n    pollingAttempts - 1\n  );\n};\n\nconst pullWorkflowArtifact = async (artifactId, artifactName) => {\n  const octokit = new Octokit();\n  const [owner, repo] = process.env.GITHUB_REPOSITORY.split('/');\n\n  const zip = await octokit.actions.downloadArtifact({\n    owner,\n    repo,\n    artifact_id: artifactId,\n    archive_format: 'zip',\n  });\n\n  const adm = new AdmZip(Buffer.from(zip.data));\n  adm.extractAllTo('artifact', true);\n\n  return `./artifact/${artifactName}`;\n};\n\nconst updateReleaseArtifact = async (\n  releaseId,\n  artifactName,\n  workflowArtifactLocalPath\n) => {\n  const octokit = new Octokit();\n  const [owner, repo] = process.env.GITHUB_REPOSITORY.split('/');\n\n  const { data } = await octokit.request(\n    'GET /repos/:owner/:repo/releases/:releaseId/assets',\n    {\n      owner,\n      repo,\n      releaseId,\n    }\n  );\n\n  for (const asset of data) {\n    await octokit.request(\n      'DELETE /repos/:owner/:repo/releases/assets/:assetId',\n      {\n        owner,\n        repo,\n        assetId: asset.id,\n      }\n    );\n    console.log(`- Removed ${asset.name} from release`);\n  }\n\n  await octokit.repos.uploadReleaseAsset({\n    owner,\n    repo,\n    release_id: releaseId,\n    name: artifactName,\n    data: fs.readFileSync(workflowArtifactLocalPath),\n  });\n};\n\nasync function run() {\n  try {\n    const workflow = core.getInput('workflow');\n    const workflowCommit = core.getInput('workflow_commit');\n    const artifactName = core.getInput('artifact_name');\n    const releaseId = core.getInput('release_id');\n\n    console.log(\n      `workflow: ${workflow}, workflowCommit: ${workflowCommit}, artifactName: ${artifactName}, releaseId: ${releaseId}`\n    );\n\n    console.log(`Finding workflow run artifact`);\n\n    const workflowArtifactId = await findWorkflowRunArtifactId(\n      workflow,\n      workflowCommit,\n      artifactName\n    );\n\n    console.log(`Pulling workflow run artifact`);\n\n    const workflowArtifactLocalPath = await pullWorkflowArtifact(\n      workflowArtifactId,\n      artifactName\n    );\n\n    console.log(`Updating release artifact`);\n\n    await updateReleaseArtifact(\n      releaseId,\n      artifactName,\n      workflowArtifactLocalPath\n    );\n\n    console.log(`Successfully updated release artifact`);\n  } catch (error) {\n    core.setFailed(error.message);\n  }\n}\n\nrun();\n","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.issue = exports.issueCommand = void 0;\nconst os = __importStar(require(\"os\"));\nconst utils_1 = require(\"./utils\");\n/**\n * Commands\n *\n * Command Format:\n *   ::name key=value,key=value::message\n *\n * Examples:\n *   ::warning::This is the message\n *   ::set-env name=MY_VAR::some value\n */\nfunction issueCommand(command, properties, message) {\n    const cmd = new Command(command, properties, message);\n    process.stdout.write(cmd.toString() + os.EOL);\n}\nexports.issueCommand = issueCommand;\nfunction issue(name, message = '') {\n    issueCommand(name, {}, message);\n}\nexports.issue = issue;\nconst CMD_STRING = '::';\nclass Command {\n    constructor(command, properties, message) {\n        if (!command) {\n            command = 'missing.command';\n        }\n        this.command = command;\n        this.properties = properties;\n        this.message = message;\n    }\n    toString() {\n        let cmdStr = CMD_STRING + this.command;\n        if (this.properties && Object.keys(this.properties).length > 0) {\n            cmdStr += ' ';\n            let first = true;\n            for (const key in this.properties) {\n                if (this.properties.hasOwnProperty(key)) {\n                    const val = this.properties[key];\n                    if (val) {\n                        if (first) {\n                            first = false;\n                        }\n                        else {\n                            cmdStr += ',';\n                        }\n                        cmdStr += `${key}=${escapeProperty(val)}`;\n                    }\n                }\n            }\n        }\n        cmdStr += `${CMD_STRING}${escapeData(this.message)}`;\n        return cmdStr;\n    }\n}\nfunction escapeData(s) {\n    return utils_1.toCommandValue(s)\n        .replace(/%/g, '%25')\n        .replace(/\\r/g, '%0D')\n        .replace(/\\n/g, '%0A');\n}\nfunction escapeProperty(s) {\n    return utils_1.toCommandValue(s)\n        .replace(/%/g, '%25')\n        .replace(/\\r/g, '%0D')\n        .replace(/\\n/g, '%0A')\n        .replace(/:/g, '%3A')\n        .replace(/,/g, '%2C');\n}\n//# sourceMappingURL=command.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getState = exports.saveState = exports.group = exports.endGroup = exports.startGroup = exports.info = exports.warning = exports.error = exports.debug = exports.isDebug = exports.setFailed = exports.setCommandEcho = exports.setOutput = exports.getBooleanInput = exports.getMultilineInput = exports.getInput = exports.addPath = exports.setSecret = exports.exportVariable = exports.ExitCode = void 0;\nconst command_1 = require(\"./command\");\nconst file_command_1 = require(\"./file-command\");\nconst utils_1 = require(\"./utils\");\nconst os = __importStar(require(\"os\"));\nconst path = __importStar(require(\"path\"));\n/**\n * The code to exit an action\n */\nvar ExitCode;\n(function (ExitCode) {\n    /**\n     * A code indicating that the action was successful\n     */\n    ExitCode[ExitCode[\"Success\"] = 0] = \"Success\";\n    /**\n     * A code indicating that the action was a failure\n     */\n    ExitCode[ExitCode[\"Failure\"] = 1] = \"Failure\";\n})(ExitCode = exports.ExitCode || (exports.ExitCode = {}));\n//-----------------------------------------------------------------------\n// Variables\n//-----------------------------------------------------------------------\n/**\n * Sets env variable for this action and future actions in the job\n * @param name the name of the variable to set\n * @param val the value of the variable. Non-string values will be converted to a string via JSON.stringify\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nfunction exportVariable(name, val) {\n    const convertedVal = utils_1.toCommandValue(val);\n    process.env[name] = convertedVal;\n    const filePath = process.env['GITHUB_ENV'] || '';\n    if (filePath) {\n        const delimiter = '_GitHubActionsFileCommandDelimeter_';\n        const commandValue = `${name}<<${delimiter}${os.EOL}${convertedVal}${os.EOL}${delimiter}`;\n        file_command_1.issueCommand('ENV', commandValue);\n    }\n    else {\n        command_1.issueCommand('set-env', { name }, convertedVal);\n    }\n}\nexports.exportVariable = exportVariable;\n/**\n * Registers a secret which will get masked from logs\n * @param secret value of the secret\n */\nfunction setSecret(secret) {\n    command_1.issueCommand('add-mask', {}, secret);\n}\nexports.setSecret = setSecret;\n/**\n * Prepends inputPath to the PATH (for this action and future actions)\n * @param inputPath\n */\nfunction addPath(inputPath) {\n    const filePath = process.env['GITHUB_PATH'] || '';\n    if (filePath) {\n        file_command_1.issueCommand('PATH', inputPath);\n    }\n    else {\n        command_1.issueCommand('add-path', {}, inputPath);\n    }\n    process.env['PATH'] = `${inputPath}${path.delimiter}${process.env['PATH']}`;\n}\nexports.addPath = addPath;\n/**\n * Gets the value of an input.\n * Unless trimWhitespace is set to false in InputOptions, the value is also trimmed.\n * Returns an empty string if the value is not defined.\n *\n * @param     name     name of the input to get\n * @param     options  optional. See InputOptions.\n * @returns   string\n */\nfunction getInput(name, options) {\n    const val = process.env[`INPUT_${name.replace(/ /g, '_').toUpperCase()}`] || '';\n    if (options && options.required && !val) {\n        throw new Error(`Input required and not supplied: ${name}`);\n    }\n    if (options && options.trimWhitespace === false) {\n        return val;\n    }\n    return val.trim();\n}\nexports.getInput = getInput;\n/**\n * Gets the values of an multiline input.  Each value is also trimmed.\n *\n * @param     name     name of the input to get\n * @param     options  optional. See InputOptions.\n * @returns   string[]\n *\n */\nfunction getMultilineInput(name, options) {\n    const inputs = getInput(name, options)\n        .split('\\n')\n        .filter(x => x !== '');\n    return inputs;\n}\nexports.getMultilineInput = getMultilineInput;\n/**\n * Gets the input value of the boolean type in the YAML 1.2 \"core schema\" specification.\n * Support boolean input list: `true | True | TRUE | false | False | FALSE` .\n * The return value is also in boolean type.\n * ref: https://yaml.org/spec/1.2/spec.html#id2804923\n *\n * @param     name     name of the input to get\n * @param     options  optional. See InputOptions.\n * @returns   boolean\n */\nfunction getBooleanInput(name, options) {\n    const trueValue = ['true', 'True', 'TRUE'];\n    const falseValue = ['false', 'False', 'FALSE'];\n    const val = getInput(name, options);\n    if (trueValue.includes(val))\n        return true;\n    if (falseValue.includes(val))\n        return false;\n    throw new TypeError(`Input does not meet YAML 1.2 \"Core Schema\" specification: ${name}\\n` +\n        `Support boolean input list: \\`true | True | TRUE | false | False | FALSE\\``);\n}\nexports.getBooleanInput = getBooleanInput;\n/**\n * Sets the value of an output.\n *\n * @param     name     name of the output to set\n * @param     value    value to store. Non-string values will be converted to a string via JSON.stringify\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nfunction setOutput(name, value) {\n    process.stdout.write(os.EOL);\n    command_1.issueCommand('set-output', { name }, value);\n}\nexports.setOutput = setOutput;\n/**\n * Enables or disables the echoing of commands into stdout for the rest of the step.\n * Echoing is disabled by default if ACTIONS_STEP_DEBUG is not set.\n *\n */\nfunction setCommandEcho(enabled) {\n    command_1.issue('echo', enabled ? 'on' : 'off');\n}\nexports.setCommandEcho = setCommandEcho;\n//-----------------------------------------------------------------------\n// Results\n//-----------------------------------------------------------------------\n/**\n * Sets the action status to failed.\n * When the action exits it will be with an exit code of 1\n * @param message add error issue message\n */\nfunction setFailed(message) {\n    process.exitCode = ExitCode.Failure;\n    error(message);\n}\nexports.setFailed = setFailed;\n//-----------------------------------------------------------------------\n// Logging Commands\n//-----------------------------------------------------------------------\n/**\n * Gets whether Actions Step Debug is on or not\n */\nfunction isDebug() {\n    return process.env['RUNNER_DEBUG'] === '1';\n}\nexports.isDebug = isDebug;\n/**\n * Writes debug message to user log\n * @param message debug message\n */\nfunction debug(message) {\n    command_1.issueCommand('debug', {}, message);\n}\nexports.debug = debug;\n/**\n * Adds an error issue\n * @param message error issue message. Errors will be converted to string via toString()\n */\nfunction error(message) {\n    command_1.issue('error', message instanceof Error ? message.toString() : message);\n}\nexports.error = error;\n/**\n * Adds an warning issue\n * @param message warning issue message. Errors will be converted to string via toString()\n */\nfunction warning(message) {\n    command_1.issue('warning', message instanceof Error ? message.toString() : message);\n}\nexports.warning = warning;\n/**\n * Writes info to log with console.log.\n * @param message info message\n */\nfunction info(message) {\n    process.stdout.write(message + os.EOL);\n}\nexports.info = info;\n/**\n * Begin an output group.\n *\n * Output until the next `groupEnd` will be foldable in this group\n *\n * @param name The name of the output group\n */\nfunction startGroup(name) {\n    command_1.issue('group', name);\n}\nexports.startGroup = startGroup;\n/**\n * End an output group.\n */\nfunction endGroup() {\n    command_1.issue('endgroup');\n}\nexports.endGroup = endGroup;\n/**\n * Wrap an asynchronous function call in a group.\n *\n * Returns the same type as the function itself.\n *\n * @param name The name of the group\n * @param fn The function to wrap in the group\n */\nfunction group(name, fn) {\n    return __awaiter(this, void 0, void 0, function* () {\n        startGroup(name);\n        let result;\n        try {\n            result = yield fn();\n        }\n        finally {\n            endGroup();\n        }\n        return result;\n    });\n}\nexports.group = group;\n//-----------------------------------------------------------------------\n// Wrapper action state\n//-----------------------------------------------------------------------\n/**\n * Saves state for current action, the state can only be retrieved by this action's post job execution.\n *\n * @param     name     name of the state to store\n * @param     value    value to store. Non-string values will be converted to a string via JSON.stringify\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nfunction saveState(name, value) {\n    command_1.issueCommand('save-state', { name }, value);\n}\nexports.saveState = saveState;\n/**\n * Gets the value of an state set by this action's main execution.\n *\n * @param     name     name of the state to get\n * @returns   string\n */\nfunction getState(name) {\n    return process.env[`STATE_${name}`] || '';\n}\nexports.getState = getState;\n//# sourceMappingURL=core.js.map","\"use strict\";\n// For internal use, subject to change.\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.issueCommand = void 0;\n// We use any as a valid input type\n/* eslint-disable @typescript-eslint/no-explicit-any */\nconst fs = __importStar(require(\"fs\"));\nconst os = __importStar(require(\"os\"));\nconst utils_1 = require(\"./utils\");\nfunction issueCommand(command, message) {\n    const filePath = process.env[`GITHUB_${command}`];\n    if (!filePath) {\n        throw new Error(`Unable to find environment variable for file command ${command}`);\n    }\n    if (!fs.existsSync(filePath)) {\n        throw new Error(`Missing file at path: ${filePath}`);\n    }\n    fs.appendFileSync(filePath, `${utils_1.toCommandValue(message)}${os.EOL}`, {\n        encoding: 'utf8'\n    });\n}\nexports.issueCommand = issueCommand;\n//# sourceMappingURL=file-command.js.map","\"use strict\";\n// We use any as a valid input type\n/* eslint-disable @typescript-eslint/no-explicit-any */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.toCommandValue = void 0;\n/**\n * Sanitizes an input into a string so it can be passed into issueCommand safely\n * @param input input to sanitize into a string\n */\nfunction toCommandValue(input) {\n    if (input === null || input === undefined) {\n        return '';\n    }\n    else if (typeof input === 'string' || input instanceof String) {\n        return input;\n    }\n    return JSON.stringify(input);\n}\nexports.toCommandValue = toCommandValue;\n//# sourceMappingURL=utils.js.map","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar core = require('@octokit/core');\nvar authAction = require('@octokit/auth-action');\nvar pluginPaginateRest = require('@octokit/plugin-paginate-rest');\nvar pluginRestEndpointMethods = require('@octokit/plugin-rest-endpoint-methods');\n\nconst VERSION = \"3.10.1\";\n\nconst Octokit = core.Octokit.plugin(pluginPaginateRest.paginateRest, pluginRestEndpointMethods.legacyRestEndpointMethods).defaults({\n  authStrategy: authAction.createActionAuth,\n  baseUrl: getApiBaseUrl(),\n  userAgent: `octokit-action.js/${VERSION}`\n});\n\nfunction getApiBaseUrl() {\n  /* istanbul ignore next */\n  return process.env[\"GITHUB_API_URL\"] || \"https://api.github.com\";\n}\n\nexports.Octokit = Octokit;\n//# sourceMappingURL=index.js.map\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar authToken = require('@octokit/auth-token');\n\nconst createActionAuth = function createActionAuth() {\n  if (!process.env.GITHUB_ACTION) {\n    throw new Error(\"[@octokit/auth-action] `GITHUB_ACTION` environment variable is not set. @octokit/auth-action is meant to be used in GitHub Actions only.\");\n  }\n\n  const definitions = [process.env.GITHUB_TOKEN, process.env.INPUT_GITHUB_TOKEN, process.env.INPUT_TOKEN].filter(Boolean);\n\n  if (definitions.length === 0) {\n    throw new Error(\"[@octokit/auth-action] `GITHUB_TOKEN` variable is not set. It must be set on either `env:` or `with:`. See https://github.com/octokit/auth-action.js#createactionauth\");\n  }\n\n  if (definitions.length > 1) {\n    throw new Error(\"[@octokit/auth-action] The token variable is specified more than once. Use either `with.token`, `with.GITHUB_TOKEN`, or `env.GITHUB_TOKEN`. See https://github.com/octokit/auth-action.js#createactionauth\");\n  }\n\n  const token = definitions.pop();\n  return authToken.createTokenAuth(token);\n};\n\nexports.createActionAuth = createActionAuth;\n//# sourceMappingURL=index.js.map\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nasync function auth(token) {\n  const tokenType = token.split(/\\./).length === 3 ? \"app\" : /^v\\d+\\./.test(token) ? \"installation\" : \"oauth\";\n  return {\n    type: \"token\",\n    token: token,\n    tokenType\n  };\n}\n\n/**\n * Prefix token for usage in the Authorization header\n *\n * @param token OAuth token or JSON Web Token\n */\nfunction withAuthorizationPrefix(token) {\n  if (token.split(/\\./).length === 3) {\n    return `bearer ${token}`;\n  }\n\n  return `token ${token}`;\n}\n\nasync function hook(token, request, route, parameters) {\n  const endpoint = request.endpoint.merge(route, parameters);\n  endpoint.headers.authorization = withAuthorizationPrefix(token);\n  return request(endpoint);\n}\n\nconst createTokenAuth = function createTokenAuth(token) {\n  if (!token) {\n    throw new Error(\"[@octokit/auth-token] No token passed to createTokenAuth\");\n  }\n\n  if (typeof token !== \"string\") {\n    throw new Error(\"[@octokit/auth-token] Token passed to createTokenAuth is not a string\");\n  }\n\n  token = token.replace(/^(token|bearer) +/i, \"\");\n  return Object.assign(auth.bind(null, token), {\n    hook: hook.bind(null, token)\n  });\n};\n\nexports.createTokenAuth = createTokenAuth;\n//# sourceMappingURL=index.js.map\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar universalUserAgent = require('universal-user-agent');\nvar beforeAfterHook = require('before-after-hook');\nvar request = require('@octokit/request');\nvar graphql = require('@octokit/graphql');\nvar authToken = require('@octokit/auth-token');\n\nfunction _objectWithoutPropertiesLoose(source, excluded) {\n  if (source == null) return {};\n  var target = {};\n  var sourceKeys = Object.keys(source);\n  var key, i;\n\n  for (i = 0; i < sourceKeys.length; i++) {\n    key = sourceKeys[i];\n    if (excluded.indexOf(key) >= 0) continue;\n    target[key] = source[key];\n  }\n\n  return target;\n}\n\nfunction _objectWithoutProperties(source, excluded) {\n  if (source == null) return {};\n\n  var target = _objectWithoutPropertiesLoose(source, excluded);\n\n  var key, i;\n\n  if (Object.getOwnPropertySymbols) {\n    var sourceSymbolKeys = Object.getOwnPropertySymbols(source);\n\n    for (i = 0; i < sourceSymbolKeys.length; i++) {\n      key = sourceSymbolKeys[i];\n      if (excluded.indexOf(key) >= 0) continue;\n      if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue;\n      target[key] = source[key];\n    }\n  }\n\n  return target;\n}\n\nconst VERSION = \"3.4.0\";\n\nclass Octokit {\n  constructor(options = {}) {\n    const hook = new beforeAfterHook.Collection();\n    const requestDefaults = {\n      baseUrl: request.request.endpoint.DEFAULTS.baseUrl,\n      headers: {},\n      request: Object.assign({}, options.request, {\n        // @ts-ignore internal usage only, no need to type\n        hook: hook.bind(null, \"request\")\n      }),\n      mediaType: {\n        previews: [],\n        format: \"\"\n      }\n    }; // prepend default user agent with `options.userAgent` if set\n\n    requestDefaults.headers[\"user-agent\"] = [options.userAgent, `octokit-core.js/${VERSION} ${universalUserAgent.getUserAgent()}`].filter(Boolean).join(\" \");\n\n    if (options.baseUrl) {\n      requestDefaults.baseUrl = options.baseUrl;\n    }\n\n    if (options.previews) {\n      requestDefaults.mediaType.previews = options.previews;\n    }\n\n    if (options.timeZone) {\n      requestDefaults.headers[\"time-zone\"] = options.timeZone;\n    }\n\n    this.request = request.request.defaults(requestDefaults);\n    this.graphql = graphql.withCustomRequest(this.request).defaults(requestDefaults);\n    this.log = Object.assign({\n      debug: () => {},\n      info: () => {},\n      warn: console.warn.bind(console),\n      error: console.error.bind(console)\n    }, options.log);\n    this.hook = hook; // (1) If neither `options.authStrategy` nor `options.auth` are set, the `octokit` instance\n    //     is unauthenticated. The `this.auth()` method is a no-op and no request hook is registered.\n    // (2) If only `options.auth` is set, use the default token authentication strategy.\n    // (3) If `options.authStrategy` is set then use it and pass in `options.auth`. Always pass own request as many strategies accept a custom request instance.\n    // TODO: type `options.auth` based on `options.authStrategy`.\n\n    if (!options.authStrategy) {\n      if (!options.auth) {\n        // (1)\n        this.auth = async () => ({\n          type: \"unauthenticated\"\n        });\n      } else {\n        // (2)\n        const auth = authToken.createTokenAuth(options.auth); // @ts-ignore  ¯\\_(ツ)_/¯\n\n        hook.wrap(\"request\", auth.hook);\n        this.auth = auth;\n      }\n    } else {\n      const {\n        authStrategy\n      } = options,\n            otherOptions = _objectWithoutProperties(options, [\"authStrategy\"]);\n\n      const auth = authStrategy(Object.assign({\n        request: this.request,\n        log: this.log,\n        // we pass the current octokit instance as well as its constructor options\n        // to allow for authentication strategies that return a new octokit instance\n        // that shares the same internal state as the current one. The original\n        // requirement for this was the \"event-octokit\" authentication strategy\n        // of https://github.com/probot/octokit-auth-probot.\n        octokit: this,\n        octokitOptions: otherOptions\n      }, options.auth)); // @ts-ignore  ¯\\_(ツ)_/¯\n\n      hook.wrap(\"request\", auth.hook);\n      this.auth = auth;\n    } // apply plugins\n    // https://stackoverflow.com/a/16345172\n\n\n    const classConstructor = this.constructor;\n    classConstructor.plugins.forEach(plugin => {\n      Object.assign(this, plugin(this, options));\n    });\n  }\n\n  static defaults(defaults) {\n    const OctokitWithDefaults = class extends this {\n      constructor(...args) {\n        const options = args[0] || {};\n\n        if (typeof defaults === \"function\") {\n          super(defaults(options));\n          return;\n        }\n\n        super(Object.assign({}, defaults, options, options.userAgent && defaults.userAgent ? {\n          userAgent: `${options.userAgent} ${defaults.userAgent}`\n        } : null));\n      }\n\n    };\n    return OctokitWithDefaults;\n  }\n  /**\n   * Attach a plugin (or many) to your Octokit instance.\n   *\n   * @example\n   * const API = Octokit.plugin(plugin1, plugin2, plugin3, ...)\n   */\n\n\n  static plugin(...newPlugins) {\n    var _a;\n\n    const currentPlugins = this.plugins;\n    const NewOctokit = (_a = class extends this {}, _a.plugins = currentPlugins.concat(newPlugins.filter(plugin => !currentPlugins.includes(plugin))), _a);\n    return NewOctokit;\n  }\n\n}\nOctokit.VERSION = VERSION;\nOctokit.plugins = [];\n\nexports.Octokit = Octokit;\n//# sourceMappingURL=index.js.map\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar isPlainObject = require('is-plain-object');\nvar universalUserAgent = require('universal-user-agent');\n\nfunction lowercaseKeys(object) {\n  if (!object) {\n    return {};\n  }\n\n  return Object.keys(object).reduce((newObj, key) => {\n    newObj[key.toLowerCase()] = object[key];\n    return newObj;\n  }, {});\n}\n\nfunction mergeDeep(defaults, options) {\n  const result = Object.assign({}, defaults);\n  Object.keys(options).forEach(key => {\n    if (isPlainObject.isPlainObject(options[key])) {\n      if (!(key in defaults)) Object.assign(result, {\n        [key]: options[key]\n      });else result[key] = mergeDeep(defaults[key], options[key]);\n    } else {\n      Object.assign(result, {\n        [key]: options[key]\n      });\n    }\n  });\n  return result;\n}\n\nfunction removeUndefinedProperties(obj) {\n  for (const key in obj) {\n    if (obj[key] === undefined) {\n      delete obj[key];\n    }\n  }\n\n  return obj;\n}\n\nfunction merge(defaults, route, options) {\n  if (typeof route === \"string\") {\n    let [method, url] = route.split(\" \");\n    options = Object.assign(url ? {\n      method,\n      url\n    } : {\n      url: method\n    }, options);\n  } else {\n    options = Object.assign({}, route);\n  } // lowercase header names before merging with defaults to avoid duplicates\n\n\n  options.headers = lowercaseKeys(options.headers); // remove properties with undefined values before merging\n\n  removeUndefinedProperties(options);\n  removeUndefinedProperties(options.headers);\n  const mergedOptions = mergeDeep(defaults || {}, options); // mediaType.previews arrays are merged, instead of overwritten\n\n  if (defaults && defaults.mediaType.previews.length) {\n    mergedOptions.mediaType.previews = defaults.mediaType.previews.filter(preview => !mergedOptions.mediaType.previews.includes(preview)).concat(mergedOptions.mediaType.previews);\n  }\n\n  mergedOptions.mediaType.previews = mergedOptions.mediaType.previews.map(preview => preview.replace(/-preview/, \"\"));\n  return mergedOptions;\n}\n\nfunction addQueryParameters(url, parameters) {\n  const separator = /\\?/.test(url) ? \"&\" : \"?\";\n  const names = Object.keys(parameters);\n\n  if (names.length === 0) {\n    return url;\n  }\n\n  return url + separator + names.map(name => {\n    if (name === \"q\") {\n      return \"q=\" + parameters.q.split(\"+\").map(encodeURIComponent).join(\"+\");\n    }\n\n    return `${name}=${encodeURIComponent(parameters[name])}`;\n  }).join(\"&\");\n}\n\nconst urlVariableRegex = /\\{[^}]+\\}/g;\n\nfunction removeNonChars(variableName) {\n  return variableName.replace(/^\\W+|\\W+$/g, \"\").split(/,/);\n}\n\nfunction extractUrlVariableNames(url) {\n  const matches = url.match(urlVariableRegex);\n\n  if (!matches) {\n    return [];\n  }\n\n  return matches.map(removeNonChars).reduce((a, b) => a.concat(b), []);\n}\n\nfunction omit(object, keysToOmit) {\n  return Object.keys(object).filter(option => !keysToOmit.includes(option)).reduce((obj, key) => {\n    obj[key] = object[key];\n    return obj;\n  }, {});\n}\n\n// Based on https://github.com/bramstein/url-template, licensed under BSD\n// TODO: create separate package.\n//\n// Copyright (c) 2012-2014, Bram Stein\n// All rights reserved.\n// Redistribution and use in source and binary forms, with or without\n// modification, are permitted provided that the following conditions\n// are met:\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n// THIS SOFTWARE IS PROVIDED BY THE AUTHOR \"AS IS\" AND ANY EXPRESS OR IMPLIED\n// WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF\n// MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO\n// EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,\n// INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,\n// BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY\n// OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\n// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,\n// EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n/* istanbul ignore file */\nfunction encodeReserved(str) {\n  return str.split(/(%[0-9A-Fa-f]{2})/g).map(function (part) {\n    if (!/%[0-9A-Fa-f]/.test(part)) {\n      part = encodeURI(part).replace(/%5B/g, \"[\").replace(/%5D/g, \"]\");\n    }\n\n    return part;\n  }).join(\"\");\n}\n\nfunction encodeUnreserved(str) {\n  return encodeURIComponent(str).replace(/[!'()*]/g, function (c) {\n    return \"%\" + c.charCodeAt(0).toString(16).toUpperCase();\n  });\n}\n\nfunction encodeValue(operator, value, key) {\n  value = operator === \"+\" || operator === \"#\" ? encodeReserved(value) : encodeUnreserved(value);\n\n  if (key) {\n    return encodeUnreserved(key) + \"=\" + value;\n  } else {\n    return value;\n  }\n}\n\nfunction isDefined(value) {\n  return value !== undefined && value !== null;\n}\n\nfunction isKeyOperator(operator) {\n  return operator === \";\" || operator === \"&\" || operator === \"?\";\n}\n\nfunction getValues(context, operator, key, modifier) {\n  var value = context[key],\n      result = [];\n\n  if (isDefined(value) && value !== \"\") {\n    if (typeof value === \"string\" || typeof value === \"number\" || typeof value === \"boolean\") {\n      value = value.toString();\n\n      if (modifier && modifier !== \"*\") {\n        value = value.substring(0, parseInt(modifier, 10));\n      }\n\n      result.push(encodeValue(operator, value, isKeyOperator(operator) ? key : \"\"));\n    } else {\n      if (modifier === \"*\") {\n        if (Array.isArray(value)) {\n          value.filter(isDefined).forEach(function (value) {\n            result.push(encodeValue(operator, value, isKeyOperator(operator) ? key : \"\"));\n          });\n        } else {\n          Object.keys(value).forEach(function (k) {\n            if (isDefined(value[k])) {\n              result.push(encodeValue(operator, value[k], k));\n            }\n          });\n        }\n      } else {\n        const tmp = [];\n\n        if (Array.isArray(value)) {\n          value.filter(isDefined).forEach(function (value) {\n            tmp.push(encodeValue(operator, value));\n          });\n        } else {\n          Object.keys(value).forEach(function (k) {\n            if (isDefined(value[k])) {\n              tmp.push(encodeUnreserved(k));\n              tmp.push(encodeValue(operator, value[k].toString()));\n            }\n          });\n        }\n\n        if (isKeyOperator(operator)) {\n          result.push(encodeUnreserved(key) + \"=\" + tmp.join(\",\"));\n        } else if (tmp.length !== 0) {\n          result.push(tmp.join(\",\"));\n        }\n      }\n    }\n  } else {\n    if (operator === \";\") {\n      if (isDefined(value)) {\n        result.push(encodeUnreserved(key));\n      }\n    } else if (value === \"\" && (operator === \"&\" || operator === \"?\")) {\n      result.push(encodeUnreserved(key) + \"=\");\n    } else if (value === \"\") {\n      result.push(\"\");\n    }\n  }\n\n  return result;\n}\n\nfunction parseUrl(template) {\n  return {\n    expand: expand.bind(null, template)\n  };\n}\n\nfunction expand(template, context) {\n  var operators = [\"+\", \"#\", \".\", \"/\", \";\", \"?\", \"&\"];\n  return template.replace(/\\{([^\\{\\}]+)\\}|([^\\{\\}]+)/g, function (_, expression, literal) {\n    if (expression) {\n      let operator = \"\";\n      const values = [];\n\n      if (operators.indexOf(expression.charAt(0)) !== -1) {\n        operator = expression.charAt(0);\n        expression = expression.substr(1);\n      }\n\n      expression.split(/,/g).forEach(function (variable) {\n        var tmp = /([^:\\*]*)(?::(\\d+)|(\\*))?/.exec(variable);\n        values.push(getValues(context, operator, tmp[1], tmp[2] || tmp[3]));\n      });\n\n      if (operator && operator !== \"+\") {\n        var separator = \",\";\n\n        if (operator === \"?\") {\n          separator = \"&\";\n        } else if (operator !== \"#\") {\n          separator = operator;\n        }\n\n        return (values.length !== 0 ? operator : \"\") + values.join(separator);\n      } else {\n        return values.join(\",\");\n      }\n    } else {\n      return encodeReserved(literal);\n    }\n  });\n}\n\nfunction parse(options) {\n  // https://fetch.spec.whatwg.org/#methods\n  let method = options.method.toUpperCase(); // replace :varname with {varname} to make it RFC 6570 compatible\n\n  let url = (options.url || \"/\").replace(/:([a-z]\\w+)/g, \"{$1}\");\n  let headers = Object.assign({}, options.headers);\n  let body;\n  let parameters = omit(options, [\"method\", \"baseUrl\", \"url\", \"headers\", \"request\", \"mediaType\"]); // extract variable names from URL to calculate remaining variables later\n\n  const urlVariableNames = extractUrlVariableNames(url);\n  url = parseUrl(url).expand(parameters);\n\n  if (!/^http/.test(url)) {\n    url = options.baseUrl + url;\n  }\n\n  const omittedParameters = Object.keys(options).filter(option => urlVariableNames.includes(option)).concat(\"baseUrl\");\n  const remainingParameters = omit(parameters, omittedParameters);\n  const isBinaryRequest = /application\\/octet-stream/i.test(headers.accept);\n\n  if (!isBinaryRequest) {\n    if (options.mediaType.format) {\n      // e.g. application/vnd.github.v3+json => application/vnd.github.v3.raw\n      headers.accept = headers.accept.split(/,/).map(preview => preview.replace(/application\\/vnd(\\.\\w+)(\\.v3)?(\\.\\w+)?(\\+json)?$/, `application/vnd$1$2.${options.mediaType.format}`)).join(\",\");\n    }\n\n    if (options.mediaType.previews.length) {\n      const previewsFromAcceptHeader = headers.accept.match(/[\\w-]+(?=-preview)/g) || [];\n      headers.accept = previewsFromAcceptHeader.concat(options.mediaType.previews).map(preview => {\n        const format = options.mediaType.format ? `.${options.mediaType.format}` : \"+json\";\n        return `application/vnd.github.${preview}-preview${format}`;\n      }).join(\",\");\n    }\n  } // for GET/HEAD requests, set URL query parameters from remaining parameters\n  // for PATCH/POST/PUT/DELETE requests, set request body from remaining parameters\n\n\n  if ([\"GET\", \"HEAD\"].includes(method)) {\n    url = addQueryParameters(url, remainingParameters);\n  } else {\n    if (\"data\" in remainingParameters) {\n      body = remainingParameters.data;\n    } else {\n      if (Object.keys(remainingParameters).length) {\n        body = remainingParameters;\n      } else {\n        headers[\"content-length\"] = 0;\n      }\n    }\n  } // default content-type for JSON if body is set\n\n\n  if (!headers[\"content-type\"] && typeof body !== \"undefined\") {\n    headers[\"content-type\"] = \"application/json; charset=utf-8\";\n  } // GitHub expects 'content-length: 0' header for PUT/PATCH requests without body.\n  // fetch does not allow to set `content-length` header, but we can set body to an empty string\n\n\n  if ([\"PATCH\", \"PUT\"].includes(method) && typeof body === \"undefined\") {\n    body = \"\";\n  } // Only return body/request keys if present\n\n\n  return Object.assign({\n    method,\n    url,\n    headers\n  }, typeof body !== \"undefined\" ? {\n    body\n  } : null, options.request ? {\n    request: options.request\n  } : null);\n}\n\nfunction endpointWithDefaults(defaults, route, options) {\n  return parse(merge(defaults, route, options));\n}\n\nfunction withDefaults(oldDefaults, newDefaults) {\n  const DEFAULTS = merge(oldDefaults, newDefaults);\n  const endpoint = endpointWithDefaults.bind(null, DEFAULTS);\n  return Object.assign(endpoint, {\n    DEFAULTS,\n    defaults: withDefaults.bind(null, DEFAULTS),\n    merge: merge.bind(null, DEFAULTS),\n    parse\n  });\n}\n\nconst VERSION = \"6.0.11\";\n\nconst userAgent = `octokit-endpoint.js/${VERSION} ${universalUserAgent.getUserAgent()}`; // DEFAULTS has all properties set that EndpointOptions has, except url.\n// So we use RequestParameters and add method as additional required property.\n\nconst DEFAULTS = {\n  method: \"GET\",\n  baseUrl: \"https://api.github.com\",\n  headers: {\n    accept: \"application/vnd.github.v3+json\",\n    \"user-agent\": userAgent\n  },\n  mediaType: {\n    format: \"\",\n    previews: []\n  }\n};\n\nconst endpoint = withDefaults(null, DEFAULTS);\n\nexports.endpoint = endpoint;\n//# sourceMappingURL=index.js.map\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar request = require('@octokit/request');\nvar universalUserAgent = require('universal-user-agent');\n\nconst VERSION = \"4.6.2\";\n\nclass GraphqlError extends Error {\n  constructor(request, response) {\n    const message = response.data.errors[0].message;\n    super(message);\n    Object.assign(this, response.data);\n    Object.assign(this, {\n      headers: response.headers\n    });\n    this.name = \"GraphqlError\";\n    this.request = request; // Maintains proper stack trace (only available on V8)\n\n    /* istanbul ignore next */\n\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, this.constructor);\n    }\n  }\n\n}\n\nconst NON_VARIABLE_OPTIONS = [\"method\", \"baseUrl\", \"url\", \"headers\", \"request\", \"query\", \"mediaType\"];\nconst FORBIDDEN_VARIABLE_OPTIONS = [\"query\", \"method\", \"url\"];\nconst GHES_V3_SUFFIX_REGEX = /\\/api\\/v3\\/?$/;\nfunction graphql(request, query, options) {\n  if (options) {\n    if (typeof query === \"string\" && \"query\" in options) {\n      return Promise.reject(new Error(`[@octokit/graphql] \"query\" cannot be used as variable name`));\n    }\n\n    for (const key in options) {\n      if (!FORBIDDEN_VARIABLE_OPTIONS.includes(key)) continue;\n      return Promise.reject(new Error(`[@octokit/graphql] \"${key}\" cannot be used as variable name`));\n    }\n  }\n\n  const parsedOptions = typeof query === \"string\" ? Object.assign({\n    query\n  }, options) : query;\n  const requestOptions = Object.keys(parsedOptions).reduce((result, key) => {\n    if (NON_VARIABLE_OPTIONS.includes(key)) {\n      result[key] = parsedOptions[key];\n      return result;\n    }\n\n    if (!result.variables) {\n      result.variables = {};\n    }\n\n    result.variables[key] = parsedOptions[key];\n    return result;\n  }, {}); // workaround for GitHub Enterprise baseUrl set with /api/v3 suffix\n  // https://github.com/octokit/auth-app.js/issues/111#issuecomment-657610451\n\n  const baseUrl = parsedOptions.baseUrl || request.endpoint.DEFAULTS.baseUrl;\n\n  if (GHES_V3_SUFFIX_REGEX.test(baseUrl)) {\n    requestOptions.url = baseUrl.replace(GHES_V3_SUFFIX_REGEX, \"/api/graphql\");\n  }\n\n  return request(requestOptions).then(response => {\n    if (response.data.errors) {\n      const headers = {};\n\n      for (const key of Object.keys(response.headers)) {\n        headers[key] = response.headers[key];\n      }\n\n      throw new GraphqlError(requestOptions, {\n        headers,\n        data: response.data\n      });\n    }\n\n    return response.data.data;\n  });\n}\n\nfunction withDefaults(request$1, newDefaults) {\n  const newRequest = request$1.defaults(newDefaults);\n\n  const newApi = (query, options) => {\n    return graphql(newRequest, query, options);\n  };\n\n  return Object.assign(newApi, {\n    defaults: withDefaults.bind(null, newRequest),\n    endpoint: request.request.endpoint\n  });\n}\n\nconst graphql$1 = withDefaults(request.request, {\n  headers: {\n    \"user-agent\": `octokit-graphql.js/${VERSION} ${universalUserAgent.getUserAgent()}`\n  },\n  method: \"POST\",\n  url: \"/graphql\"\n});\nfunction withCustomRequest(customRequest) {\n  return withDefaults(customRequest, {\n    method: \"POST\",\n    url: \"/graphql\"\n  });\n}\n\nexports.graphql = graphql$1;\nexports.withCustomRequest = withCustomRequest;\n//# sourceMappingURL=index.js.map\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nconst VERSION = \"2.13.3\";\n\n/**\n * Some “list” response that can be paginated have a different response structure\n *\n * They have a `total_count` key in the response (search also has `incomplete_results`,\n * /installation/repositories also has `repository_selection`), as well as a key with\n * the list of the items which name varies from endpoint to endpoint.\n *\n * Octokit normalizes these responses so that paginated results are always returned following\n * the same structure. One challenge is that if the list response has only one page, no Link\n * header is provided, so this header alone is not sufficient to check wether a response is\n * paginated or not.\n *\n * We check if a \"total_count\" key is present in the response data, but also make sure that\n * a \"url\" property is not, as the \"Get the combined status for a specific ref\" endpoint would\n * otherwise match: https://developer.github.com/v3/repos/statuses/#get-the-combined-status-for-a-specific-ref\n */\nfunction normalizePaginatedListResponse(response) {\n  const responseNeedsNormalization = \"total_count\" in response.data && !(\"url\" in response.data);\n  if (!responseNeedsNormalization) return response; // keep the additional properties intact as there is currently no other way\n  // to retrieve the same information.\n\n  const incompleteResults = response.data.incomplete_results;\n  const repositorySelection = response.data.repository_selection;\n  const totalCount = response.data.total_count;\n  delete response.data.incomplete_results;\n  delete response.data.repository_selection;\n  delete response.data.total_count;\n  const namespaceKey = Object.keys(response.data)[0];\n  const data = response.data[namespaceKey];\n  response.data = data;\n\n  if (typeof incompleteResults !== \"undefined\") {\n    response.data.incomplete_results = incompleteResults;\n  }\n\n  if (typeof repositorySelection !== \"undefined\") {\n    response.data.repository_selection = repositorySelection;\n  }\n\n  response.data.total_count = totalCount;\n  return response;\n}\n\nfunction iterator(octokit, route, parameters) {\n  const options = typeof route === \"function\" ? route.endpoint(parameters) : octokit.request.endpoint(route, parameters);\n  const requestMethod = typeof route === \"function\" ? route : octokit.request;\n  const method = options.method;\n  const headers = options.headers;\n  let url = options.url;\n  return {\n    [Symbol.asyncIterator]: () => ({\n      async next() {\n        if (!url) return {\n          done: true\n        };\n        const response = await requestMethod({\n          method,\n          url,\n          headers\n        });\n        const normalizedResponse = normalizePaginatedListResponse(response); // `response.headers.link` format:\n        // '<https://api.github.com/users/aseemk/followers?page=2>; rel=\"next\", <https://api.github.com/users/aseemk/followers?page=2>; rel=\"last\"'\n        // sets `url` to undefined if \"next\" URL is not present or `link` header is not set\n\n        url = ((normalizedResponse.headers.link || \"\").match(/<([^>]+)>;\\s*rel=\"next\"/) || [])[1];\n        return {\n          value: normalizedResponse\n        };\n      }\n\n    })\n  };\n}\n\nfunction paginate(octokit, route, parameters, mapFn) {\n  if (typeof parameters === \"function\") {\n    mapFn = parameters;\n    parameters = undefined;\n  }\n\n  return gather(octokit, [], iterator(octokit, route, parameters)[Symbol.asyncIterator](), mapFn);\n}\n\nfunction gather(octokit, results, iterator, mapFn) {\n  return iterator.next().then(result => {\n    if (result.done) {\n      return results;\n    }\n\n    let earlyExit = false;\n\n    function done() {\n      earlyExit = true;\n    }\n\n    results = results.concat(mapFn ? mapFn(result.value, done) : result.value.data);\n\n    if (earlyExit) {\n      return results;\n    }\n\n    return gather(octokit, results, iterator, mapFn);\n  });\n}\n\nconst composePaginateRest = Object.assign(paginate, {\n  iterator\n});\n\nconst paginatingEndpoints = [\"GET /app/installations\", \"GET /applications/grants\", \"GET /authorizations\", \"GET /enterprises/{enterprise}/actions/permissions/organizations\", \"GET /enterprises/{enterprise}/actions/runner-groups\", \"GET /enterprises/{enterprise}/actions/runner-groups/{runner_group_id}/organizations\", \"GET /enterprises/{enterprise}/actions/runner-groups/{runner_group_id}/runners\", \"GET /enterprises/{enterprise}/actions/runners\", \"GET /enterprises/{enterprise}/actions/runners/downloads\", \"GET /events\", \"GET /gists\", \"GET /gists/public\", \"GET /gists/starred\", \"GET /gists/{gist_id}/comments\", \"GET /gists/{gist_id}/commits\", \"GET /gists/{gist_id}/forks\", \"GET /installation/repositories\", \"GET /issues\", \"GET /marketplace_listing/plans\", \"GET /marketplace_listing/plans/{plan_id}/accounts\", \"GET /marketplace_listing/stubbed/plans\", \"GET /marketplace_listing/stubbed/plans/{plan_id}/accounts\", \"GET /networks/{owner}/{repo}/events\", \"GET /notifications\", \"GET /organizations\", \"GET /orgs/{org}/actions/permissions/repositories\", \"GET /orgs/{org}/actions/runner-groups\", \"GET /orgs/{org}/actions/runner-groups/{runner_group_id}/repositories\", \"GET /orgs/{org}/actions/runner-groups/{runner_group_id}/runners\", \"GET /orgs/{org}/actions/runners\", \"GET /orgs/{org}/actions/runners/downloads\", \"GET /orgs/{org}/actions/secrets\", \"GET /orgs/{org}/actions/secrets/{secret_name}/repositories\", \"GET /orgs/{org}/blocks\", \"GET /orgs/{org}/credential-authorizations\", \"GET /orgs/{org}/events\", \"GET /orgs/{org}/failed_invitations\", \"GET /orgs/{org}/hooks\", \"GET /orgs/{org}/installations\", \"GET /orgs/{org}/invitations\", \"GET /orgs/{org}/invitations/{invitation_id}/teams\", \"GET /orgs/{org}/issues\", \"GET /orgs/{org}/members\", \"GET /orgs/{org}/migrations\", \"GET /orgs/{org}/migrations/{migration_id}/repositories\", \"GET /orgs/{org}/outside_collaborators\", \"GET /orgs/{org}/projects\", \"GET /orgs/{org}/public_members\", \"GET /orgs/{org}/repos\", \"GET /orgs/{org}/team-sync/groups\", \"GET /orgs/{org}/teams\", \"GET /orgs/{org}/teams/{team_slug}/discussions\", \"GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments\", \"GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}/reactions\", \"GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/reactions\", \"GET /orgs/{org}/teams/{team_slug}/invitations\", \"GET /orgs/{org}/teams/{team_slug}/members\", \"GET /orgs/{org}/teams/{team_slug}/projects\", \"GET /orgs/{org}/teams/{team_slug}/repos\", \"GET /orgs/{org}/teams/{team_slug}/team-sync/group-mappings\", \"GET /orgs/{org}/teams/{team_slug}/teams\", \"GET /projects/columns/{column_id}/cards\", \"GET /projects/{project_id}/collaborators\", \"GET /projects/{project_id}/columns\", \"GET /repos/{owner}/{repo}/actions/artifacts\", \"GET /repos/{owner}/{repo}/actions/runners\", \"GET /repos/{owner}/{repo}/actions/runners/downloads\", \"GET /repos/{owner}/{repo}/actions/runs\", \"GET /repos/{owner}/{repo}/actions/runs/{run_id}/artifacts\", \"GET /repos/{owner}/{repo}/actions/runs/{run_id}/jobs\", \"GET /repos/{owner}/{repo}/actions/secrets\", \"GET /repos/{owner}/{repo}/actions/workflows\", \"GET /repos/{owner}/{repo}/actions/workflows/{workflow_id}/runs\", \"GET /repos/{owner}/{repo}/assignees\", \"GET /repos/{owner}/{repo}/branches\", \"GET /repos/{owner}/{repo}/check-runs/{check_run_id}/annotations\", \"GET /repos/{owner}/{repo}/check-suites/{check_suite_id}/check-runs\", \"GET /repos/{owner}/{repo}/code-scanning/alerts\", \"GET /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}/instances\", \"GET /repos/{owner}/{repo}/code-scanning/analyses\", \"GET /repos/{owner}/{repo}/collaborators\", \"GET /repos/{owner}/{repo}/comments\", \"GET /repos/{owner}/{repo}/comments/{comment_id}/reactions\", \"GET /repos/{owner}/{repo}/commits\", \"GET /repos/{owner}/{repo}/commits/{commit_sha}/branches-where-head\", \"GET /repos/{owner}/{repo}/commits/{commit_sha}/comments\", \"GET /repos/{owner}/{repo}/commits/{commit_sha}/pulls\", \"GET /repos/{owner}/{repo}/commits/{ref}/check-runs\", \"GET /repos/{owner}/{repo}/commits/{ref}/check-suites\", \"GET /repos/{owner}/{repo}/commits/{ref}/statuses\", \"GET /repos/{owner}/{repo}/contributors\", \"GET /repos/{owner}/{repo}/deployments\", \"GET /repos/{owner}/{repo}/deployments/{deployment_id}/statuses\", \"GET /repos/{owner}/{repo}/events\", \"GET /repos/{owner}/{repo}/forks\", \"GET /repos/{owner}/{repo}/git/matching-refs/{ref}\", \"GET /repos/{owner}/{repo}/hooks\", \"GET /repos/{owner}/{repo}/invitations\", \"GET /repos/{owner}/{repo}/issues\", \"GET /repos/{owner}/{repo}/issues/comments\", \"GET /repos/{owner}/{repo}/issues/comments/{comment_id}/reactions\", \"GET /repos/{owner}/{repo}/issues/events\", \"GET /repos/{owner}/{repo}/issues/{issue_number}/comments\", \"GET /repos/{owner}/{repo}/issues/{issue_number}/events\", \"GET /repos/{owner}/{repo}/issues/{issue_number}/labels\", \"GET /repos/{owner}/{repo}/issues/{issue_number}/reactions\", \"GET /repos/{owner}/{repo}/issues/{issue_number}/timeline\", \"GET /repos/{owner}/{repo}/keys\", \"GET /repos/{owner}/{repo}/labels\", \"GET /repos/{owner}/{repo}/milestones\", \"GET /repos/{owner}/{repo}/milestones/{milestone_number}/labels\", \"GET /repos/{owner}/{repo}/notifications\", \"GET /repos/{owner}/{repo}/pages/builds\", \"GET /repos/{owner}/{repo}/projects\", \"GET /repos/{owner}/{repo}/pulls\", \"GET /repos/{owner}/{repo}/pulls/comments\", \"GET /repos/{owner}/{repo}/pulls/comments/{comment_id}/reactions\", \"GET /repos/{owner}/{repo}/pulls/{pull_number}/comments\", \"GET /repos/{owner}/{repo}/pulls/{pull_number}/commits\", \"GET /repos/{owner}/{repo}/pulls/{pull_number}/files\", \"GET /repos/{owner}/{repo}/pulls/{pull_number}/requested_reviewers\", \"GET /repos/{owner}/{repo}/pulls/{pull_number}/reviews\", \"GET /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}/comments\", \"GET /repos/{owner}/{repo}/releases\", \"GET /repos/{owner}/{repo}/releases/{release_id}/assets\", \"GET /repos/{owner}/{repo}/secret-scanning/alerts\", \"GET /repos/{owner}/{repo}/stargazers\", \"GET /repos/{owner}/{repo}/subscribers\", \"GET /repos/{owner}/{repo}/tags\", \"GET /repos/{owner}/{repo}/teams\", \"GET /repositories\", \"GET /repositories/{repository_id}/environments/{environment_name}/secrets\", \"GET /scim/v2/enterprises/{enterprise}/Groups\", \"GET /scim/v2/enterprises/{enterprise}/Users\", \"GET /scim/v2/organizations/{org}/Users\", \"GET /search/code\", \"GET /search/commits\", \"GET /search/issues\", \"GET /search/labels\", \"GET /search/repositories\", \"GET /search/topics\", \"GET /search/users\", \"GET /teams/{team_id}/discussions\", \"GET /teams/{team_id}/discussions/{discussion_number}/comments\", \"GET /teams/{team_id}/discussions/{discussion_number}/comments/{comment_number}/reactions\", \"GET /teams/{team_id}/discussions/{discussion_number}/reactions\", \"GET /teams/{team_id}/invitations\", \"GET /teams/{team_id}/members\", \"GET /teams/{team_id}/projects\", \"GET /teams/{team_id}/repos\", \"GET /teams/{team_id}/team-sync/group-mappings\", \"GET /teams/{team_id}/teams\", \"GET /user/blocks\", \"GET /user/emails\", \"GET /user/followers\", \"GET /user/following\", \"GET /user/gpg_keys\", \"GET /user/installations\", \"GET /user/installations/{installation_id}/repositories\", \"GET /user/issues\", \"GET /user/keys\", \"GET /user/marketplace_purchases\", \"GET /user/marketplace_purchases/stubbed\", \"GET /user/memberships/orgs\", \"GET /user/migrations\", \"GET /user/migrations/{migration_id}/repositories\", \"GET /user/orgs\", \"GET /user/public_emails\", \"GET /user/repos\", \"GET /user/repository_invitations\", \"GET /user/starred\", \"GET /user/subscriptions\", \"GET /user/teams\", \"GET /users\", \"GET /users/{username}/events\", \"GET /users/{username}/events/orgs/{org}\", \"GET /users/{username}/events/public\", \"GET /users/{username}/followers\", \"GET /users/{username}/following\", \"GET /users/{username}/gists\", \"GET /users/{username}/gpg_keys\", \"GET /users/{username}/keys\", \"GET /users/{username}/orgs\", \"GET /users/{username}/projects\", \"GET /users/{username}/received_events\", \"GET /users/{username}/received_events/public\", \"GET /users/{username}/repos\", \"GET /users/{username}/starred\", \"GET /users/{username}/subscriptions\"];\n\nfunction isPaginatingEndpoint(arg) {\n  if (typeof arg === \"string\") {\n    return paginatingEndpoints.includes(arg);\n  } else {\n    return false;\n  }\n}\n\n/**\n * @param octokit Octokit instance\n * @param options Options passed to Octokit constructor\n */\n\nfunction paginateRest(octokit) {\n  return {\n    paginate: Object.assign(paginate.bind(null, octokit), {\n      iterator: iterator.bind(null, octokit)\n    })\n  };\n}\npaginateRest.VERSION = VERSION;\n\nexports.composePaginateRest = composePaginateRest;\nexports.isPaginatingEndpoint = isPaginatingEndpoint;\nexports.paginateRest = paginateRest;\nexports.paginatingEndpoints = paginatingEndpoints;\n//# sourceMappingURL=index.js.map\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nfunction ownKeys(object, enumerableOnly) {\n  var keys = Object.keys(object);\n\n  if (Object.getOwnPropertySymbols) {\n    var symbols = Object.getOwnPropertySymbols(object);\n\n    if (enumerableOnly) {\n      symbols = symbols.filter(function (sym) {\n        return Object.getOwnPropertyDescriptor(object, sym).enumerable;\n      });\n    }\n\n    keys.push.apply(keys, symbols);\n  }\n\n  return keys;\n}\n\nfunction _objectSpread2(target) {\n  for (var i = 1; i < arguments.length; i++) {\n    var source = arguments[i] != null ? arguments[i] : {};\n\n    if (i % 2) {\n      ownKeys(Object(source), true).forEach(function (key) {\n        _defineProperty(target, key, source[key]);\n      });\n    } else if (Object.getOwnPropertyDescriptors) {\n      Object.defineProperties(target, Object.getOwnPropertyDescriptors(source));\n    } else {\n      ownKeys(Object(source)).forEach(function (key) {\n        Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key));\n      });\n    }\n  }\n\n  return target;\n}\n\nfunction _defineProperty(obj, key, value) {\n  if (key in obj) {\n    Object.defineProperty(obj, key, {\n      value: value,\n      enumerable: true,\n      configurable: true,\n      writable: true\n    });\n  } else {\n    obj[key] = value;\n  }\n\n  return obj;\n}\n\nconst Endpoints = {\n  actions: {\n    addSelectedRepoToOrgSecret: [\"PUT /orgs/{org}/actions/secrets/{secret_name}/repositories/{repository_id}\"],\n    approveWorkflowRun: [\"POST /repos/{owner}/{repo}/actions/runs/{run_id}/approve\"],\n    cancelWorkflowRun: [\"POST /repos/{owner}/{repo}/actions/runs/{run_id}/cancel\"],\n    createOrUpdateEnvironmentSecret: [\"PUT /repositories/{repository_id}/environments/{environment_name}/secrets/{secret_name}\"],\n    createOrUpdateOrgSecret: [\"PUT /orgs/{org}/actions/secrets/{secret_name}\"],\n    createOrUpdateRepoSecret: [\"PUT /repos/{owner}/{repo}/actions/secrets/{secret_name}\"],\n    createRegistrationTokenForOrg: [\"POST /orgs/{org}/actions/runners/registration-token\"],\n    createRegistrationTokenForRepo: [\"POST /repos/{owner}/{repo}/actions/runners/registration-token\"],\n    createRemoveTokenForOrg: [\"POST /orgs/{org}/actions/runners/remove-token\"],\n    createRemoveTokenForRepo: [\"POST /repos/{owner}/{repo}/actions/runners/remove-token\"],\n    createWorkflowDispatch: [\"POST /repos/{owner}/{repo}/actions/workflows/{workflow_id}/dispatches\"],\n    deleteArtifact: [\"DELETE /repos/{owner}/{repo}/actions/artifacts/{artifact_id}\"],\n    deleteEnvironmentSecret: [\"DELETE /repositories/{repository_id}/environments/{environment_name}/secrets/{secret_name}\"],\n    deleteOrgSecret: [\"DELETE /orgs/{org}/actions/secrets/{secret_name}\"],\n    deleteRepoSecret: [\"DELETE /repos/{owner}/{repo}/actions/secrets/{secret_name}\"],\n    deleteSelfHostedRunnerFromOrg: [\"DELETE /orgs/{org}/actions/runners/{runner_id}\"],\n    deleteSelfHostedRunnerFromRepo: [\"DELETE /repos/{owner}/{repo}/actions/runners/{runner_id}\"],\n    deleteWorkflowRun: [\"DELETE /repos/{owner}/{repo}/actions/runs/{run_id}\"],\n    deleteWorkflowRunLogs: [\"DELETE /repos/{owner}/{repo}/actions/runs/{run_id}/logs\"],\n    disableSelectedRepositoryGithubActionsOrganization: [\"DELETE /orgs/{org}/actions/permissions/repositories/{repository_id}\"],\n    disableWorkflow: [\"PUT /repos/{owner}/{repo}/actions/workflows/{workflow_id}/disable\"],\n    downloadArtifact: [\"GET /repos/{owner}/{repo}/actions/artifacts/{artifact_id}/{archive_format}\"],\n    downloadJobLogsForWorkflowRun: [\"GET /repos/{owner}/{repo}/actions/jobs/{job_id}/logs\"],\n    downloadWorkflowRunLogs: [\"GET /repos/{owner}/{repo}/actions/runs/{run_id}/logs\"],\n    enableSelectedRepositoryGithubActionsOrganization: [\"PUT /orgs/{org}/actions/permissions/repositories/{repository_id}\"],\n    enableWorkflow: [\"PUT /repos/{owner}/{repo}/actions/workflows/{workflow_id}/enable\"],\n    getAllowedActionsOrganization: [\"GET /orgs/{org}/actions/permissions/selected-actions\"],\n    getAllowedActionsRepository: [\"GET /repos/{owner}/{repo}/actions/permissions/selected-actions\"],\n    getArtifact: [\"GET /repos/{owner}/{repo}/actions/artifacts/{artifact_id}\"],\n    getEnvironmentPublicKey: [\"GET /repositories/{repository_id}/environments/{environment_name}/secrets/public-key\"],\n    getEnvironmentSecret: [\"GET /repositories/{repository_id}/environments/{environment_name}/secrets/{secret_name}\"],\n    getGithubActionsPermissionsOrganization: [\"GET /orgs/{org}/actions/permissions\"],\n    getGithubActionsPermissionsRepository: [\"GET /repos/{owner}/{repo}/actions/permissions\"],\n    getJobForWorkflowRun: [\"GET /repos/{owner}/{repo}/actions/jobs/{job_id}\"],\n    getOrgPublicKey: [\"GET /orgs/{org}/actions/secrets/public-key\"],\n    getOrgSecret: [\"GET /orgs/{org}/actions/secrets/{secret_name}\"],\n    getPendingDeploymentsForRun: [\"GET /repos/{owner}/{repo}/actions/runs/{run_id}/pending_deployments\"],\n    getRepoPermissions: [\"GET /repos/{owner}/{repo}/actions/permissions\", {}, {\n      renamed: [\"actions\", \"getGithubActionsPermissionsRepository\"]\n    }],\n    getRepoPublicKey: [\"GET /repos/{owner}/{repo}/actions/secrets/public-key\"],\n    getRepoSecret: [\"GET /repos/{owner}/{repo}/actions/secrets/{secret_name}\"],\n    getReviewsForRun: [\"GET /repos/{owner}/{repo}/actions/runs/{run_id}/approvals\"],\n    getSelfHostedRunnerForOrg: [\"GET /orgs/{org}/actions/runners/{runner_id}\"],\n    getSelfHostedRunnerForRepo: [\"GET /repos/{owner}/{repo}/actions/runners/{runner_id}\"],\n    getWorkflow: [\"GET /repos/{owner}/{repo}/actions/workflows/{workflow_id}\"],\n    getWorkflowRun: [\"GET /repos/{owner}/{repo}/actions/runs/{run_id}\"],\n    getWorkflowRunUsage: [\"GET /repos/{owner}/{repo}/actions/runs/{run_id}/timing\"],\n    getWorkflowUsage: [\"GET /repos/{owner}/{repo}/actions/workflows/{workflow_id}/timing\"],\n    listArtifactsForRepo: [\"GET /repos/{owner}/{repo}/actions/artifacts\"],\n    listEnvironmentSecrets: [\"GET /repositories/{repository_id}/environments/{environment_name}/secrets\"],\n    listJobsForWorkflowRun: [\"GET /repos/{owner}/{repo}/actions/runs/{run_id}/jobs\"],\n    listOrgSecrets: [\"GET /orgs/{org}/actions/secrets\"],\n    listRepoSecrets: [\"GET /repos/{owner}/{repo}/actions/secrets\"],\n    listRepoWorkflows: [\"GET /repos/{owner}/{repo}/actions/workflows\"],\n    listRunnerApplicationsForOrg: [\"GET /orgs/{org}/actions/runners/downloads\"],\n    listRunnerApplicationsForRepo: [\"GET /repos/{owner}/{repo}/actions/runners/downloads\"],\n    listSelectedReposForOrgSecret: [\"GET /orgs/{org}/actions/secrets/{secret_name}/repositories\"],\n    listSelectedRepositoriesEnabledGithubActionsOrganization: [\"GET /orgs/{org}/actions/permissions/repositories\"],\n    listSelfHostedRunnersForOrg: [\"GET /orgs/{org}/actions/runners\"],\n    listSelfHostedRunnersForRepo: [\"GET /repos/{owner}/{repo}/actions/runners\"],\n    listWorkflowRunArtifacts: [\"GET /repos/{owner}/{repo}/actions/runs/{run_id}/artifacts\"],\n    listWorkflowRuns: [\"GET /repos/{owner}/{repo}/actions/workflows/{workflow_id}/runs\"],\n    listWorkflowRunsForRepo: [\"GET /repos/{owner}/{repo}/actions/runs\"],\n    reRunWorkflow: [\"POST /repos/{owner}/{repo}/actions/runs/{run_id}/rerun\"],\n    removeSelectedRepoFromOrgSecret: [\"DELETE /orgs/{org}/actions/secrets/{secret_name}/repositories/{repository_id}\"],\n    reviewPendingDeploymentsForRun: [\"POST /repos/{owner}/{repo}/actions/runs/{run_id}/pending_deployments\"],\n    setAllowedActionsOrganization: [\"PUT /orgs/{org}/actions/permissions/selected-actions\"],\n    setAllowedActionsRepository: [\"PUT /repos/{owner}/{repo}/actions/permissions/selected-actions\"],\n    setGithubActionsPermissionsOrganization: [\"PUT /orgs/{org}/actions/permissions\"],\n    setGithubActionsPermissionsRepository: [\"PUT /repos/{owner}/{repo}/actions/permissions\"],\n    setSelectedReposForOrgSecret: [\"PUT /orgs/{org}/actions/secrets/{secret_name}/repositories\"],\n    setSelectedRepositoriesEnabledGithubActionsOrganization: [\"PUT /orgs/{org}/actions/permissions/repositories\"]\n  },\n  activity: {\n    checkRepoIsStarredByAuthenticatedUser: [\"GET /user/starred/{owner}/{repo}\"],\n    deleteRepoSubscription: [\"DELETE /repos/{owner}/{repo}/subscription\"],\n    deleteThreadSubscription: [\"DELETE /notifications/threads/{thread_id}/subscription\"],\n    getFeeds: [\"GET /feeds\"],\n    getRepoSubscription: [\"GET /repos/{owner}/{repo}/subscription\"],\n    getThread: [\"GET /notifications/threads/{thread_id}\"],\n    getThreadSubscriptionForAuthenticatedUser: [\"GET /notifications/threads/{thread_id}/subscription\"],\n    listEventsForAuthenticatedUser: [\"GET /users/{username}/events\"],\n    listNotificationsForAuthenticatedUser: [\"GET /notifications\"],\n    listOrgEventsForAuthenticatedUser: [\"GET /users/{username}/events/orgs/{org}\"],\n    listPublicEvents: [\"GET /events\"],\n    listPublicEventsForRepoNetwork: [\"GET /networks/{owner}/{repo}/events\"],\n    listPublicEventsForUser: [\"GET /users/{username}/events/public\"],\n    listPublicOrgEvents: [\"GET /orgs/{org}/events\"],\n    listReceivedEventsForUser: [\"GET /users/{username}/received_events\"],\n    listReceivedPublicEventsForUser: [\"GET /users/{username}/received_events/public\"],\n    listRepoEvents: [\"GET /repos/{owner}/{repo}/events\"],\n    listRepoNotificationsForAuthenticatedUser: [\"GET /repos/{owner}/{repo}/notifications\"],\n    listReposStarredByAuthenticatedUser: [\"GET /user/starred\"],\n    listReposStarredByUser: [\"GET /users/{username}/starred\"],\n    listReposWatchedByUser: [\"GET /users/{username}/subscriptions\"],\n    listStargazersForRepo: [\"GET /repos/{owner}/{repo}/stargazers\"],\n    listWatchedReposForAuthenticatedUser: [\"GET /user/subscriptions\"],\n    listWatchersForRepo: [\"GET /repos/{owner}/{repo}/subscribers\"],\n    markNotificationsAsRead: [\"PUT /notifications\"],\n    markRepoNotificationsAsRead: [\"PUT /repos/{owner}/{repo}/notifications\"],\n    markThreadAsRead: [\"PATCH /notifications/threads/{thread_id}\"],\n    setRepoSubscription: [\"PUT /repos/{owner}/{repo}/subscription\"],\n    setThreadSubscription: [\"PUT /notifications/threads/{thread_id}/subscription\"],\n    starRepoForAuthenticatedUser: [\"PUT /user/starred/{owner}/{repo}\"],\n    unstarRepoForAuthenticatedUser: [\"DELETE /user/starred/{owner}/{repo}\"]\n  },\n  apps: {\n    addRepoToInstallation: [\"PUT /user/installations/{installation_id}/repositories/{repository_id}\"],\n    checkToken: [\"POST /applications/{client_id}/token\"],\n    createContentAttachment: [\"POST /content_references/{content_reference_id}/attachments\", {\n      mediaType: {\n        previews: [\"corsair\"]\n      }\n    }],\n    createContentAttachmentForRepo: [\"POST /repos/{owner}/{repo}/content_references/{content_reference_id}/attachments\", {\n      mediaType: {\n        previews: [\"corsair\"]\n      }\n    }],\n    createFromManifest: [\"POST /app-manifests/{code}/conversions\"],\n    createInstallationAccessToken: [\"POST /app/installations/{installation_id}/access_tokens\"],\n    deleteAuthorization: [\"DELETE /applications/{client_id}/grant\"],\n    deleteInstallation: [\"DELETE /app/installations/{installation_id}\"],\n    deleteToken: [\"DELETE /applications/{client_id}/token\"],\n    getAuthenticated: [\"GET /app\"],\n    getBySlug: [\"GET /apps/{app_slug}\"],\n    getInstallation: [\"GET /app/installations/{installation_id}\"],\n    getOrgInstallation: [\"GET /orgs/{org}/installation\"],\n    getRepoInstallation: [\"GET /repos/{owner}/{repo}/installation\"],\n    getSubscriptionPlanForAccount: [\"GET /marketplace_listing/accounts/{account_id}\"],\n    getSubscriptionPlanForAccountStubbed: [\"GET /marketplace_listing/stubbed/accounts/{account_id}\"],\n    getUserInstallation: [\"GET /users/{username}/installation\"],\n    getWebhookConfigForApp: [\"GET /app/hook/config\"],\n    listAccountsForPlan: [\"GET /marketplace_listing/plans/{plan_id}/accounts\"],\n    listAccountsForPlanStubbed: [\"GET /marketplace_listing/stubbed/plans/{plan_id}/accounts\"],\n    listInstallationReposForAuthenticatedUser: [\"GET /user/installations/{installation_id}/repositories\"],\n    listInstallations: [\"GET /app/installations\"],\n    listInstallationsForAuthenticatedUser: [\"GET /user/installations\"],\n    listPlans: [\"GET /marketplace_listing/plans\"],\n    listPlansStubbed: [\"GET /marketplace_listing/stubbed/plans\"],\n    listReposAccessibleToInstallation: [\"GET /installation/repositories\"],\n    listSubscriptionsForAuthenticatedUser: [\"GET /user/marketplace_purchases\"],\n    listSubscriptionsForAuthenticatedUserStubbed: [\"GET /user/marketplace_purchases/stubbed\"],\n    removeRepoFromInstallation: [\"DELETE /user/installations/{installation_id}/repositories/{repository_id}\"],\n    resetToken: [\"PATCH /applications/{client_id}/token\"],\n    revokeInstallationAccessToken: [\"DELETE /installation/token\"],\n    scopeToken: [\"POST /applications/{client_id}/token/scoped\"],\n    suspendInstallation: [\"PUT /app/installations/{installation_id}/suspended\"],\n    unsuspendInstallation: [\"DELETE /app/installations/{installation_id}/suspended\"],\n    updateWebhookConfigForApp: [\"PATCH /app/hook/config\"]\n  },\n  billing: {\n    getGithubActionsBillingOrg: [\"GET /orgs/{org}/settings/billing/actions\"],\n    getGithubActionsBillingUser: [\"GET /users/{username}/settings/billing/actions\"],\n    getGithubPackagesBillingOrg: [\"GET /orgs/{org}/settings/billing/packages\"],\n    getGithubPackagesBillingUser: [\"GET /users/{username}/settings/billing/packages\"],\n    getSharedStorageBillingOrg: [\"GET /orgs/{org}/settings/billing/shared-storage\"],\n    getSharedStorageBillingUser: [\"GET /users/{username}/settings/billing/shared-storage\"]\n  },\n  checks: {\n    create: [\"POST /repos/{owner}/{repo}/check-runs\"],\n    createSuite: [\"POST /repos/{owner}/{repo}/check-suites\"],\n    get: [\"GET /repos/{owner}/{repo}/check-runs/{check_run_id}\"],\n    getSuite: [\"GET /repos/{owner}/{repo}/check-suites/{check_suite_id}\"],\n    listAnnotations: [\"GET /repos/{owner}/{repo}/check-runs/{check_run_id}/annotations\"],\n    listForRef: [\"GET /repos/{owner}/{repo}/commits/{ref}/check-runs\"],\n    listForSuite: [\"GET /repos/{owner}/{repo}/check-suites/{check_suite_id}/check-runs\"],\n    listSuitesForRef: [\"GET /repos/{owner}/{repo}/commits/{ref}/check-suites\"],\n    rerequestSuite: [\"POST /repos/{owner}/{repo}/check-suites/{check_suite_id}/rerequest\"],\n    setSuitesPreferences: [\"PATCH /repos/{owner}/{repo}/check-suites/preferences\"],\n    update: [\"PATCH /repos/{owner}/{repo}/check-runs/{check_run_id}\"]\n  },\n  codeScanning: {\n    deleteAnalysis: [\"DELETE /repos/{owner}/{repo}/code-scanning/analyses/{analysis_id}{?confirm_delete}\"],\n    getAlert: [\"GET /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}\", {}, {\n      renamedParameters: {\n        alert_id: \"alert_number\"\n      }\n    }],\n    getAnalysis: [\"GET /repos/{owner}/{repo}/code-scanning/analyses/{analysis_id}\"],\n    getSarif: [\"GET /repos/{owner}/{repo}/code-scanning/sarifs/{sarif_id}\"],\n    listAlertInstances: [\"GET /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}/instances\"],\n    listAlertsForRepo: [\"GET /repos/{owner}/{repo}/code-scanning/alerts\"],\n    listAlertsInstances: [\"GET /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}/instances\", {}, {\n      renamed: [\"codeScanning\", \"listAlertInstances\"]\n    }],\n    listRecentAnalyses: [\"GET /repos/{owner}/{repo}/code-scanning/analyses\"],\n    updateAlert: [\"PATCH /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}\"],\n    uploadSarif: [\"POST /repos/{owner}/{repo}/code-scanning/sarifs\"]\n  },\n  codesOfConduct: {\n    getAllCodesOfConduct: [\"GET /codes_of_conduct\", {\n      mediaType: {\n        previews: [\"scarlet-witch\"]\n      }\n    }],\n    getConductCode: [\"GET /codes_of_conduct/{key}\", {\n      mediaType: {\n        previews: [\"scarlet-witch\"]\n      }\n    }],\n    getForRepo: [\"GET /repos/{owner}/{repo}/community/code_of_conduct\", {\n      mediaType: {\n        previews: [\"scarlet-witch\"]\n      }\n    }]\n  },\n  emojis: {\n    get: [\"GET /emojis\"]\n  },\n  enterpriseAdmin: {\n    disableSelectedOrganizationGithubActionsEnterprise: [\"DELETE /enterprises/{enterprise}/actions/permissions/organizations/{org_id}\"],\n    enableSelectedOrganizationGithubActionsEnterprise: [\"PUT /enterprises/{enterprise}/actions/permissions/organizations/{org_id}\"],\n    getAllowedActionsEnterprise: [\"GET /enterprises/{enterprise}/actions/permissions/selected-actions\"],\n    getGithubActionsPermissionsEnterprise: [\"GET /enterprises/{enterprise}/actions/permissions\"],\n    listSelectedOrganizationsEnabledGithubActionsEnterprise: [\"GET /enterprises/{enterprise}/actions/permissions/organizations\"],\n    setAllowedActionsEnterprise: [\"PUT /enterprises/{enterprise}/actions/permissions/selected-actions\"],\n    setGithubActionsPermissionsEnterprise: [\"PUT /enterprises/{enterprise}/actions/permissions\"],\n    setSelectedOrganizationsEnabledGithubActionsEnterprise: [\"PUT /enterprises/{enterprise}/actions/permissions/organizations\"]\n  },\n  gists: {\n    checkIsStarred: [\"GET /gists/{gist_id}/star\"],\n    create: [\"POST /gists\"],\n    createComment: [\"POST /gists/{gist_id}/comments\"],\n    delete: [\"DELETE /gists/{gist_id}\"],\n    deleteComment: [\"DELETE /gists/{gist_id}/comments/{comment_id}\"],\n    fork: [\"POST /gists/{gist_id}/forks\"],\n    get: [\"GET /gists/{gist_id}\"],\n    getComment: [\"GET /gists/{gist_id}/comments/{comment_id}\"],\n    getRevision: [\"GET /gists/{gist_id}/{sha}\"],\n    list: [\"GET /gists\"],\n    listComments: [\"GET /gists/{gist_id}/comments\"],\n    listCommits: [\"GET /gists/{gist_id}/commits\"],\n    listForUser: [\"GET /users/{username}/gists\"],\n    listForks: [\"GET /gists/{gist_id}/forks\"],\n    listPublic: [\"GET /gists/public\"],\n    listStarred: [\"GET /gists/starred\"],\n    star: [\"PUT /gists/{gist_id}/star\"],\n    unstar: [\"DELETE /gists/{gist_id}/star\"],\n    update: [\"PATCH /gists/{gist_id}\"],\n    updateComment: [\"PATCH /gists/{gist_id}/comments/{comment_id}\"]\n  },\n  git: {\n    createBlob: [\"POST /repos/{owner}/{repo}/git/blobs\"],\n    createCommit: [\"POST /repos/{owner}/{repo}/git/commits\"],\n    createRef: [\"POST /repos/{owner}/{repo}/git/refs\"],\n    createTag: [\"POST /repos/{owner}/{repo}/git/tags\"],\n    createTree: [\"POST /repos/{owner}/{repo}/git/trees\"],\n    deleteRef: [\"DELETE /repos/{owner}/{repo}/git/refs/{ref}\"],\n    getBlob: [\"GET /repos/{owner}/{repo}/git/blobs/{file_sha}\"],\n    getCommit: [\"GET /repos/{owner}/{repo}/git/commits/{commit_sha}\"],\n    getRef: [\"GET /repos/{owner}/{repo}/git/ref/{ref}\"],\n    getTag: [\"GET /repos/{owner}/{repo}/git/tags/{tag_sha}\"],\n    getTree: [\"GET /repos/{owner}/{repo}/git/trees/{tree_sha}\"],\n    listMatchingRefs: [\"GET /repos/{owner}/{repo}/git/matching-refs/{ref}\"],\n    updateRef: [\"PATCH /repos/{owner}/{repo}/git/refs/{ref}\"]\n  },\n  gitignore: {\n    getAllTemplates: [\"GET /gitignore/templates\"],\n    getTemplate: [\"GET /gitignore/templates/{name}\"]\n  },\n  interactions: {\n    getRestrictionsForAuthenticatedUser: [\"GET /user/interaction-limits\"],\n    getRestrictionsForOrg: [\"GET /orgs/{org}/interaction-limits\"],\n    getRestrictionsForRepo: [\"GET /repos/{owner}/{repo}/interaction-limits\"],\n    getRestrictionsForYourPublicRepos: [\"GET /user/interaction-limits\", {}, {\n      renamed: [\"interactions\", \"getRestrictionsForAuthenticatedUser\"]\n    }],\n    removeRestrictionsForAuthenticatedUser: [\"DELETE /user/interaction-limits\"],\n    removeRestrictionsForOrg: [\"DELETE /orgs/{org}/interaction-limits\"],\n    removeRestrictionsForRepo: [\"DELETE /repos/{owner}/{repo}/interaction-limits\"],\n    removeRestrictionsForYourPublicRepos: [\"DELETE /user/interaction-limits\", {}, {\n      renamed: [\"interactions\", \"removeRestrictionsForAuthenticatedUser\"]\n    }],\n    setRestrictionsForAuthenticatedUser: [\"PUT /user/interaction-limits\"],\n    setRestrictionsForOrg: [\"PUT /orgs/{org}/interaction-limits\"],\n    setRestrictionsForRepo: [\"PUT /repos/{owner}/{repo}/interaction-limits\"],\n    setRestrictionsForYourPublicRepos: [\"PUT /user/interaction-limits\", {}, {\n      renamed: [\"interactions\", \"setRestrictionsForAuthenticatedUser\"]\n    }]\n  },\n  issues: {\n    addAssignees: [\"POST /repos/{owner}/{repo}/issues/{issue_number}/assignees\"],\n    addLabels: [\"POST /repos/{owner}/{repo}/issues/{issue_number}/labels\"],\n    checkUserCanBeAssigned: [\"GET /repos/{owner}/{repo}/assignees/{assignee}\"],\n    create: [\"POST /repos/{owner}/{repo}/issues\"],\n    createComment: [\"POST /repos/{owner}/{repo}/issues/{issue_number}/comments\"],\n    createLabel: [\"POST /repos/{owner}/{repo}/labels\"],\n    createMilestone: [\"POST /repos/{owner}/{repo}/milestones\"],\n    deleteComment: [\"DELETE /repos/{owner}/{repo}/issues/comments/{comment_id}\"],\n    deleteLabel: [\"DELETE /repos/{owner}/{repo}/labels/{name}\"],\n    deleteMilestone: [\"DELETE /repos/{owner}/{repo}/milestones/{milestone_number}\"],\n    get: [\"GET /repos/{owner}/{repo}/issues/{issue_number}\"],\n    getComment: [\"GET /repos/{owner}/{repo}/issues/comments/{comment_id}\"],\n    getEvent: [\"GET /repos/{owner}/{repo}/issues/events/{event_id}\"],\n    getLabel: [\"GET /repos/{owner}/{repo}/labels/{name}\"],\n    getMilestone: [\"GET /repos/{owner}/{repo}/milestones/{milestone_number}\"],\n    list: [\"GET /issues\"],\n    listAssignees: [\"GET /repos/{owner}/{repo}/assignees\"],\n    listComments: [\"GET /repos/{owner}/{repo}/issues/{issue_number}/comments\"],\n    listCommentsForRepo: [\"GET /repos/{owner}/{repo}/issues/comments\"],\n    listEvents: [\"GET /repos/{owner}/{repo}/issues/{issue_number}/events\"],\n    listEventsForRepo: [\"GET /repos/{owner}/{repo}/issues/events\"],\n    listEventsForTimeline: [\"GET /repos/{owner}/{repo}/issues/{issue_number}/timeline\", {\n      mediaType: {\n        previews: [\"mockingbird\"]\n      }\n    }],\n    listForAuthenticatedUser: [\"GET /user/issues\"],\n    listForOrg: [\"GET /orgs/{org}/issues\"],\n    listForRepo: [\"GET /repos/{owner}/{repo}/issues\"],\n    listLabelsForMilestone: [\"GET /repos/{owner}/{repo}/milestones/{milestone_number}/labels\"],\n    listLabelsForRepo: [\"GET /repos/{owner}/{repo}/labels\"],\n    listLabelsOnIssue: [\"GET /repos/{owner}/{repo}/issues/{issue_number}/labels\"],\n    listMilestones: [\"GET /repos/{owner}/{repo}/milestones\"],\n    lock: [\"PUT /repos/{owner}/{repo}/issues/{issue_number}/lock\"],\n    removeAllLabels: [\"DELETE /repos/{owner}/{repo}/issues/{issue_number}/labels\"],\n    removeAssignees: [\"DELETE /repos/{owner}/{repo}/issues/{issue_number}/assignees\"],\n    removeLabel: [\"DELETE /repos/{owner}/{repo}/issues/{issue_number}/labels/{name}\"],\n    setLabels: [\"PUT /repos/{owner}/{repo}/issues/{issue_number}/labels\"],\n    unlock: [\"DELETE /repos/{owner}/{repo}/issues/{issue_number}/lock\"],\n    update: [\"PATCH /repos/{owner}/{repo}/issues/{issue_number}\"],\n    updateComment: [\"PATCH /repos/{owner}/{repo}/issues/comments/{comment_id}\"],\n    updateLabel: [\"PATCH /repos/{owner}/{repo}/labels/{name}\"],\n    updateMilestone: [\"PATCH /repos/{owner}/{repo}/milestones/{milestone_number}\"]\n  },\n  licenses: {\n    get: [\"GET /licenses/{license}\"],\n    getAllCommonlyUsed: [\"GET /licenses\"],\n    getForRepo: [\"GET /repos/{owner}/{repo}/license\"]\n  },\n  markdown: {\n    render: [\"POST /markdown\"],\n    renderRaw: [\"POST /markdown/raw\", {\n      headers: {\n        \"content-type\": \"text/plain; charset=utf-8\"\n      }\n    }]\n  },\n  meta: {\n    get: [\"GET /meta\"],\n    getOctocat: [\"GET /octocat\"],\n    getZen: [\"GET /zen\"],\n    root: [\"GET /\"]\n  },\n  migrations: {\n    cancelImport: [\"DELETE /repos/{owner}/{repo}/import\"],\n    deleteArchiveForAuthenticatedUser: [\"DELETE /user/migrations/{migration_id}/archive\", {\n      mediaType: {\n        previews: [\"wyandotte\"]\n      }\n    }],\n    deleteArchiveForOrg: [\"DELETE /orgs/{org}/migrations/{migration_id}/archive\", {\n      mediaType: {\n        previews: [\"wyandotte\"]\n      }\n    }],\n    downloadArchiveForOrg: [\"GET /orgs/{org}/migrations/{migration_id}/archive\", {\n      mediaType: {\n        previews: [\"wyandotte\"]\n      }\n    }],\n    getArchiveForAuthenticatedUser: [\"GET /user/migrations/{migration_id}/archive\", {\n      mediaType: {\n        previews: [\"wyandotte\"]\n      }\n    }],\n    getCommitAuthors: [\"GET /repos/{owner}/{repo}/import/authors\"],\n    getImportStatus: [\"GET /repos/{owner}/{repo}/import\"],\n    getLargeFiles: [\"GET /repos/{owner}/{repo}/import/large_files\"],\n    getStatusForAuthenticatedUser: [\"GET /user/migrations/{migration_id}\", {\n      mediaType: {\n        previews: [\"wyandotte\"]\n      }\n    }],\n    getStatusForOrg: [\"GET /orgs/{org}/migrations/{migration_id}\", {\n      mediaType: {\n        previews: [\"wyandotte\"]\n      }\n    }],\n    listForAuthenticatedUser: [\"GET /user/migrations\", {\n      mediaType: {\n        previews: [\"wyandotte\"]\n      }\n    }],\n    listForOrg: [\"GET /orgs/{org}/migrations\", {\n      mediaType: {\n        previews: [\"wyandotte\"]\n      }\n    }],\n    listReposForOrg: [\"GET /orgs/{org}/migrations/{migration_id}/repositories\", {\n      mediaType: {\n        previews: [\"wyandotte\"]\n      }\n    }],\n    listReposForUser: [\"GET /user/migrations/{migration_id}/repositories\", {\n      mediaType: {\n        previews: [\"wyandotte\"]\n      }\n    }],\n    mapCommitAuthor: [\"PATCH /repos/{owner}/{repo}/import/authors/{author_id}\"],\n    setLfsPreference: [\"PATCH /repos/{owner}/{repo}/import/lfs\"],\n    startForAuthenticatedUser: [\"POST /user/migrations\"],\n    startForOrg: [\"POST /orgs/{org}/migrations\"],\n    startImport: [\"PUT /repos/{owner}/{repo}/import\"],\n    unlockRepoForAuthenticatedUser: [\"DELETE /user/migrations/{migration_id}/repos/{repo_name}/lock\", {\n      mediaType: {\n        previews: [\"wyandotte\"]\n      }\n    }],\n    unlockRepoForOrg: [\"DELETE /orgs/{org}/migrations/{migration_id}/repos/{repo_name}/lock\", {\n      mediaType: {\n        previews: [\"wyandotte\"]\n      }\n    }],\n    updateImport: [\"PATCH /repos/{owner}/{repo}/import\"]\n  },\n  orgs: {\n    blockUser: [\"PUT /orgs/{org}/blocks/{username}\"],\n    cancelInvitation: [\"DELETE /orgs/{org}/invitations/{invitation_id}\"],\n    checkBlockedUser: [\"GET /orgs/{org}/blocks/{username}\"],\n    checkMembershipForUser: [\"GET /orgs/{org}/members/{username}\"],\n    checkPublicMembershipForUser: [\"GET /orgs/{org}/public_members/{username}\"],\n    convertMemberToOutsideCollaborator: [\"PUT /orgs/{org}/outside_collaborators/{username}\"],\n    createInvitation: [\"POST /orgs/{org}/invitations\"],\n    createWebhook: [\"POST /orgs/{org}/hooks\"],\n    deleteWebhook: [\"DELETE /orgs/{org}/hooks/{hook_id}\"],\n    get: [\"GET /orgs/{org}\"],\n    getMembershipForAuthenticatedUser: [\"GET /user/memberships/orgs/{org}\"],\n    getMembershipForUser: [\"GET /orgs/{org}/memberships/{username}\"],\n    getWebhook: [\"GET /orgs/{org}/hooks/{hook_id}\"],\n    getWebhookConfigForOrg: [\"GET /orgs/{org}/hooks/{hook_id}/config\"],\n    list: [\"GET /organizations\"],\n    listAppInstallations: [\"GET /orgs/{org}/installations\"],\n    listBlockedUsers: [\"GET /orgs/{org}/blocks\"],\n    listFailedInvitations: [\"GET /orgs/{org}/failed_invitations\"],\n    listForAuthenticatedUser: [\"GET /user/orgs\"],\n    listForUser: [\"GET /users/{username}/orgs\"],\n    listInvitationTeams: [\"GET /orgs/{org}/invitations/{invitation_id}/teams\"],\n    listMembers: [\"GET /orgs/{org}/members\"],\n    listMembershipsForAuthenticatedUser: [\"GET /user/memberships/orgs\"],\n    listOutsideCollaborators: [\"GET /orgs/{org}/outside_collaborators\"],\n    listPendingInvitations: [\"GET /orgs/{org}/invitations\"],\n    listPublicMembers: [\"GET /orgs/{org}/public_members\"],\n    listWebhooks: [\"GET /orgs/{org}/hooks\"],\n    pingWebhook: [\"POST /orgs/{org}/hooks/{hook_id}/pings\"],\n    removeMember: [\"DELETE /orgs/{org}/members/{username}\"],\n    removeMembershipForUser: [\"DELETE /orgs/{org}/memberships/{username}\"],\n    removeOutsideCollaborator: [\"DELETE /orgs/{org}/outside_collaborators/{username}\"],\n    removePublicMembershipForAuthenticatedUser: [\"DELETE /orgs/{org}/public_members/{username}\"],\n    setMembershipForUser: [\"PUT /orgs/{org}/memberships/{username}\"],\n    setPublicMembershipForAuthenticatedUser: [\"PUT /orgs/{org}/public_members/{username}\"],\n    unblockUser: [\"DELETE /orgs/{org}/blocks/{username}\"],\n    update: [\"PATCH /orgs/{org}\"],\n    updateMembershipForAuthenticatedUser: [\"PATCH /user/memberships/orgs/{org}\"],\n    updateWebhook: [\"PATCH /orgs/{org}/hooks/{hook_id}\"],\n    updateWebhookConfigForOrg: [\"PATCH /orgs/{org}/hooks/{hook_id}/config\"]\n  },\n  packages: {\n    deletePackageForAuthenticatedUser: [\"DELETE /user/packages/{package_type}/{package_name}\"],\n    deletePackageForOrg: [\"DELETE /orgs/{org}/packages/{package_type}/{package_name}\"],\n    deletePackageVersionForAuthenticatedUser: [\"DELETE /user/packages/{package_type}/{package_name}/versions/{package_version_id}\"],\n    deletePackageVersionForOrg: [\"DELETE /orgs/{org}/packages/{package_type}/{package_name}/versions/{package_version_id}\"],\n    getAllPackageVersionsForAPackageOwnedByAnOrg: [\"GET /orgs/{org}/packages/{package_type}/{package_name}/versions\", {}, {\n      renamed: [\"packages\", \"getAllPackageVersionsForPackageOwnedByOrg\"]\n    }],\n    getAllPackageVersionsForAPackageOwnedByTheAuthenticatedUser: [\"GET /user/packages/{package_type}/{package_name}/versions\", {}, {\n      renamed: [\"packages\", \"getAllPackageVersionsForPackageOwnedByAuthenticatedUser\"]\n    }],\n    getAllPackageVersionsForPackageOwnedByAuthenticatedUser: [\"GET /user/packages/{package_type}/{package_name}/versions\"],\n    getAllPackageVersionsForPackageOwnedByOrg: [\"GET /orgs/{org}/packages/{package_type}/{package_name}/versions\"],\n    getAllPackageVersionsForPackageOwnedByUser: [\"GET /users/{username}/packages/{package_type}/{package_name}/versions\"],\n    getPackageForAuthenticatedUser: [\"GET /user/packages/{package_type}/{package_name}\"],\n    getPackageForOrganization: [\"GET /orgs/{org}/packages/{package_type}/{package_name}\"],\n    getPackageForUser: [\"GET /users/{username}/packages/{package_type}/{package_name}\"],\n    getPackageVersionForAuthenticatedUser: [\"GET /user/packages/{package_type}/{package_name}/versions/{package_version_id}\"],\n    getPackageVersionForOrganization: [\"GET /orgs/{org}/packages/{package_type}/{package_name}/versions/{package_version_id}\"],\n    getPackageVersionForUser: [\"GET /users/{username}/packages/{package_type}/{package_name}/versions/{package_version_id}\"],\n    restorePackageForAuthenticatedUser: [\"POST /user/packages/{package_type}/{package_name}/restore{?token}\"],\n    restorePackageForOrg: [\"POST /orgs/{org}/packages/{package_type}/{package_name}/restore{?token}\"],\n    restorePackageVersionForAuthenticatedUser: [\"POST /user/packages/{package_type}/{package_name}/versions/{package_version_id}/restore\"],\n    restorePackageVersionForOrg: [\"POST /orgs/{org}/packages/{package_type}/{package_name}/versions/{package_version_id}/restore\"]\n  },\n  projects: {\n    addCollaborator: [\"PUT /projects/{project_id}/collaborators/{username}\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    createCard: [\"POST /projects/columns/{column_id}/cards\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    createColumn: [\"POST /projects/{project_id}/columns\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    createForAuthenticatedUser: [\"POST /user/projects\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    createForOrg: [\"POST /orgs/{org}/projects\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    createForRepo: [\"POST /repos/{owner}/{repo}/projects\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    delete: [\"DELETE /projects/{project_id}\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    deleteCard: [\"DELETE /projects/columns/cards/{card_id}\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    deleteColumn: [\"DELETE /projects/columns/{column_id}\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    get: [\"GET /projects/{project_id}\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    getCard: [\"GET /projects/columns/cards/{card_id}\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    getColumn: [\"GET /projects/columns/{column_id}\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    getPermissionForUser: [\"GET /projects/{project_id}/collaborators/{username}/permission\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    listCards: [\"GET /projects/columns/{column_id}/cards\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    listCollaborators: [\"GET /projects/{project_id}/collaborators\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    listColumns: [\"GET /projects/{project_id}/columns\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    listForOrg: [\"GET /orgs/{org}/projects\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    listForRepo: [\"GET /repos/{owner}/{repo}/projects\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    listForUser: [\"GET /users/{username}/projects\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    moveCard: [\"POST /projects/columns/cards/{card_id}/moves\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    moveColumn: [\"POST /projects/columns/{column_id}/moves\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    removeCollaborator: [\"DELETE /projects/{project_id}/collaborators/{username}\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    update: [\"PATCH /projects/{project_id}\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    updateCard: [\"PATCH /projects/columns/cards/{card_id}\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    updateColumn: [\"PATCH /projects/columns/{column_id}\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }]\n  },\n  pulls: {\n    checkIfMerged: [\"GET /repos/{owner}/{repo}/pulls/{pull_number}/merge\"],\n    create: [\"POST /repos/{owner}/{repo}/pulls\"],\n    createReplyForReviewComment: [\"POST /repos/{owner}/{repo}/pulls/{pull_number}/comments/{comment_id}/replies\"],\n    createReview: [\"POST /repos/{owner}/{repo}/pulls/{pull_number}/reviews\"],\n    createReviewComment: [\"POST /repos/{owner}/{repo}/pulls/{pull_number}/comments\"],\n    deletePendingReview: [\"DELETE /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}\"],\n    deleteReviewComment: [\"DELETE /repos/{owner}/{repo}/pulls/comments/{comment_id}\"],\n    dismissReview: [\"PUT /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}/dismissals\"],\n    get: [\"GET /repos/{owner}/{repo}/pulls/{pull_number}\"],\n    getReview: [\"GET /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}\"],\n    getReviewComment: [\"GET /repos/{owner}/{repo}/pulls/comments/{comment_id}\"],\n    list: [\"GET /repos/{owner}/{repo}/pulls\"],\n    listCommentsForReview: [\"GET /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}/comments\"],\n    listCommits: [\"GET /repos/{owner}/{repo}/pulls/{pull_number}/commits\"],\n    listFiles: [\"GET /repos/{owner}/{repo}/pulls/{pull_number}/files\"],\n    listRequestedReviewers: [\"GET /repos/{owner}/{repo}/pulls/{pull_number}/requested_reviewers\"],\n    listReviewComments: [\"GET /repos/{owner}/{repo}/pulls/{pull_number}/comments\"],\n    listReviewCommentsForRepo: [\"GET /repos/{owner}/{repo}/pulls/comments\"],\n    listReviews: [\"GET /repos/{owner}/{repo}/pulls/{pull_number}/reviews\"],\n    merge: [\"PUT /repos/{owner}/{repo}/pulls/{pull_number}/merge\"],\n    removeRequestedReviewers: [\"DELETE /repos/{owner}/{repo}/pulls/{pull_number}/requested_reviewers\"],\n    requestReviewers: [\"POST /repos/{owner}/{repo}/pulls/{pull_number}/requested_reviewers\"],\n    submitReview: [\"POST /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}/events\"],\n    update: [\"PATCH /repos/{owner}/{repo}/pulls/{pull_number}\"],\n    updateBranch: [\"PUT /repos/{owner}/{repo}/pulls/{pull_number}/update-branch\", {\n      mediaType: {\n        previews: [\"lydian\"]\n      }\n    }],\n    updateReview: [\"PUT /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}\"],\n    updateReviewComment: [\"PATCH /repos/{owner}/{repo}/pulls/comments/{comment_id}\"]\n  },\n  rateLimit: {\n    get: [\"GET /rate_limit\"]\n  },\n  reactions: {\n    createForCommitComment: [\"POST /repos/{owner}/{repo}/comments/{comment_id}/reactions\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    createForIssue: [\"POST /repos/{owner}/{repo}/issues/{issue_number}/reactions\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    createForIssueComment: [\"POST /repos/{owner}/{repo}/issues/comments/{comment_id}/reactions\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    createForPullRequestReviewComment: [\"POST /repos/{owner}/{repo}/pulls/comments/{comment_id}/reactions\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    createForRelease: [\"POST /repos/{owner}/{repo}/releases/{release_id}/reactions\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    createForTeamDiscussionCommentInOrg: [\"POST /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}/reactions\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    createForTeamDiscussionInOrg: [\"POST /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/reactions\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    deleteForCommitComment: [\"DELETE /repos/{owner}/{repo}/comments/{comment_id}/reactions/{reaction_id}\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    deleteForIssue: [\"DELETE /repos/{owner}/{repo}/issues/{issue_number}/reactions/{reaction_id}\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    deleteForIssueComment: [\"DELETE /repos/{owner}/{repo}/issues/comments/{comment_id}/reactions/{reaction_id}\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    deleteForPullRequestComment: [\"DELETE /repos/{owner}/{repo}/pulls/comments/{comment_id}/reactions/{reaction_id}\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    deleteForTeamDiscussion: [\"DELETE /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/reactions/{reaction_id}\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    deleteForTeamDiscussionComment: [\"DELETE /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}/reactions/{reaction_id}\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    deleteLegacy: [\"DELETE /reactions/{reaction_id}\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }, {\n      deprecated: \"octokit.rest.reactions.deleteLegacy() is deprecated, see https://docs.github.com/rest/reference/reactions/#delete-a-reaction-legacy\"\n    }],\n    listForCommitComment: [\"GET /repos/{owner}/{repo}/comments/{comment_id}/reactions\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    listForIssue: [\"GET /repos/{owner}/{repo}/issues/{issue_number}/reactions\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    listForIssueComment: [\"GET /repos/{owner}/{repo}/issues/comments/{comment_id}/reactions\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    listForPullRequestReviewComment: [\"GET /repos/{owner}/{repo}/pulls/comments/{comment_id}/reactions\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    listForTeamDiscussionCommentInOrg: [\"GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}/reactions\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }],\n    listForTeamDiscussionInOrg: [\"GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/reactions\", {\n      mediaType: {\n        previews: [\"squirrel-girl\"]\n      }\n    }]\n  },\n  repos: {\n    acceptInvitation: [\"PATCH /user/repository_invitations/{invitation_id}\"],\n    addAppAccessRestrictions: [\"POST /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/apps\", {}, {\n      mapToData: \"apps\"\n    }],\n    addCollaborator: [\"PUT /repos/{owner}/{repo}/collaborators/{username}\"],\n    addStatusCheckContexts: [\"POST /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks/contexts\", {}, {\n      mapToData: \"contexts\"\n    }],\n    addTeamAccessRestrictions: [\"POST /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/teams\", {}, {\n      mapToData: \"teams\"\n    }],\n    addUserAccessRestrictions: [\"POST /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/users\", {}, {\n      mapToData: \"users\"\n    }],\n    checkCollaborator: [\"GET /repos/{owner}/{repo}/collaborators/{username}\"],\n    checkVulnerabilityAlerts: [\"GET /repos/{owner}/{repo}/vulnerability-alerts\", {\n      mediaType: {\n        previews: [\"dorian\"]\n      }\n    }],\n    compareCommits: [\"GET /repos/{owner}/{repo}/compare/{base}...{head}\"],\n    compareCommitsWithBasehead: [\"GET /repos/{owner}/{repo}/compare/{basehead}\"],\n    createCommitComment: [\"POST /repos/{owner}/{repo}/commits/{commit_sha}/comments\"],\n    createCommitSignatureProtection: [\"POST /repos/{owner}/{repo}/branches/{branch}/protection/required_signatures\", {\n      mediaType: {\n        previews: [\"zzzax\"]\n      }\n    }],\n    createCommitStatus: [\"POST /repos/{owner}/{repo}/statuses/{sha}\"],\n    createDeployKey: [\"POST /repos/{owner}/{repo}/keys\"],\n    createDeployment: [\"POST /repos/{owner}/{repo}/deployments\"],\n    createDeploymentStatus: [\"POST /repos/{owner}/{repo}/deployments/{deployment_id}/statuses\"],\n    createDispatchEvent: [\"POST /repos/{owner}/{repo}/dispatches\"],\n    createForAuthenticatedUser: [\"POST /user/repos\"],\n    createFork: [\"POST /repos/{owner}/{repo}/forks\"],\n    createInOrg: [\"POST /orgs/{org}/repos\"],\n    createOrUpdateEnvironment: [\"PUT /repos/{owner}/{repo}/environments/{environment_name}\"],\n    createOrUpdateFileContents: [\"PUT /repos/{owner}/{repo}/contents/{path}\"],\n    createPagesSite: [\"POST /repos/{owner}/{repo}/pages\", {\n      mediaType: {\n        previews: [\"switcheroo\"]\n      }\n    }],\n    createRelease: [\"POST /repos/{owner}/{repo}/releases\"],\n    createUsingTemplate: [\"POST /repos/{template_owner}/{template_repo}/generate\", {\n      mediaType: {\n        previews: [\"baptiste\"]\n      }\n    }],\n    createWebhook: [\"POST /repos/{owner}/{repo}/hooks\"],\n    declineInvitation: [\"DELETE /user/repository_invitations/{invitation_id}\"],\n    delete: [\"DELETE /repos/{owner}/{repo}\"],\n    deleteAccessRestrictions: [\"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/restrictions\"],\n    deleteAdminBranchProtection: [\"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/enforce_admins\"],\n    deleteAnEnvironment: [\"DELETE /repos/{owner}/{repo}/environments/{environment_name}\"],\n    deleteBranchProtection: [\"DELETE /repos/{owner}/{repo}/branches/{branch}/protection\"],\n    deleteCommitComment: [\"DELETE /repos/{owner}/{repo}/comments/{comment_id}\"],\n    deleteCommitSignatureProtection: [\"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/required_signatures\", {\n      mediaType: {\n        previews: [\"zzzax\"]\n      }\n    }],\n    deleteDeployKey: [\"DELETE /repos/{owner}/{repo}/keys/{key_id}\"],\n    deleteDeployment: [\"DELETE /repos/{owner}/{repo}/deployments/{deployment_id}\"],\n    deleteFile: [\"DELETE /repos/{owner}/{repo}/contents/{path}\"],\n    deleteInvitation: [\"DELETE /repos/{owner}/{repo}/invitations/{invitation_id}\"],\n    deletePagesSite: [\"DELETE /repos/{owner}/{repo}/pages\", {\n      mediaType: {\n        previews: [\"switcheroo\"]\n      }\n    }],\n    deletePullRequestReviewProtection: [\"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/required_pull_request_reviews\"],\n    deleteRelease: [\"DELETE /repos/{owner}/{repo}/releases/{release_id}\"],\n    deleteReleaseAsset: [\"DELETE /repos/{owner}/{repo}/releases/assets/{asset_id}\"],\n    deleteWebhook: [\"DELETE /repos/{owner}/{repo}/hooks/{hook_id}\"],\n    disableAutomatedSecurityFixes: [\"DELETE /repos/{owner}/{repo}/automated-security-fixes\", {\n      mediaType: {\n        previews: [\"london\"]\n      }\n    }],\n    disableVulnerabilityAlerts: [\"DELETE /repos/{owner}/{repo}/vulnerability-alerts\", {\n      mediaType: {\n        previews: [\"dorian\"]\n      }\n    }],\n    downloadArchive: [\"GET /repos/{owner}/{repo}/zipball/{ref}\", {}, {\n      renamed: [\"repos\", \"downloadZipballArchive\"]\n    }],\n    downloadTarballArchive: [\"GET /repos/{owner}/{repo}/tarball/{ref}\"],\n    downloadZipballArchive: [\"GET /repos/{owner}/{repo}/zipball/{ref}\"],\n    enableAutomatedSecurityFixes: [\"PUT /repos/{owner}/{repo}/automated-security-fixes\", {\n      mediaType: {\n        previews: [\"london\"]\n      }\n    }],\n    enableVulnerabilityAlerts: [\"PUT /repos/{owner}/{repo}/vulnerability-alerts\", {\n      mediaType: {\n        previews: [\"dorian\"]\n      }\n    }],\n    get: [\"GET /repos/{owner}/{repo}\"],\n    getAccessRestrictions: [\"GET /repos/{owner}/{repo}/branches/{branch}/protection/restrictions\"],\n    getAdminBranchProtection: [\"GET /repos/{owner}/{repo}/branches/{branch}/protection/enforce_admins\"],\n    getAllEnvironments: [\"GET /repos/{owner}/{repo}/environments\"],\n    getAllStatusCheckContexts: [\"GET /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks/contexts\"],\n    getAllTopics: [\"GET /repos/{owner}/{repo}/topics\", {\n      mediaType: {\n        previews: [\"mercy\"]\n      }\n    }],\n    getAppsWithAccessToProtectedBranch: [\"GET /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/apps\"],\n    getBranch: [\"GET /repos/{owner}/{repo}/branches/{branch}\"],\n    getBranchProtection: [\"GET /repos/{owner}/{repo}/branches/{branch}/protection\"],\n    getClones: [\"GET /repos/{owner}/{repo}/traffic/clones\"],\n    getCodeFrequencyStats: [\"GET /repos/{owner}/{repo}/stats/code_frequency\"],\n    getCollaboratorPermissionLevel: [\"GET /repos/{owner}/{repo}/collaborators/{username}/permission\"],\n    getCombinedStatusForRef: [\"GET /repos/{owner}/{repo}/commits/{ref}/status\"],\n    getCommit: [\"GET /repos/{owner}/{repo}/commits/{ref}\"],\n    getCommitActivityStats: [\"GET /repos/{owner}/{repo}/stats/commit_activity\"],\n    getCommitComment: [\"GET /repos/{owner}/{repo}/comments/{comment_id}\"],\n    getCommitSignatureProtection: [\"GET /repos/{owner}/{repo}/branches/{branch}/protection/required_signatures\", {\n      mediaType: {\n        previews: [\"zzzax\"]\n      }\n    }],\n    getCommunityProfileMetrics: [\"GET /repos/{owner}/{repo}/community/profile\"],\n    getContent: [\"GET /repos/{owner}/{repo}/contents/{path}\"],\n    getContributorsStats: [\"GET /repos/{owner}/{repo}/stats/contributors\"],\n    getDeployKey: [\"GET /repos/{owner}/{repo}/keys/{key_id}\"],\n    getDeployment: [\"GET /repos/{owner}/{repo}/deployments/{deployment_id}\"],\n    getDeploymentStatus: [\"GET /repos/{owner}/{repo}/deployments/{deployment_id}/statuses/{status_id}\"],\n    getEnvironment: [\"GET /repos/{owner}/{repo}/environments/{environment_name}\"],\n    getLatestPagesBuild: [\"GET /repos/{owner}/{repo}/pages/builds/latest\"],\n    getLatestRelease: [\"GET /repos/{owner}/{repo}/releases/latest\"],\n    getPages: [\"GET /repos/{owner}/{repo}/pages\"],\n    getPagesBuild: [\"GET /repos/{owner}/{repo}/pages/builds/{build_id}\"],\n    getPagesHealthCheck: [\"GET /repos/{owner}/{repo}/pages/health\"],\n    getParticipationStats: [\"GET /repos/{owner}/{repo}/stats/participation\"],\n    getPullRequestReviewProtection: [\"GET /repos/{owner}/{repo}/branches/{branch}/protection/required_pull_request_reviews\"],\n    getPunchCardStats: [\"GET /repos/{owner}/{repo}/stats/punch_card\"],\n    getReadme: [\"GET /repos/{owner}/{repo}/readme\"],\n    getReadmeInDirectory: [\"GET /repos/{owner}/{repo}/readme/{dir}\"],\n    getRelease: [\"GET /repos/{owner}/{repo}/releases/{release_id}\"],\n    getReleaseAsset: [\"GET /repos/{owner}/{repo}/releases/assets/{asset_id}\"],\n    getReleaseByTag: [\"GET /repos/{owner}/{repo}/releases/tags/{tag}\"],\n    getStatusChecksProtection: [\"GET /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks\"],\n    getTeamsWithAccessToProtectedBranch: [\"GET /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/teams\"],\n    getTopPaths: [\"GET /repos/{owner}/{repo}/traffic/popular/paths\"],\n    getTopReferrers: [\"GET /repos/{owner}/{repo}/traffic/popular/referrers\"],\n    getUsersWithAccessToProtectedBranch: [\"GET /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/users\"],\n    getViews: [\"GET /repos/{owner}/{repo}/traffic/views\"],\n    getWebhook: [\"GET /repos/{owner}/{repo}/hooks/{hook_id}\"],\n    getWebhookConfigForRepo: [\"GET /repos/{owner}/{repo}/hooks/{hook_id}/config\"],\n    listBranches: [\"GET /repos/{owner}/{repo}/branches\"],\n    listBranchesForHeadCommit: [\"GET /repos/{owner}/{repo}/commits/{commit_sha}/branches-where-head\", {\n      mediaType: {\n        previews: [\"groot\"]\n      }\n    }],\n    listCollaborators: [\"GET /repos/{owner}/{repo}/collaborators\"],\n    listCommentsForCommit: [\"GET /repos/{owner}/{repo}/commits/{commit_sha}/comments\"],\n    listCommitCommentsForRepo: [\"GET /repos/{owner}/{repo}/comments\"],\n    listCommitStatusesForRef: [\"GET /repos/{owner}/{repo}/commits/{ref}/statuses\"],\n    listCommits: [\"GET /repos/{owner}/{repo}/commits\"],\n    listContributors: [\"GET /repos/{owner}/{repo}/contributors\"],\n    listDeployKeys: [\"GET /repos/{owner}/{repo}/keys\"],\n    listDeploymentStatuses: [\"GET /repos/{owner}/{repo}/deployments/{deployment_id}/statuses\"],\n    listDeployments: [\"GET /repos/{owner}/{repo}/deployments\"],\n    listForAuthenticatedUser: [\"GET /user/repos\"],\n    listForOrg: [\"GET /orgs/{org}/repos\"],\n    listForUser: [\"GET /users/{username}/repos\"],\n    listForks: [\"GET /repos/{owner}/{repo}/forks\"],\n    listInvitations: [\"GET /repos/{owner}/{repo}/invitations\"],\n    listInvitationsForAuthenticatedUser: [\"GET /user/repository_invitations\"],\n    listLanguages: [\"GET /repos/{owner}/{repo}/languages\"],\n    listPagesBuilds: [\"GET /repos/{owner}/{repo}/pages/builds\"],\n    listPublic: [\"GET /repositories\"],\n    listPullRequestsAssociatedWithCommit: [\"GET /repos/{owner}/{repo}/commits/{commit_sha}/pulls\", {\n      mediaType: {\n        previews: [\"groot\"]\n      }\n    }],\n    listReleaseAssets: [\"GET /repos/{owner}/{repo}/releases/{release_id}/assets\"],\n    listReleases: [\"GET /repos/{owner}/{repo}/releases\"],\n    listTags: [\"GET /repos/{owner}/{repo}/tags\"],\n    listTeams: [\"GET /repos/{owner}/{repo}/teams\"],\n    listWebhooks: [\"GET /repos/{owner}/{repo}/hooks\"],\n    merge: [\"POST /repos/{owner}/{repo}/merges\"],\n    pingWebhook: [\"POST /repos/{owner}/{repo}/hooks/{hook_id}/pings\"],\n    removeAppAccessRestrictions: [\"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/apps\", {}, {\n      mapToData: \"apps\"\n    }],\n    removeCollaborator: [\"DELETE /repos/{owner}/{repo}/collaborators/{username}\"],\n    removeStatusCheckContexts: [\"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks/contexts\", {}, {\n      mapToData: \"contexts\"\n    }],\n    removeStatusCheckProtection: [\"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks\"],\n    removeTeamAccessRestrictions: [\"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/teams\", {}, {\n      mapToData: \"teams\"\n    }],\n    removeUserAccessRestrictions: [\"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/users\", {}, {\n      mapToData: \"users\"\n    }],\n    renameBranch: [\"POST /repos/{owner}/{repo}/branches/{branch}/rename\"],\n    replaceAllTopics: [\"PUT /repos/{owner}/{repo}/topics\", {\n      mediaType: {\n        previews: [\"mercy\"]\n      }\n    }],\n    requestPagesBuild: [\"POST /repos/{owner}/{repo}/pages/builds\"],\n    setAdminBranchProtection: [\"POST /repos/{owner}/{repo}/branches/{branch}/protection/enforce_admins\"],\n    setAppAccessRestrictions: [\"PUT /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/apps\", {}, {\n      mapToData: \"apps\"\n    }],\n    setStatusCheckContexts: [\"PUT /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks/contexts\", {}, {\n      mapToData: \"contexts\"\n    }],\n    setTeamAccessRestrictions: [\"PUT /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/teams\", {}, {\n      mapToData: \"teams\"\n    }],\n    setUserAccessRestrictions: [\"PUT /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/users\", {}, {\n      mapToData: \"users\"\n    }],\n    testPushWebhook: [\"POST /repos/{owner}/{repo}/hooks/{hook_id}/tests\"],\n    transfer: [\"POST /repos/{owner}/{repo}/transfer\"],\n    update: [\"PATCH /repos/{owner}/{repo}\"],\n    updateBranchProtection: [\"PUT /repos/{owner}/{repo}/branches/{branch}/protection\"],\n    updateCommitComment: [\"PATCH /repos/{owner}/{repo}/comments/{comment_id}\"],\n    updateInformationAboutPagesSite: [\"PUT /repos/{owner}/{repo}/pages\"],\n    updateInvitation: [\"PATCH /repos/{owner}/{repo}/invitations/{invitation_id}\"],\n    updatePullRequestReviewProtection: [\"PATCH /repos/{owner}/{repo}/branches/{branch}/protection/required_pull_request_reviews\"],\n    updateRelease: [\"PATCH /repos/{owner}/{repo}/releases/{release_id}\"],\n    updateReleaseAsset: [\"PATCH /repos/{owner}/{repo}/releases/assets/{asset_id}\"],\n    updateStatusCheckPotection: [\"PATCH /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks\", {}, {\n      renamed: [\"repos\", \"updateStatusCheckProtection\"]\n    }],\n    updateStatusCheckProtection: [\"PATCH /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks\"],\n    updateWebhook: [\"PATCH /repos/{owner}/{repo}/hooks/{hook_id}\"],\n    updateWebhookConfigForRepo: [\"PATCH /repos/{owner}/{repo}/hooks/{hook_id}/config\"],\n    uploadReleaseAsset: [\"POST /repos/{owner}/{repo}/releases/{release_id}/assets{?name,label}\", {\n      baseUrl: \"https://uploads.github.com\"\n    }]\n  },\n  search: {\n    code: [\"GET /search/code\"],\n    commits: [\"GET /search/commits\", {\n      mediaType: {\n        previews: [\"cloak\"]\n      }\n    }],\n    issuesAndPullRequests: [\"GET /search/issues\"],\n    labels: [\"GET /search/labels\"],\n    repos: [\"GET /search/repositories\"],\n    topics: [\"GET /search/topics\", {\n      mediaType: {\n        previews: [\"mercy\"]\n      }\n    }],\n    users: [\"GET /search/users\"]\n  },\n  secretScanning: {\n    getAlert: [\"GET /repos/{owner}/{repo}/secret-scanning/alerts/{alert_number}\"],\n    listAlertsForRepo: [\"GET /repos/{owner}/{repo}/secret-scanning/alerts\"],\n    updateAlert: [\"PATCH /repos/{owner}/{repo}/secret-scanning/alerts/{alert_number}\"]\n  },\n  teams: {\n    addOrUpdateMembershipForUserInOrg: [\"PUT /orgs/{org}/teams/{team_slug}/memberships/{username}\"],\n    addOrUpdateProjectPermissionsInOrg: [\"PUT /orgs/{org}/teams/{team_slug}/projects/{project_id}\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    addOrUpdateRepoPermissionsInOrg: [\"PUT /orgs/{org}/teams/{team_slug}/repos/{owner}/{repo}\"],\n    checkPermissionsForProjectInOrg: [\"GET /orgs/{org}/teams/{team_slug}/projects/{project_id}\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    checkPermissionsForRepoInOrg: [\"GET /orgs/{org}/teams/{team_slug}/repos/{owner}/{repo}\"],\n    create: [\"POST /orgs/{org}/teams\"],\n    createDiscussionCommentInOrg: [\"POST /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments\"],\n    createDiscussionInOrg: [\"POST /orgs/{org}/teams/{team_slug}/discussions\"],\n    deleteDiscussionCommentInOrg: [\"DELETE /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}\"],\n    deleteDiscussionInOrg: [\"DELETE /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}\"],\n    deleteInOrg: [\"DELETE /orgs/{org}/teams/{team_slug}\"],\n    getByName: [\"GET /orgs/{org}/teams/{team_slug}\"],\n    getDiscussionCommentInOrg: [\"GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}\"],\n    getDiscussionInOrg: [\"GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}\"],\n    getMembershipForUserInOrg: [\"GET /orgs/{org}/teams/{team_slug}/memberships/{username}\"],\n    list: [\"GET /orgs/{org}/teams\"],\n    listChildInOrg: [\"GET /orgs/{org}/teams/{team_slug}/teams\"],\n    listDiscussionCommentsInOrg: [\"GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments\"],\n    listDiscussionsInOrg: [\"GET /orgs/{org}/teams/{team_slug}/discussions\"],\n    listForAuthenticatedUser: [\"GET /user/teams\"],\n    listMembersInOrg: [\"GET /orgs/{org}/teams/{team_slug}/members\"],\n    listPendingInvitationsInOrg: [\"GET /orgs/{org}/teams/{team_slug}/invitations\"],\n    listProjectsInOrg: [\"GET /orgs/{org}/teams/{team_slug}/projects\", {\n      mediaType: {\n        previews: [\"inertia\"]\n      }\n    }],\n    listReposInOrg: [\"GET /orgs/{org}/teams/{team_slug}/repos\"],\n    removeMembershipForUserInOrg: [\"DELETE /orgs/{org}/teams/{team_slug}/memberships/{username}\"],\n    removeProjectInOrg: [\"DELETE /orgs/{org}/teams/{team_slug}/projects/{project_id}\"],\n    removeRepoInOrg: [\"DELETE /orgs/{org}/teams/{team_slug}/repos/{owner}/{repo}\"],\n    updateDiscussionCommentInOrg: [\"PATCH /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}\"],\n    updateDiscussionInOrg: [\"PATCH /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}\"],\n    updateInOrg: [\"PATCH /orgs/{org}/teams/{team_slug}\"]\n  },\n  users: {\n    addEmailForAuthenticated: [\"POST /user/emails\"],\n    block: [\"PUT /user/blocks/{username}\"],\n    checkBlocked: [\"GET /user/blocks/{username}\"],\n    checkFollowingForUser: [\"GET /users/{username}/following/{target_user}\"],\n    checkPersonIsFollowedByAuthenticated: [\"GET /user/following/{username}\"],\n    createGpgKeyForAuthenticated: [\"POST /user/gpg_keys\"],\n    createPublicSshKeyForAuthenticated: [\"POST /user/keys\"],\n    deleteEmailForAuthenticated: [\"DELETE /user/emails\"],\n    deleteGpgKeyForAuthenticated: [\"DELETE /user/gpg_keys/{gpg_key_id}\"],\n    deletePublicSshKeyForAuthenticated: [\"DELETE /user/keys/{key_id}\"],\n    follow: [\"PUT /user/following/{username}\"],\n    getAuthenticated: [\"GET /user\"],\n    getByUsername: [\"GET /users/{username}\"],\n    getContextForUser: [\"GET /users/{username}/hovercard\"],\n    getGpgKeyForAuthenticated: [\"GET /user/gpg_keys/{gpg_key_id}\"],\n    getPublicSshKeyForAuthenticated: [\"GET /user/keys/{key_id}\"],\n    list: [\"GET /users\"],\n    listBlockedByAuthenticated: [\"GET /user/blocks\"],\n    listEmailsForAuthenticated: [\"GET /user/emails\"],\n    listFollowedByAuthenticated: [\"GET /user/following\"],\n    listFollowersForAuthenticatedUser: [\"GET /user/followers\"],\n    listFollowersForUser: [\"GET /users/{username}/followers\"],\n    listFollowingForUser: [\"GET /users/{username}/following\"],\n    listGpgKeysForAuthenticated: [\"GET /user/gpg_keys\"],\n    listGpgKeysForUser: [\"GET /users/{username}/gpg_keys\"],\n    listPublicEmailsForAuthenticated: [\"GET /user/public_emails\"],\n    listPublicKeysForUser: [\"GET /users/{username}/keys\"],\n    listPublicSshKeysForAuthenticated: [\"GET /user/keys\"],\n    setPrimaryEmailVisibilityForAuthenticated: [\"PATCH /user/email/visibility\"],\n    unblock: [\"DELETE /user/blocks/{username}\"],\n    unfollow: [\"DELETE /user/following/{username}\"],\n    updateAuthenticated: [\"PATCH /user\"]\n  }\n};\n\nconst VERSION = \"5.3.1\";\n\nfunction endpointsToMethods(octokit, endpointsMap) {\n  const newMethods = {};\n\n  for (const [scope, endpoints] of Object.entries(endpointsMap)) {\n    for (const [methodName, endpoint] of Object.entries(endpoints)) {\n      const [route, defaults, decorations] = endpoint;\n      const [method, url] = route.split(/ /);\n      const endpointDefaults = Object.assign({\n        method,\n        url\n      }, defaults);\n\n      if (!newMethods[scope]) {\n        newMethods[scope] = {};\n      }\n\n      const scopeMethods = newMethods[scope];\n\n      if (decorations) {\n        scopeMethods[methodName] = decorate(octokit, scope, methodName, endpointDefaults, decorations);\n        continue;\n      }\n\n      scopeMethods[methodName] = octokit.request.defaults(endpointDefaults);\n    }\n  }\n\n  return newMethods;\n}\n\nfunction decorate(octokit, scope, methodName, defaults, decorations) {\n  const requestWithDefaults = octokit.request.defaults(defaults);\n  /* istanbul ignore next */\n\n  function withDecorations(...args) {\n    // @ts-ignore https://github.com/microsoft/TypeScript/issues/25488\n    let options = requestWithDefaults.endpoint.merge(...args); // There are currently no other decorations than `.mapToData`\n\n    if (decorations.mapToData) {\n      options = Object.assign({}, options, {\n        data: options[decorations.mapToData],\n        [decorations.mapToData]: undefined\n      });\n      return requestWithDefaults(options);\n    }\n\n    if (decorations.renamed) {\n      const [newScope, newMethodName] = decorations.renamed;\n      octokit.log.warn(`octokit.${scope}.${methodName}() has been renamed to octokit.${newScope}.${newMethodName}()`);\n    }\n\n    if (decorations.deprecated) {\n      octokit.log.warn(decorations.deprecated);\n    }\n\n    if (decorations.renamedParameters) {\n      // @ts-ignore https://github.com/microsoft/TypeScript/issues/25488\n      const options = requestWithDefaults.endpoint.merge(...args);\n\n      for (const [name, alias] of Object.entries(decorations.renamedParameters)) {\n        if (name in options) {\n          octokit.log.warn(`\"${name}\" parameter is deprecated for \"octokit.${scope}.${methodName}()\". Use \"${alias}\" instead`);\n\n          if (!(alias in options)) {\n            options[alias] = options[name];\n          }\n\n          delete options[name];\n        }\n      }\n\n      return requestWithDefaults(options);\n    } // @ts-ignore https://github.com/microsoft/TypeScript/issues/25488\n\n\n    return requestWithDefaults(...args);\n  }\n\n  return Object.assign(withDecorations, requestWithDefaults);\n}\n\nfunction restEndpointMethods(octokit) {\n  const api = endpointsToMethods(octokit, Endpoints);\n  return {\n    rest: api\n  };\n}\nrestEndpointMethods.VERSION = VERSION;\nfunction legacyRestEndpointMethods(octokit) {\n  const api = endpointsToMethods(octokit, Endpoints);\n  return _objectSpread2(_objectSpread2({}, api), {}, {\n    rest: api\n  });\n}\nlegacyRestEndpointMethods.VERSION = VERSION;\n\nexports.legacyRestEndpointMethods = legacyRestEndpointMethods;\nexports.restEndpointMethods = restEndpointMethods;\n//# sourceMappingURL=index.js.map\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nfunction _interopDefault (ex) { return (ex && (typeof ex === 'object') && 'default' in ex) ? ex['default'] : ex; }\n\nvar deprecation = require('deprecation');\nvar once = _interopDefault(require('once'));\n\nconst logOnce = once(deprecation => console.warn(deprecation));\n/**\n * Error with extra properties to help with debugging\n */\n\nclass RequestError extends Error {\n  constructor(message, statusCode, options) {\n    super(message); // Maintains proper stack trace (only available on V8)\n\n    /* istanbul ignore next */\n\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, this.constructor);\n    }\n\n    this.name = \"HttpError\";\n    this.status = statusCode;\n    Object.defineProperty(this, \"code\", {\n      get() {\n        logOnce(new deprecation.Deprecation(\"[@octokit/request-error] `error.code` is deprecated, use `error.status`.\"));\n        return statusCode;\n      }\n\n    });\n    this.headers = options.headers || {}; // redact request credentials without mutating original request options\n\n    const requestCopy = Object.assign({}, options.request);\n\n    if (options.request.headers.authorization) {\n      requestCopy.headers = Object.assign({}, options.request.headers, {\n        authorization: options.request.headers.authorization.replace(/ .*$/, \" [REDACTED]\")\n      });\n    }\n\n    requestCopy.url = requestCopy.url // client_id & client_secret can be passed as URL query parameters to increase rate limit\n    // see https://developer.github.com/v3/#increasing-the-unauthenticated-rate-limit-for-oauth-applications\n    .replace(/\\bclient_secret=\\w+/g, \"client_secret=[REDACTED]\") // OAuth tokens can be passed as URL query parameters, although it is not recommended\n    // see https://developer.github.com/v3/#oauth2-token-sent-in-a-header\n    .replace(/\\baccess_token=\\w+/g, \"access_token=[REDACTED]\");\n    this.request = requestCopy;\n  }\n\n}\n\nexports.RequestError = RequestError;\n//# sourceMappingURL=index.js.map\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nfunction _interopDefault (ex) { return (ex && (typeof ex === 'object') && 'default' in ex) ? ex['default'] : ex; }\n\nvar endpoint = require('@octokit/endpoint');\nvar universalUserAgent = require('universal-user-agent');\nvar isPlainObject = require('is-plain-object');\nvar nodeFetch = _interopDefault(require('node-fetch'));\nvar requestError = require('@octokit/request-error');\n\nconst VERSION = \"5.5.0\";\n\nfunction getBufferResponse(response) {\n  return response.arrayBuffer();\n}\n\nfunction fetchWrapper(requestOptions) {\n  const log = requestOptions.request && requestOptions.request.log ? requestOptions.request.log : console;\n\n  if (isPlainObject.isPlainObject(requestOptions.body) || Array.isArray(requestOptions.body)) {\n    requestOptions.body = JSON.stringify(requestOptions.body);\n  }\n\n  let headers = {};\n  let status;\n  let url;\n  const fetch = requestOptions.request && requestOptions.request.fetch || nodeFetch;\n  return fetch(requestOptions.url, Object.assign({\n    method: requestOptions.method,\n    body: requestOptions.body,\n    headers: requestOptions.headers,\n    redirect: requestOptions.redirect\n  }, // `requestOptions.request.agent` type is incompatible\n  // see https://github.com/octokit/types.ts/pull/264\n  requestOptions.request)).then(response => {\n    url = response.url;\n    status = response.status;\n\n    for (const keyAndValue of response.headers) {\n      headers[keyAndValue[0]] = keyAndValue[1];\n    }\n\n    if (\"deprecation\" in headers) {\n      const matches = headers.link && headers.link.match(/<([^>]+)>; rel=\"deprecation\"/);\n      const deprecationLink = matches && matches.pop();\n      log.warn(`[@octokit/request] \"${requestOptions.method} ${requestOptions.url}\" is deprecated. It is scheduled to be removed on ${headers.sunset}${deprecationLink ? `. See ${deprecationLink}` : \"\"}`);\n    }\n\n    if (status === 204 || status === 205) {\n      return;\n    } // GitHub API returns 200 for HEAD requests\n\n\n    if (requestOptions.method === \"HEAD\") {\n      if (status < 400) {\n        return;\n      }\n\n      throw new requestError.RequestError(response.statusText, status, {\n        headers,\n        request: requestOptions\n      });\n    }\n\n    if (status === 304) {\n      throw new requestError.RequestError(\"Not modified\", status, {\n        headers,\n        request: requestOptions\n      });\n    }\n\n    if (status >= 400) {\n      return response.text().then(message => {\n        const error = new requestError.RequestError(message, status, {\n          headers,\n          request: requestOptions\n        });\n\n        try {\n          let responseBody = JSON.parse(error.message);\n          Object.assign(error, responseBody);\n          let errors = responseBody.errors; // Assumption `errors` would always be in Array format\n\n          error.message = error.message + \": \" + errors.map(JSON.stringify).join(\", \");\n        } catch (e) {// ignore, see octokit/rest.js#684\n        }\n\n        throw error;\n      });\n    }\n\n    const contentType = response.headers.get(\"content-type\");\n\n    if (/application\\/json/.test(contentType)) {\n      return response.json();\n    }\n\n    if (!contentType || /^text\\/|charset=utf-8$/.test(contentType)) {\n      return response.text();\n    }\n\n    return getBufferResponse(response);\n  }).then(data => {\n    return {\n      status,\n      url,\n      headers,\n      data\n    };\n  }).catch(error => {\n    if (error instanceof requestError.RequestError) {\n      throw error;\n    }\n\n    throw new requestError.RequestError(error.message, 500, {\n      headers,\n      request: requestOptions\n    });\n  });\n}\n\nfunction withDefaults(oldEndpoint, newDefaults) {\n  const endpoint = oldEndpoint.defaults(newDefaults);\n\n  const newApi = function (route, parameters) {\n    const endpointOptions = endpoint.merge(route, parameters);\n\n    if (!endpointOptions.request || !endpointOptions.request.hook) {\n      return fetchWrapper(endpoint.parse(endpointOptions));\n    }\n\n    const request = (route, parameters) => {\n      return fetchWrapper(endpoint.parse(endpoint.merge(route, parameters)));\n    };\n\n    Object.assign(request, {\n      endpoint,\n      defaults: withDefaults.bind(null, endpoint)\n    });\n    return endpointOptions.request.hook(request, endpointOptions);\n  };\n\n  return Object.assign(newApi, {\n    endpoint,\n    defaults: withDefaults.bind(null, endpoint)\n  });\n}\n\nconst request = withDefaults(endpoint.endpoint, {\n  headers: {\n    \"user-agent\": `octokit-request.js/${VERSION} ${universalUserAgent.getUserAgent()}`\n  }\n});\n\nexports.request = request;\n//# sourceMappingURL=index.js.map\n","const Utils = require(\"./util\");\r\nconst pth = require(\"path\");\r\nconst ZipEntry = require(\"./zipEntry\");\r\nconst ZipFile = require(\"./zipFile\");\r\n\r\nconst fs = Utils.FileSystem.require();\r\nfs.existsSync = fs.existsSync || pth.existsSync;\r\n\r\nconst defaultOptions = {\r\n    // read entries during load (initial loading may be slower)\r\n    readEntries: false,\r\n    // default method is none\r\n    method: Utils.Constants.NONE\r\n}\r\n\r\nfunction canonical(p) {\r\n    // trick normalize think path is absolute\r\n    var safeSuffix = pth.posix.normalize(\"/\" + p.split(\"\\\\\").join(\"/\"));\r\n    return pth.join(\".\", safeSuffix);\r\n}\r\n\r\nmodule.exports = function (/**String*/input, /** object */options) {\r\n    let inBuffer = null;\r\n\r\n    // create object based default options, allowing them to be overwritten\r\n    const opts = Object.assign(Object.create( null ), defaultOptions);\r\n\r\n    // test input variable\r\n    if (input && \"object\" === typeof input){\r\n        // if value is not buffer we accept it to be object with options\r\n        if (!(input instanceof Uint8Array)){\r\n            Object.assign(opts, input);\r\n            input = opts.input ? opts.input : undefined;\r\n            if (opts.input) delete opts.input;\r\n        }\r\n\r\n        // if input is buffer\r\n        if (input instanceof Uint8Array){\r\n            inBuffer = input;\r\n            opts.method = Utils.Constants.BUFFER;\r\n            input = undefined;\r\n        }\r\n    }\r\n\r\n    // assign options\r\n    Object.assign(opts, options);\r\n\r\n    // if input is file name we retrieve its content\r\n    if (input && \"string\" === typeof input) {\r\n        // load zip file\r\n        if (fs.existsSync(input)) {\r\n            opts.method = Utils.Constants.FILE;\r\n            opts.filename = input;\r\n            inBuffer = fs.readFileSync(input);\r\n        } else {\r\n            throw new Error(Utils.Errors.INVALID_FILENAME);\r\n        }\r\n    }\r\n\r\n    // create variable\r\n    const _zip = new ZipFile(inBuffer, opts);\r\n\r\n    function sanitize(prefix, name) {\r\n        prefix = pth.resolve(pth.normalize(prefix));\r\n        var parts = name.split('/');\r\n        for (var i = 0, l = parts.length; i < l; i++) {\r\n            var path = pth.normalize(pth.join(prefix, parts.slice(i, l).join(pth.sep)));\r\n            if (path.indexOf(prefix) === 0) {\r\n                return path;\r\n            }\r\n        }\r\n        return pth.normalize(pth.join(prefix, pth.basename(name)));\r\n    }\r\n\r\n\tfunction getEntry(/**Object*/entry) {\r\n\t\tif (entry && _zip) {\r\n\t\t\tvar item;\r\n\t\t\t// If entry was given as a file name\r\n\t\t\tif (typeof entry === \"string\")\r\n\t\t\t\titem = _zip.getEntry(entry);\r\n\t\t\t// if entry was given as a ZipEntry object\r\n\t\t\tif (typeof entry === \"object\" && typeof entry.entryName !== \"undefined\" && typeof entry.header !== \"undefined\")\r\n\t\t\t\titem = _zip.getEntry(entry.entryName);\r\n\r\n\t\t\tif (item) {\r\n\t\t\t\treturn item;\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn null;\r\n\t}\r\n\r\n    function fixPath(zipPath){\r\n        const { join, normalize, sep } = pth.posix;\r\n        // convert windows file separators and normalize\r\n        return join(\".\", normalize(sep + zipPath.split(\"\\\\\").join(sep) + sep));\r\n    }\r\n\r\n\treturn {\r\n\t\t/**\r\n\t\t * Extracts the given entry from the archive and returns the content as a Buffer object\r\n\t\t * @param entry ZipEntry object or String with the full path of the entry\r\n\t\t *\r\n\t\t * @return Buffer or Null in case of error\r\n\t\t */\r\n\t\treadFile: function (/**Object*/entry, /*String, Buffer*/pass) {\r\n\t\t\tvar item = getEntry(entry);\r\n\t\t\treturn item && item.getData(pass) || null;\r\n\t\t},\r\n\r\n\t\t/**\r\n\t\t * Asynchronous readFile\r\n\t\t * @param entry ZipEntry object or String with the full path of the entry\r\n\t\t * @param callback\r\n\t\t *\r\n\t\t * @return Buffer or Null in case of error\r\n\t\t */\r\n\t\treadFileAsync: function (/**Object*/entry, /**Function*/callback) {\r\n\t\t\tvar item = getEntry(entry);\r\n\t\t\tif (item) {\r\n\t\t\t\titem.getDataAsync(callback);\r\n\t\t\t} else {\r\n\t\t\t\tcallback(null, \"getEntry failed for:\" + entry)\r\n\t\t\t}\r\n\t\t},\r\n\r\n\t\t/**\r\n\t\t * Extracts the given entry from the archive and returns the content as plain text in the given encoding\r\n\t\t * @param entry ZipEntry object or String with the full path of the entry\r\n\t\t * @param encoding Optional. If no encoding is specified utf8 is used\r\n\t\t *\r\n\t\t * @return String\r\n\t\t */\r\n\t\treadAsText: function (/**Object*/entry, /**String=*/encoding) {\r\n\t\t\tvar item = getEntry(entry);\r\n\t\t\tif (item) {\r\n\t\t\t\tvar data = item.getData();\r\n\t\t\t\tif (data && data.length) {\r\n\t\t\t\t\treturn data.toString(encoding || \"utf8\");\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\treturn \"\";\r\n\t\t},\r\n\r\n\t\t/**\r\n\t\t * Asynchronous readAsText\r\n\t\t * @param entry ZipEntry object or String with the full path of the entry\r\n\t\t * @param callback\r\n\t\t * @param encoding Optional. If no encoding is specified utf8 is used\r\n\t\t *\r\n\t\t * @return String\r\n\t\t */\r\n\t\treadAsTextAsync: function (/**Object*/entry, /**Function*/callback, /**String=*/encoding) {\r\n\t\t\tvar item = getEntry(entry);\r\n\t\t\tif (item) {\r\n\t\t\t\titem.getDataAsync(function (data, err) {\r\n\t\t\t\t\tif (err) {\r\n\t\t\t\t\t\tcallback(data, err);\r\n\t\t\t\t\t\treturn;\r\n\t\t\t\t\t}\r\n\r\n\t\t\t\t\tif (data && data.length) {\r\n\t\t\t\t\t\tcallback(data.toString(encoding || \"utf8\"));\r\n\t\t\t\t\t} else {\r\n\t\t\t\t\t\tcallback(\"\");\r\n\t\t\t\t\t}\r\n\t\t\t\t})\r\n\t\t\t} else {\r\n\t\t\t\tcallback(\"\");\r\n\t\t\t}\r\n\t\t},\r\n\r\n\t\t/**\r\n\t\t * Remove the entry from the file or the entry and all it's nested directories and files if the given entry is a directory\r\n\t\t *\r\n\t\t * @param entry\r\n\t\t */\r\n\t\tdeleteFile: function (/**Object*/entry) { // @TODO: test deleteFile\r\n\t\t\tvar item = getEntry(entry);\r\n\t\t\tif (item) {\r\n\t\t\t\t_zip.deleteEntry(item.entryName);\r\n\t\t\t}\r\n\t\t},\r\n\r\n\t\t/**\r\n\t\t * Adds a comment to the zip. The zip must be rewritten after adding the comment.\r\n\t\t *\r\n\t\t * @param comment\r\n\t\t */\r\n\t\taddZipComment: function (/**String*/comment) { // @TODO: test addZipComment\r\n\t\t\t_zip.comment = comment;\r\n\t\t},\r\n\r\n\t\t/**\r\n\t\t * Returns the zip comment\r\n\t\t *\r\n\t\t * @return String\r\n\t\t */\r\n\t\tgetZipComment: function () {\r\n\t\t\treturn _zip.comment || '';\r\n\t\t},\r\n\r\n\t\t/**\r\n\t\t * Adds a comment to a specified zipEntry. The zip must be rewritten after adding the comment\r\n\t\t * The comment cannot exceed 65535 characters in length\r\n\t\t *\r\n\t\t * @param entry\r\n\t\t * @param comment\r\n\t\t */\r\n\t\taddZipEntryComment: function (/**Object*/entry, /**String*/comment) {\r\n\t\t\tvar item = getEntry(entry);\r\n\t\t\tif (item) {\r\n\t\t\t\titem.comment = comment;\r\n\t\t\t}\r\n\t\t},\r\n\r\n\t\t/**\r\n\t\t * Returns the comment of the specified entry\r\n\t\t *\r\n\t\t * @param entry\r\n\t\t * @return String\r\n\t\t */\r\n\t\tgetZipEntryComment: function (/**Object*/entry) {\r\n\t\t\tvar item = getEntry(entry);\r\n\t\t\tif (item) {\r\n\t\t\t\treturn item.comment || '';\r\n\t\t\t}\r\n\t\t\treturn ''\r\n\t\t},\r\n\r\n\t\t/**\r\n\t\t * Updates the content of an existing entry inside the archive. The zip must be rewritten after updating the content\r\n\t\t *\r\n\t\t * @param entry\r\n\t\t * @param content\r\n\t\t */\r\n\t\tupdateFile: function (/**Object*/entry, /**Buffer*/content) {\r\n\t\t\tvar item = getEntry(entry);\r\n\t\t\tif (item) {\r\n\t\t\t\titem.setData(content);\r\n\t\t\t}\r\n\t\t},\r\n\r\n\t\t/**\r\n\t\t * Adds a file from the disk to the archive\r\n\t\t *\r\n\t\t * @param localPath File to add to zip\r\n\t\t * @param zipPath Optional path inside the zip\r\n\t\t * @param zipName Optional name for the file\r\n\t\t */\r\n\t\taddLocalFile: function (/**String*/localPath, /**String=*/zipPath, /**String=*/zipName, /**String*/comment) {\r\n\t\t\tif (fs.existsSync(localPath)) {\r\n\t\t\t\t// fix ZipPath\r\n\t\t\t\tzipPath = (zipPath) ? fixPath(zipPath) : \"\";\r\n\r\n\t\t\t\t// p - local file name\r\n\t\t\t\tvar p = localPath.split(\"\\\\\").join(\"/\").split(\"/\").pop();\r\n\r\n\t\t\t\t// add file name into zippath\r\n\t\t\t\tzipPath += (zipName) ? zipName : p;\r\n\r\n\t\t\t\t// read file attributes\r\n\t\t\t\tconst _attr = fs.statSync(localPath);\r\n\r\n\t\t\t\t// add file into zip file\r\n\t\t\t\tthis.addFile(zipPath, fs.readFileSync(localPath), comment, _attr)\r\n\t\t\t} else {\r\n\t\t\t\tthrow new Error(Utils.Errors.FILE_NOT_FOUND.replace(\"%s\", localPath));\r\n\t\t\t}\r\n\t\t},\r\n\r\n\t\t/**\r\n\t\t * Adds a local directory and all its nested files and directories to the archive\r\n\t\t *\r\n\t\t * @param localPath\r\n\t\t * @param zipPath optional path inside zip\r\n\t\t * @param filter optional RegExp or Function if files match will\r\n\t\t *               be included.\r\n\t\t */\r\n        addLocalFolder: function (/**String*/localPath, /**String=*/zipPath, /**=RegExp|Function*/filter) {\r\n            // Prepare filter\r\n            if (filter instanceof RegExp) {                 // if filter is RegExp wrap it\r\n                filter = (function (rx){\r\n                    return function (filename) {\r\n                        return rx.test(filename);\r\n                    }\r\n                })(filter);\r\n            } else if ('function' !== typeof filter) {       // if filter is not function we will replace it\r\n                filter = function () {\r\n                    return true;\r\n                };\r\n            }\r\n\r\n            // fix ZipPath\r\n            zipPath = (zipPath) ? fixPath(zipPath) : \"\";\r\n\r\n            // normalize the path first\r\n            localPath = pth.normalize(localPath);\r\n\r\n            if (fs.existsSync(localPath)) {\r\n\r\n                var items = Utils.findFiles(localPath),\r\n                    self = this;\r\n\r\n                if (items.length) {\r\n                    items.forEach(function (filepath) {\r\n                        var p = pth.relative(localPath, filepath).split(\"\\\\\").join(\"/\"); //windows fix\r\n                        if (filter(p)) {\r\n                            var stats = fs.statSync(filepath);\r\n                            if (stats.isFile()) {\r\n                                self.addFile(zipPath + p, fs.readFileSync(filepath), \"\", stats);\r\n                            } else {\r\n                                self.addFile(zipPath + p + '/', Buffer.alloc(0), \"\", stats);\r\n                            }\r\n                        }\r\n                    });\r\n                }\r\n            } else {\r\n                throw new Error(Utils.Errors.FILE_NOT_FOUND.replace(\"%s\", localPath));\r\n            }\r\n        },\r\n\r\n\t\t/**\r\n\t\t * Asynchronous addLocalFile\r\n\t\t * @param localPath\r\n\t\t * @param callback\r\n\t\t * @param zipPath optional path inside zip\r\n\t\t * @param filter optional RegExp or Function if files match will\r\n\t\t *               be included.\r\n\t\t */\r\n        addLocalFolderAsync: function (/*String*/localPath, /*Function*/callback, /*String*/zipPath, /*RegExp|Function*/filter) {\r\n            if (filter instanceof RegExp) {\r\n                filter = (function (rx) {\r\n                    return function (filename) {\r\n                        return rx.test(filename);\r\n                    };\r\n                })(filter);\r\n            } else if (\"function\" !== typeof filter) {\r\n                filter = function () {\r\n                    return true;\r\n                };\r\n            }\r\n\r\n            // fix ZipPath\r\n            zipPath = zipPath ? fixPath(zipPath) : \"\";\r\n\r\n            // normalize the path first\r\n            localPath = pth.normalize(localPath);\r\n\r\n            var self = this;\r\n            fs.open(localPath, 'r', function (err) {\r\n                if (err && err.code === 'ENOENT') {\r\n                    callback(undefined, Utils.Errors.FILE_NOT_FOUND.replace(\"%s\", localPath));\r\n                } else if (err) {\r\n                    callback(undefined, err);\r\n                } else {\r\n                    var items = Utils.findFiles(localPath);\r\n                    var i = -1;\r\n\r\n                    var next = function () {\r\n                        i += 1;\r\n                        if (i < items.length) {\r\n                            var filepath = items[i];\r\n                            var p = pth.relative(localPath, filepath).split(\"\\\\\").join(\"/\"); //windows fix\r\n                            p = p.normalize('NFD').replace(/[\\u0300-\\u036f]/g, '').replace(/[^\\x20-\\x7E]/g, '') // accent fix\r\n                            if (filter(p)) {\r\n                                fs.stat(filepath, function (er0, stats) {\r\n                                    if (er0) callback(undefined, er0);\r\n                                    if (stats.isFile()) {\r\n                                        fs.readFile(filepath, function (er1, data) {\r\n                                            if (er1) {\r\n                                                callback(undefined, er1);\r\n                                            } else {\r\n                                                self.addFile(zipPath + p, data, \"\", stats);\r\n                                                next();\r\n                                            }\r\n                                        });\r\n                                    } else {\r\n                                        self.addFile(zipPath + p + \"/\", Buffer.alloc(0), \"\", stats);\r\n                                        next();\r\n                                    }\r\n                                });\r\n                            } else {\r\n                                next();\r\n                            }\r\n\r\n                        } else {\r\n                            callback(true, undefined);\r\n                        }\r\n                    }\r\n\r\n                    next();\r\n                }\r\n            });\r\n        },\r\n\r\n        addLocalFolderPromise: function (/*String*/ localPath, /* object */ options) {\r\n            return new Promise((resolve, reject) => {\r\n                const { filter, zipPath } = Object.assign({}, options);\r\n                this.addLocalFolderAsync(localPath,\r\n                    (done, err) => {\r\n                        if (err) reject(err);\r\n                        if (done) resolve(this);\r\n                    }, zipPath, filter\r\n                );\r\n            });\r\n        },\r\n\r\n        /**\r\n         * Allows you to create a entry (file or directory) in the zip file.\r\n         * If you want to create a directory the entryName must end in / and a null buffer should be provided.\r\n         * Comment and attributes are optional\r\n         *\r\n         * @param {string} entryName\r\n         * @param {Buffer | string} content - file content as buffer or utf8 coded string\r\n         * @param {string} comment - file comment\r\n         * @param {number | object} attr - number as unix file permissions, object as filesystem Stats object\r\n         */\r\n        addFile: function (/**String*/ entryName, /**Buffer*/ content, /**String*/ comment, /**Number*/ attr) {\r\n            let entry = getEntry(entryName);\r\n            const update = entry != null;\r\n\r\n            // prepare new entry\r\n            if (!update){\r\n                entry = new ZipEntry();\r\n                entry.entryName = entryName;\r\n            }\r\n            entry.comment = comment || \"\";\r\n\r\n            const isStat = ('object' === typeof attr) && (attr instanceof fs.Stats);\r\n\r\n            // last modification time from file stats\r\n            if (isStat){\r\n                entry.header.time = attr.mtime;\r\n            }\r\n\r\n            // Set file attribute\r\n            var fileattr = (entry.isDirectory) ? 0x10 : 0;  // (MS-DOS directory flag)\r\n\r\n            // extended attributes field for Unix\r\n            if('win32' !== process.platform){\r\n                // set file type either S_IFDIR / S_IFREG\r\n                let unix = (entry.isDirectory) ? 0x4000 : 0x8000;\r\n\r\n                if (isStat) {                                       // File attributes from file stats\r\n                    unix |= (0xfff & attr.mode);\r\n                }else if ('number' === typeof attr){                // attr from given attr values\r\n                    unix |= (0xfff & attr);\r\n                }else{                                              // Default values:\r\n                    unix |= (entry.isDirectory) ? 0o755 : 0o644;    // permissions (drwxr-xr-x) or (-r-wr--r--)\r\n                }\r\n\r\n                fileattr = (fileattr | (unix << 16)) >>> 0;         // add attributes\r\n            }\r\n\r\n            entry.attr = fileattr;\r\n\r\n            entry.setData(content);\r\n            if (!update) _zip.setEntry(entry);\r\n        },\r\n\r\n\t\t/**\r\n\t\t * Returns an array of ZipEntry objects representing the files and folders inside the archive\r\n\t\t *\r\n\t\t * @return Array\r\n\t\t */\r\n\t\tgetEntries: function () {\r\n\t\t\tif (_zip) {\r\n\t\t\t\treturn _zip.entries;\r\n\t\t\t} else {\r\n\t\t\t\treturn [];\r\n\t\t\t}\r\n\t\t},\r\n\r\n\t\t/**\r\n\t\t * Returns a ZipEntry object representing the file or folder specified by ``name``.\r\n\t\t *\r\n\t\t * @param name\r\n\t\t * @return ZipEntry\r\n\t\t */\r\n\t\tgetEntry: function (/**String*/name) {\r\n\t\t\treturn getEntry(name);\r\n\t\t},\r\n\r\n\t\tgetEntryCount: function() {\r\n\t\t\treturn _zip.getEntryCount();\r\n\t\t},\r\n\r\n\t\tforEach: function(callback) {\r\n\t\t\treturn _zip.forEach(callback);\r\n\t\t},\r\n\r\n\t\t/**\r\n\t\t * Extracts the given entry to the given targetPath\r\n\t\t * If the entry is a directory inside the archive, the entire directory and it's subdirectories will be extracted\r\n\t\t *\r\n\t\t * @param entry ZipEntry object or String with the full path of the entry\r\n\t\t * @param targetPath Target folder where to write the file\r\n\t\t * @param maintainEntryPath If maintainEntryPath is true and the entry is inside a folder, the entry folder\r\n\t\t *                          will be created in targetPath as well. Default is TRUE\r\n\t\t * @param overwrite If the file already exists at the target path, the file will be overwriten if this is true.\r\n\t\t *                  Default is FALSE\r\n         * @param outFileName String If set will override the filename of the extracted file (Only works if the entry is a file)\r\n\t\t *\r\n\t\t * @return Boolean\r\n\t\t */\r\n\t\textractEntryTo: function (/**Object*/entry, /**String*/targetPath, /**Boolean*/maintainEntryPath, /**Boolean*/overwrite, /**String**/outFileName) {\r\n\t\t\toverwrite = overwrite || false;\r\n\t\t\tmaintainEntryPath = typeof maintainEntryPath === \"undefined\" ? true : maintainEntryPath;\r\n\r\n\t\t\tvar item = getEntry(entry);\r\n\t\t\tif (!item) {\r\n\t\t\t\tthrow new Error(Utils.Errors.NO_ENTRY);\r\n\t\t\t}\r\n\r\n\t\t\tvar entryName = canonical(item.entryName);\r\n\r\n\t\t\tvar target = sanitize(targetPath,outFileName && !item.isDirectory ? outFileName : (maintainEntryPath ? entryName : pth.basename(entryName)));\r\n\r\n\t\t\tif (item.isDirectory) {\r\n\t\t\t\ttarget = pth.resolve(target, \"..\");\r\n\t\t\t\tvar children = _zip.getEntryChildren(item);\r\n\t\t\t\tchildren.forEach(function (child) {\r\n\t\t\t\t\tif (child.isDirectory) return;\r\n\t\t\t\t\tvar content = child.getData();\r\n\t\t\t\t\tif (!content) {\r\n\t\t\t\t\t\tthrow new Error(Utils.Errors.CANT_EXTRACT_FILE);\r\n\t\t\t\t\t}\r\n\t\t\t\t\tvar name = canonical(child.entryName)\r\n\t\t\t\t\tvar childName = sanitize(targetPath, maintainEntryPath ? name : pth.basename(name));\r\n\t\t\t\t\t// The reverse operation for attr depend on method addFile()\r\n\t\t\t\t\tvar fileAttr = child.attr ? (((child.attr >>> 0) | 0) >> 16) & 0xfff : 0;\r\n\t\t\t\t\tUtils.writeFileTo(childName, content, overwrite, fileAttr);\r\n\t\t\t\t});\r\n\t\t\t\treturn true;\r\n\t\t\t}\r\n\r\n\t\t\tvar content = item.getData();\r\n\t\t\tif (!content) throw new Error(Utils.Errors.CANT_EXTRACT_FILE);\r\n\r\n\t\t\tif (fs.existsSync(target) && !overwrite) {\r\n\t\t\t\tthrow new Error(Utils.Errors.CANT_OVERRIDE);\r\n\t\t\t}\r\n\t\t\t// The reverse operation for attr depend on method addFile()\r\n\t\t\tvar fileAttr = item.attr ? (((item.attr >>> 0) | 0) >> 16) & 0xfff : 0;\r\n\t\t\tUtils.writeFileTo(target, content, overwrite, fileAttr);\r\n\r\n\t\t\treturn true;\r\n\t\t},\r\n\r\n\t\t/**\r\n\t\t * Test the archive\r\n\t\t *\r\n\t\t */\r\n\t\ttest: function (pass) {\r\n\t\t\tif (!_zip) {\r\n\t\t\t\treturn false;\r\n\t\t\t}\r\n\r\n\t\t\tfor (var entry in _zip.entries) {\r\n\t\t\t\ttry {\r\n\t\t\t\t\tif (entry.isDirectory) {\r\n\t\t\t\t\t\tcontinue;\r\n\t\t\t\t\t}\r\n\t\t\t\t\tvar content = _zip.entries[entry].getData(pass);\r\n\t\t\t\t\tif (!content) {\r\n\t\t\t\t\t\treturn false;\r\n\t\t\t\t\t}\r\n\t\t\t\t} catch (err) {\r\n\t\t\t\t\treturn false;\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\treturn true;\r\n\t\t},\r\n\r\n\t\t/**\r\n\t\t * Extracts the entire archive to the given location\r\n\t\t *\r\n\t\t * @param targetPath Target location\r\n\t\t * @param overwrite If the file already exists at the target path, the file will be overwriten if this is true.\r\n\t\t *                  Default is FALSE\r\n\t\t */\r\n\t\textractAllTo: function (/**String*/targetPath, /**Boolean*/overwrite, /*String, Buffer*/pass) {\r\n\t\t\toverwrite = overwrite || false;\r\n\t\t\tif (!_zip) {\r\n\t\t\t\tthrow new Error(Utils.Errors.NO_ZIP);\r\n\t\t\t}\r\n\t\t\t_zip.entries.forEach(function (entry) {\r\n\t\t\t\tvar entryName = sanitize(targetPath, canonical(entry.entryName.toString()));\r\n\t\t\t\tif (entry.isDirectory) {\r\n\t\t\t\t\tUtils.makeDir(entryName);\r\n\t\t\t\t\treturn;\r\n\t\t\t\t}\r\n\t\t\t\tvar content = entry.getData(pass);\r\n\t\t\t\tif (!content) {\r\n\t\t\t\t\tthrow new Error(Utils.Errors.CANT_EXTRACT_FILE);\r\n\t\t\t\t}\r\n\t\t\t\t// The reverse operation for attr depend on method addFile()\r\n\t\t\t\tvar fileAttr = entry.attr ? (((entry.attr >>> 0) | 0) >> 16) & 0xfff : 0;\r\n\t\t\t\tUtils.writeFileTo(entryName, content, overwrite, fileAttr);\r\n\t\t\t\ttry {\r\n\t\t\t\t\tfs.utimesSync(entryName, entry.header.time, entry.header.time)\r\n\t\t\t\t} catch (err) {\r\n\t\t\t\t\tthrow new Error(Utils.Errors.CANT_EXTRACT_FILE);\r\n\t\t\t\t}\r\n\t\t\t})\r\n\t\t},\r\n\r\n\t\t/**\r\n\t\t * Asynchronous extractAllTo\r\n\t\t *\r\n\t\t * @param targetPath Target location\r\n\t\t * @param overwrite If the file already exists at the target path, the file will be overwriten if this is true.\r\n\t\t *                  Default is FALSE\r\n\t\t * @param callback\r\n\t\t */\r\n\t\textractAllToAsync: function (/**String*/targetPath, /**Boolean*/overwrite, /**Function*/callback) {\r\n\t\t\tif (!callback) {\r\n\t\t\t\tcallback = function() {}\r\n\t\t\t}\r\n\t\t\toverwrite = overwrite || false;\r\n\t\t\tif (!_zip) {\r\n\t\t\t\tcallback(new Error(Utils.Errors.NO_ZIP));\r\n\t\t\t\treturn;\r\n\t\t\t}\r\n\r\n\t\t\tvar entries = _zip.entries;\r\n\t\t\tvar i = entries.length;\r\n\t\t\tentries.forEach(function (entry) {\r\n\t\t\t\tif (i <= 0) return; // Had an error already\r\n\r\n\t\t\t\tvar entryName = pth.normalize(canonical(entry.entryName.toString()));\r\n\r\n\t\t\t\tif (entry.isDirectory) {\r\n\t\t\t\t\tUtils.makeDir(sanitize(targetPath, entryName));\r\n\t\t\t\t\tif (--i === 0)\r\n\t\t\t\t\t\tcallback(undefined);\r\n\t\t\t\t\treturn;\r\n\t\t\t\t}\r\n\t\t\t\tentry.getDataAsync(function (content, err) {\r\n\t\t\t\t\tif (i <= 0) return;\r\n\t\t\t\t\tif (err) {\r\n\t\t\t\t\t\tcallback(new Error(err));\r\n\t\t\t\t\t\treturn;\r\n\t\t\t\t\t}\r\n\t\t\t\t\tif (!content) {\r\n\t\t\t\t\t\ti = 0;\r\n\t\t\t\t\t\tcallback(new Error(Utils.Errors.CANT_EXTRACT_FILE));\r\n\t\t\t\t\t\treturn;\r\n\t\t\t\t\t}\r\n\r\n\t\t\t\t\t// The reverse operation for attr depend on method addFile()\r\n\t\t\t\t\tvar fileAttr = entry.attr ? (((entry.attr >>> 0) | 0) >> 16) & 0xfff : 0;\r\n\t\t\t\t\tUtils.writeFileToAsync(sanitize(targetPath, entryName), content, overwrite, fileAttr, function (succ) {\r\n\t\t\t\t\t\ttry {\r\n\t\t\t\t\t\t\tfs.utimesSync(pth.resolve(targetPath, entryName), entry.header.time, entry.header.time);\r\n\t\t\t\t\t\t} catch (err) {\r\n\t\t\t\t\t\t\tcallback(new Error('Unable to set utimes'));\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t\tif (i <= 0) return;\r\n\t\t\t\t\t\tif (!succ) {\r\n\t\t\t\t\t\t\ti = 0;\r\n\t\t\t\t\t\t\tcallback(new Error('Unable to write'));\r\n\t\t\t\t\t\t\treturn;\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t\tif (--i === 0)\r\n\t\t\t\t\t\t\tcallback(undefined);\r\n\t\t\t\t\t});\r\n\t\t\t\t});\r\n\t\t\t})\r\n\t\t},\r\n\r\n\t\t/**\r\n\t\t * Writes the newly created zip file to disk at the specified location or if a zip was opened and no ``targetFileName`` is provided, it will overwrite the opened zip\r\n\t\t *\r\n\t\t * @param targetFileName\r\n\t\t * @param callback\r\n\t\t */\r\n\t\twriteZip: function (/**String*/targetFileName, /**Function*/callback) {\r\n\t\t\tif (arguments.length === 1) {\r\n\t\t\t\tif (typeof targetFileName === \"function\") {\r\n\t\t\t\t\tcallback = targetFileName;\r\n\t\t\t\t\ttargetFileName = \"\";\r\n\t\t\t\t}\r\n\t\t\t}\r\n\r\n\t\t\tif (!targetFileName && opts.filename) {\r\n\t\t\t\ttargetFileName = opts.filename;\r\n\t\t\t}\r\n\t\t\tif (!targetFileName) return;\r\n\r\n\t\t\tvar zipData = _zip.compressToBuffer();\r\n\t\t\tif (zipData) {\r\n\t\t\t\tvar ok = Utils.writeFileTo(targetFileName, zipData, true);\r\n\t\t\t\tif (typeof callback === 'function') callback(!ok ? new Error(\"failed\") : null, \"\");\r\n\t\t\t}\r\n\t\t},\r\n\r\n        writeZipPromise: function (/**String*/ targetFileName, /* object */ options) {\r\n            const { overwrite, perm } = Object.assign({ overwrite: true }, options);\r\n\r\n            return new Promise((resolve, reject) => {\r\n                // find file name\r\n                if (!targetFileName && opts.filename) targetFileName = opts.filename;\r\n                if (!targetFileName) reject(\"ADM-ZIP: ZIP File Name Missing\");\r\n\r\n                this.toBufferPromise().then((zipData) => {\r\n                    const ret = (done) => (done ? resolve(done) : reject(\"ADM-ZIP: Wasn't able to write zip file\"));\r\n                    Utils.writeFileToAsync(targetFileName, zipData, overwrite, perm, ret);\r\n                }, reject);\r\n            });\r\n        },\r\n\r\n        toBufferPromise: function () {\r\n            return new Promise((resolve, reject) => {\r\n                _zip.toAsyncBuffer(resolve, reject);\r\n            });\r\n        },\r\n\r\n\t\t/**\r\n\t\t * Returns the content of the entire zip file as a Buffer object\r\n\t\t *\r\n\t\t * @return Buffer\r\n\t\t */\r\n\t\ttoBuffer: function (/**Function=*/onSuccess, /**Function=*/onFail, /**Function=*/onItemStart, /**Function=*/onItemEnd) {\r\n\t\t\tthis.valueOf = 2;\r\n\t\t\tif (typeof onSuccess === \"function\") {\r\n\t\t\t\t_zip.toAsyncBuffer(onSuccess, onFail, onItemStart, onItemEnd);\r\n\t\t\t\treturn null;\r\n\t\t\t}\r\n\t\t\treturn _zip.compressToBuffer()\r\n\t\t}\r\n\t}\r\n};\r\n","var Utils = require(\"../util\"),\r\n    Constants = Utils.Constants;\r\n\r\n/* The central directory file header */\r\nmodule.exports = function () {\r\n    var _verMade = 0x14,\r\n        _version = 0x0A,\r\n        _flags = 0,\r\n        _method = 0,\r\n        _time = 0,\r\n        _crc = 0,\r\n        _compressedSize = 0,\r\n        _size = 0,\r\n        _fnameLen = 0,\r\n        _extraLen = 0,\r\n\r\n        _comLen = 0,\r\n        _diskStart = 0,\r\n        _inattr = 0,\r\n        _attr = 0,\r\n        _offset = 0;\r\n\r\n    switch(process.platform){\r\n        case 'win32':\r\n            _verMade |= 0x0A00;\r\n        default:\r\n            _verMade |= 0x0300;\r\n    }\r\n\r\n    var _dataHeader = {};\r\n\r\n    function setTime(val) {\r\n        val = new Date(val);\r\n        _time = (val.getFullYear() - 1980 & 0x7f) << 25  // b09-16 years from 1980\r\n            | (val.getMonth() + 1) << 21                 // b05-08 month\r\n            | val.getDate() << 16                        // b00-04 hour\r\n\r\n            // 2 bytes time\r\n            | val.getHours() << 11    // b11-15 hour\r\n            | val.getMinutes() << 5   // b05-10 minute\r\n            | val.getSeconds() >> 1;  // b00-04 seconds divided by 2\r\n    }\r\n\r\n    setTime(+new Date());\r\n\r\n    return {\r\n        get made () { return _verMade; },\r\n        set made (val) { _verMade = val; },\r\n\r\n        get version () { return _version; },\r\n        set version (val) { _version = val },\r\n\r\n        get flags () { return _flags },\r\n        set flags (val) { _flags = val; },\r\n\r\n        get method () { return _method; },\r\n        set method (val) {\r\n            switch (val){\r\n                case Constants.STORED:\r\n                    this.version = 10;\r\n                case Constants.DEFLATED:\r\n                default:\r\n                    this.version = 20;\r\n            }\r\n            _method = val;\r\n            },\r\n\r\n        get time () { return new Date(\r\n            ((_time >> 25) & 0x7f) + 1980,\r\n            ((_time >> 21) & 0x0f) - 1,\r\n            (_time >> 16) & 0x1f,\r\n            (_time >> 11) & 0x1f,\r\n            (_time >> 5) & 0x3f,\r\n            (_time & 0x1f) << 1\r\n        );\r\n        },\r\n        set time (val) {\r\n            setTime(val);\r\n        },\r\n\r\n        get crc () { return _crc; },\r\n        set crc (val) { _crc = val; },\r\n\r\n        get compressedSize () { return _compressedSize; },\r\n        set compressedSize (val) { _compressedSize = val; },\r\n\r\n        get size () { return _size; },\r\n        set size (val) { _size = val; },\r\n\r\n        get fileNameLength () { return _fnameLen; },\r\n        set fileNameLength (val) { _fnameLen = val; },\r\n\r\n        get extraLength () { return _extraLen },\r\n        set extraLength (val) { _extraLen = val; },\r\n\r\n        get commentLength () { return _comLen },\r\n        set commentLength (val) { _comLen = val },\r\n\r\n        get diskNumStart () { return _diskStart },\r\n        set diskNumStart (val) { _diskStart = val },\r\n\r\n        get inAttr () { return _inattr },\r\n        set inAttr (val) { _inattr = val },\r\n\r\n        get attr () { return _attr },\r\n        set attr (val) { _attr = val },\r\n\r\n        get offset () { return _offset },\r\n        set offset (val) { _offset = val },\r\n\r\n        get encripted () { return (_flags & 1) === 1 },\r\n\r\n        get entryHeaderSize () {\r\n            return Constants.CENHDR + _fnameLen + _extraLen + _comLen;\r\n        },\r\n\r\n        get realDataOffset () {\r\n            return _offset + Constants.LOCHDR + _dataHeader.fnameLen + _dataHeader.extraLen;\r\n        },\r\n\r\n        get dataHeader () {\r\n            return _dataHeader;\r\n        },\r\n\r\n        loadDataHeaderFromBinary : function(/*Buffer*/input) {\r\n            var data = input.slice(_offset, _offset + Constants.LOCHDR);\r\n            // 30 bytes and should start with \"PK\\003\\004\"\r\n            if (data.readUInt32LE(0) !== Constants.LOCSIG) {\r\n                throw new Error(Utils.Errors.INVALID_LOC);\r\n            }\r\n            _dataHeader = {\r\n                // version needed to extract\r\n                version : data.readUInt16LE(Constants.LOCVER),\r\n                // general purpose bit flag\r\n                flags : data.readUInt16LE(Constants.LOCFLG),\r\n                // compression method\r\n                method : data.readUInt16LE(Constants.LOCHOW),\r\n                // modification time (2 bytes time, 2 bytes date)\r\n                time : data.readUInt32LE(Constants.LOCTIM),\r\n                // uncompressed file crc-32 value\r\n                crc : data.readUInt32LE(Constants.LOCCRC),\r\n                // compressed size\r\n                compressedSize : data.readUInt32LE(Constants.LOCSIZ),\r\n                // uncompressed size\r\n                size : data.readUInt32LE(Constants.LOCLEN),\r\n                // filename length\r\n                fnameLen : data.readUInt16LE(Constants.LOCNAM),\r\n                // extra field length\r\n                extraLen : data.readUInt16LE(Constants.LOCEXT)\r\n            }\r\n        },\r\n\r\n        loadFromBinary : function(/*Buffer*/data) {\r\n            // data should be 46 bytes and start with \"PK 01 02\"\r\n            if (data.length !== Constants.CENHDR || data.readUInt32LE(0) !== Constants.CENSIG) {\r\n                throw new Error(Utils.Errors.INVALID_CEN);\r\n            }\r\n            // version made by\r\n            _verMade = data.readUInt16LE(Constants.CENVEM);\r\n            // version needed to extract\r\n            _version = data.readUInt16LE(Constants.CENVER);\r\n            // encrypt, decrypt flags\r\n            _flags = data.readUInt16LE(Constants.CENFLG);\r\n            // compression method\r\n            _method = data.readUInt16LE(Constants.CENHOW);\r\n            // modification time (2 bytes time, 2 bytes date)\r\n            _time = data.readUInt32LE(Constants.CENTIM);\r\n            // uncompressed file crc-32 value\r\n            _crc = data.readUInt32LE(Constants.CENCRC);\r\n            // compressed size\r\n            _compressedSize = data.readUInt32LE(Constants.CENSIZ);\r\n            // uncompressed size\r\n            _size = data.readUInt32LE(Constants.CENLEN);\r\n            // filename length\r\n            _fnameLen = data.readUInt16LE(Constants.CENNAM);\r\n            // extra field length\r\n            _extraLen = data.readUInt16LE(Constants.CENEXT);\r\n            // file comment length\r\n            _comLen = data.readUInt16LE(Constants.CENCOM);\r\n            // volume number start\r\n            _diskStart = data.readUInt16LE(Constants.CENDSK);\r\n            // internal file attributes\r\n            _inattr = data.readUInt16LE(Constants.CENATT);\r\n            // external file attributes\r\n            _attr = data.readUInt32LE(Constants.CENATX);\r\n            // LOC header offset\r\n            _offset = data.readUInt32LE(Constants.CENOFF);\r\n        },\r\n\r\n        dataHeaderToBinary : function() {\r\n            // LOC header size (30 bytes)\r\n            var data = Buffer.alloc(Constants.LOCHDR);\r\n            // \"PK\\003\\004\"\r\n            data.writeUInt32LE(Constants.LOCSIG, 0);\r\n            // version needed to extract\r\n            data.writeUInt16LE(_version, Constants.LOCVER);\r\n            // general purpose bit flag\r\n            data.writeUInt16LE(_flags, Constants.LOCFLG);\r\n            // compression method\r\n            data.writeUInt16LE(_method, Constants.LOCHOW);\r\n            // modification time (2 bytes time, 2 bytes date)\r\n            data.writeUInt32LE(_time, Constants.LOCTIM);\r\n            // uncompressed file crc-32 value\r\n            data.writeUInt32LE(_crc, Constants.LOCCRC);\r\n            // compressed size\r\n            data.writeUInt32LE(_compressedSize, Constants.LOCSIZ);\r\n            // uncompressed size\r\n            data.writeUInt32LE(_size, Constants.LOCLEN);\r\n            // filename length\r\n            data.writeUInt16LE(_fnameLen, Constants.LOCNAM);\r\n            // extra field length\r\n            data.writeUInt16LE(_extraLen, Constants.LOCEXT);\r\n            return data;\r\n        },\r\n\r\n        entryHeaderToBinary : function() {\r\n            // CEN header size (46 bytes)\r\n            var data = Buffer.alloc(Constants.CENHDR + _fnameLen + _extraLen + _comLen);\r\n            // \"PK\\001\\002\"\r\n            data.writeUInt32LE(Constants.CENSIG, 0);\r\n            // version made by\r\n            data.writeUInt16LE(_verMade, Constants.CENVEM);\r\n            // version needed to extract\r\n            data.writeUInt16LE(_version, Constants.CENVER);\r\n            // encrypt, decrypt flags\r\n            data.writeUInt16LE(_flags, Constants.CENFLG);\r\n            // compression method\r\n            data.writeUInt16LE(_method, Constants.CENHOW);\r\n            // modification time (2 bytes time, 2 bytes date)\r\n            data.writeUInt32LE(_time, Constants.CENTIM);\r\n            // uncompressed file crc-32 value\r\n            data.writeUInt32LE(_crc, Constants.CENCRC);\r\n            // compressed size\r\n            data.writeUInt32LE(_compressedSize, Constants.CENSIZ);\r\n            // uncompressed size\r\n            data.writeUInt32LE(_size, Constants.CENLEN);\r\n            // filename length\r\n            data.writeUInt16LE(_fnameLen, Constants.CENNAM);\r\n            // extra field length\r\n            data.writeUInt16LE(_extraLen, Constants.CENEXT);\r\n            // file comment length\r\n            data.writeUInt16LE(_comLen, Constants.CENCOM);\r\n            // volume number start\r\n            data.writeUInt16LE(_diskStart, Constants.CENDSK);\r\n            // internal file attributes\r\n            data.writeUInt16LE(_inattr, Constants.CENATT);\r\n            // external file attributes\r\n            data.writeUInt32LE(_attr, Constants.CENATX);\r\n            // LOC header offset\r\n            data.writeUInt32LE(_offset, Constants.CENOFF);\r\n            // fill all with\r\n            data.fill(0x00, Constants.CENHDR);\r\n            return data;\r\n        },\r\n\r\n        toString : function() {\r\n            return '{\\n' +\r\n                '\\t\"made\" : ' + _verMade + \",\\n\" +\r\n                '\\t\"version\" : ' + _version + \",\\n\" +\r\n                '\\t\"flags\" : ' + _flags + \",\\n\" +\r\n                '\\t\"method\" : ' + Utils.methodToString(_method) + \",\\n\" +\r\n                '\\t\"time\" : ' + this.time + \",\\n\" +\r\n                '\\t\"crc\" : 0x' + _crc.toString(16).toUpperCase() + \",\\n\" +\r\n                '\\t\"compressedSize\" : ' + _compressedSize + \" bytes,\\n\" +\r\n                '\\t\"size\" : ' + _size + \" bytes,\\n\" +\r\n                '\\t\"fileNameLength\" : ' + _fnameLen + \",\\n\" +\r\n                '\\t\"extraLength\" : ' + _extraLen + \" bytes,\\n\" +\r\n                '\\t\"commentLength\" : ' + _comLen + \" bytes,\\n\" +\r\n                '\\t\"diskNumStart\" : ' + _diskStart + \",\\n\" +\r\n                '\\t\"inAttr\" : ' + _inattr + \",\\n\" +\r\n                '\\t\"attr\" : ' + _attr + \",\\n\" +\r\n                '\\t\"offset\" : ' + _offset + \",\\n\" +\r\n                '\\t\"entryHeaderSize\" : ' + (Constants.CENHDR + _fnameLen + _extraLen + _comLen) + \" bytes\\n\" +\r\n                '}';\r\n        }\r\n    }\r\n};\r\n","exports.EntryHeader = require(\"./entryHeader\");\r\nexports.MainHeader = require(\"./mainHeader\");\r\n","var Utils = require(\"../util\"),\r\n    Constants = Utils.Constants;\r\n\r\n/* The entries in the end of central directory */\r\nmodule.exports = function () {\r\n    var _volumeEntries = 0,\r\n        _totalEntries = 0,\r\n        _size = 0,\r\n        _offset = 0,\r\n        _commentLength = 0;\r\n\r\n    return {\r\n        get diskEntries () { return _volumeEntries },\r\n        set diskEntries (/*Number*/val) { _volumeEntries = _totalEntries = val; },\r\n\r\n        get totalEntries () { return _totalEntries },\r\n        set totalEntries (/*Number*/val) { _totalEntries = _volumeEntries = val; },\r\n\r\n        get size () { return _size },\r\n        set size (/*Number*/val) { _size = val; },\r\n\r\n        get offset () { return _offset },\r\n        set offset (/*Number*/val) { _offset = val; },\r\n\r\n        get commentLength () { return _commentLength },\r\n        set commentLength (/*Number*/val) { _commentLength = val; },\r\n\r\n        get mainHeaderSize () {\r\n            return Constants.ENDHDR + _commentLength;\r\n        },\r\n\r\n        loadFromBinary : function(/*Buffer*/data) {\r\n            // data should be 22 bytes and start with \"PK 05 06\"\r\n            // or be 56+ bytes and start with \"PK 06 06\" for Zip64\r\n            if ((data.length !== Constants.ENDHDR || data.readUInt32LE(0) !== Constants.ENDSIG) &&\r\n                (data.length < Constants.ZIP64HDR || data.readUInt32LE(0) !== Constants.ZIP64SIG)) {\r\n\r\n                throw new Error(Utils.Errors.INVALID_END);\r\n            }\r\n\r\n            if (data.readUInt32LE(0) === Constants.ENDSIG) {\r\n                // number of entries on this volume\r\n                _volumeEntries = data.readUInt16LE(Constants.ENDSUB);\r\n                // total number of entries\r\n                _totalEntries = data.readUInt16LE(Constants.ENDTOT);\r\n                // central directory size in bytes\r\n                _size = data.readUInt32LE(Constants.ENDSIZ);\r\n                // offset of first CEN header\r\n                _offset = data.readUInt32LE(Constants.ENDOFF);\r\n                // zip file comment length\r\n                _commentLength = data.readUInt16LE(Constants.ENDCOM);\r\n            } else {\r\n                // number of entries on this volume\r\n                _volumeEntries = Utils.readBigUInt64LE(data, Constants.ZIP64SUB);\r\n                // total number of entries\r\n                _totalEntries = Utils.readBigUInt64LE(data, Constants.ZIP64TOT);\r\n                // central directory size in bytes\r\n                _size = Utils.readBigUInt64LE(data, Constants.ZIP64SIZ);\r\n                // offset of first CEN header\r\n                _offset = Utils.readBigUInt64LE(data, Constants.ZIP64OFF);\r\n\r\n                _commentLength = 0;\r\n            }\r\n\r\n        },\r\n\r\n        toBinary : function() {\r\n           var b = Buffer.alloc(Constants.ENDHDR + _commentLength);\r\n            // \"PK 05 06\" signature\r\n            b.writeUInt32LE(Constants.ENDSIG, 0);\r\n            b.writeUInt32LE(0, 4);\r\n            // number of entries on this volume\r\n            b.writeUInt16LE(_volumeEntries, Constants.ENDSUB);\r\n            // total number of entries\r\n            b.writeUInt16LE(_totalEntries, Constants.ENDTOT);\r\n            // central directory size in bytes\r\n            b.writeUInt32LE(_size, Constants.ENDSIZ);\r\n            // offset of first CEN header\r\n            b.writeUInt32LE(_offset, Constants.ENDOFF);\r\n            // zip file comment length\r\n            b.writeUInt16LE(_commentLength, Constants.ENDCOM);\r\n            // fill comment memory with spaces so no garbage is left there\r\n            b.fill(\" \", Constants.ENDHDR);\r\n\r\n            return b;\r\n        },\r\n\r\n        toString : function() {\r\n            return '{\\n' +\r\n                '\\t\"diskEntries\" : ' + _volumeEntries + \",\\n\" +\r\n                '\\t\"totalEntries\" : ' + _totalEntries + \",\\n\" +\r\n                '\\t\"size\" : ' + _size + \" bytes,\\n\" +\r\n                '\\t\"offset\" : 0x' + _offset.toString(16).toUpperCase() + \",\\n\" +\r\n                '\\t\"commentLength\" : 0x' + _commentLength + \"\\n\" +\r\n            '}';\r\n        }\r\n    }\r\n};","module.exports = function (/*Buffer*/inbuf) {\r\n\r\n  var zlib = require(\"zlib\");\r\n  \r\n  var opts = {chunkSize: (parseInt(inbuf.length / 1024) + 1) * 1024};\r\n  \r\n  return {\r\n    deflate: function () {\r\n      return zlib.deflateRawSync(inbuf, opts);\r\n    },\r\n\r\n    deflateAsync: function (/*Function*/callback) {\r\n      var tmp = zlib.createDeflateRaw(opts), parts = [], total = 0;\r\n      tmp.on('data', function (data) {\r\n        parts.push(data);\r\n        total += data.length;\r\n      });\r\n      tmp.on('end', function () {\r\n        var buf = Buffer.alloc(total), written = 0;\r\n        buf.fill(0);\r\n        for (var i = 0; i < parts.length; i++) {\r\n          var part = parts[i];\r\n          part.copy(buf, written);\r\n          written += part.length;\r\n        }\r\n        callback && callback(buf);\r\n      });\r\n      tmp.end(inbuf);\r\n    }\r\n  }\r\n};\r\n","exports.Deflater = require(\"./deflater\");\r\nexports.Inflater = require(\"./inflater\");\r\nexports.ZipCrypto = require(\"./zipcrypto\");","module.exports = function (/*Buffer*/inbuf) {\r\n\r\n  var zlib = require(\"zlib\");\r\n\r\n  return {\r\n    inflate: function () {\r\n      return zlib.inflateRawSync(inbuf);\r\n    },\r\n\r\n    inflateAsync: function (/*Function*/callback) {\r\n      var tmp = zlib.createInflateRaw(), parts = [], total = 0;\r\n      tmp.on('data', function (data) {\r\n        parts.push(data);\r\n        total += data.length;\r\n      });\r\n      tmp.on('end', function () {\r\n        var buf = Buffer.alloc(total), written = 0;\r\n        buf.fill(0);\r\n        for (var i = 0; i < parts.length; i++) {\r\n          var part = parts[i];\r\n          part.copy(buf, written);\r\n          written += part.length;\r\n        }\r\n        callback && callback(buf);\r\n      });\r\n      tmp.end(inbuf);\r\n    }\r\n  }\r\n};\r\n","// node crypt, we use it for generate salt\r\nconst { randomFillSync } = require(\"crypto\");\r\n\r\n\"use strict\";\r\n\r\n// generate CRC32 lookup table\r\nconst crctable = new Uint32Array(256).map((t, crc) => {\r\n    for (let j = 0; j < 8; j++) {\r\n        if (0 !== (crc & 1)) {\r\n            crc = (crc >>> 1) ^ 0xedb88320;\r\n        } else {\r\n            crc >>>= 1;\r\n        }\r\n    }\r\n    return crc >>> 0;\r\n});\r\n\r\n// C-style uInt32 Multiply (discards higher bits, when JS multiply discards lower bits)\r\nconst uMul = (a, b) => Math.imul(a, b) >>> 0;\r\n\r\n// crc32 byte single update (actually same function is part of utils.crc32 function :) )\r\nconst crc32update = (pCrc32, bval) => {\r\n    return crctable[(pCrc32 ^ bval) & 0xff] ^ (pCrc32 >>> 8);\r\n};\r\n\r\n// function for generating salt for encrytion header\r\nconst genSalt = () => {\r\n    if (\"function\" === typeof randomFillSync) {\r\n        return randomFillSync(Buffer.alloc(12));\r\n    } else {\r\n        // fallback if function is not defined\r\n        return genSalt.node();\r\n    }\r\n};\r\n\r\n// salt generation with node random function (mainly as fallback)\r\ngenSalt.node = () => {\r\n    const salt = Buffer.alloc(12);\r\n    const len = salt.length;\r\n    for (let i = 0; i < len; i++) salt[i] = (Math.random() * 256) & 0xff;\r\n    return salt;\r\n};\r\n\r\n// general config\r\nconst config = {\r\n    genSalt\r\n};\r\n\r\n// Class Initkeys handles same basic ops with keys\r\nfunction Initkeys(pw) {\r\n    const pass = Buffer.isBuffer(pw) ? pw : Buffer.from(pw);\r\n    this.keys = new Uint32Array([0x12345678, 0x23456789, 0x34567890]);\r\n    for (let i = 0; i < pass.length; i++) {\r\n        this.updateKeys(pass[i]);\r\n    }\r\n}\r\n\r\nInitkeys.prototype.updateKeys = function (byteValue) {\r\n    const keys = this.keys;\r\n    keys[0] = crc32update(keys[0], byteValue);\r\n    keys[1] += keys[0] & 0xff;\r\n    keys[1] = uMul(keys[1], 134775813) + 1;\r\n    keys[2] = crc32update(keys[2], keys[1] >>> 24);\r\n    return byteValue;\r\n};\r\n\r\nInitkeys.prototype.next = function () {\r\n    const k = (this.keys[2] | 2) >>> 0; // key\r\n    return (uMul(k, k ^ 1) >> 8) & 0xff; // decode\r\n};\r\n\r\nfunction make_decrypter(/*Buffer*/ pwd) {\r\n    // 1. Stage initialize key\r\n    const keys = new Initkeys(pwd);\r\n\r\n    // return decrypter function\r\n    return function (/*Buffer*/ data) {\r\n        // result - we create new Buffer for results\r\n        const result = Buffer.alloc(data.length);\r\n        let pos = 0;\r\n        // process input data\r\n        for (let c of data) {\r\n            //c ^= keys.next();\r\n            //result[pos++] = c; // decode & Save Value\r\n            result[pos++] = keys.updateKeys(c ^ keys.next()); // update keys with decoded byte\r\n        }\r\n        return result;\r\n    };\r\n}\r\n\r\nfunction make_encrypter(/*Buffer*/ pwd) {\r\n    // 1. Stage initialize key\r\n    const keys = new Initkeys(pwd);\r\n\r\n    // return encrypting function, result and pos is here so we dont have to merge buffers later\r\n    return function (/*Buffer*/ data, /*Buffer*/ result, /* Number */ pos = 0) {\r\n        // result - we create new Buffer for results\r\n        if (!result) result = Buffer.alloc(data.length);\r\n        // process input data\r\n        for (let c of data) {\r\n            const k = keys.next(); // save key byte\r\n            result[pos++] = c ^ k; // save val\r\n            keys.updateKeys(c); // update keys with decoded byte\r\n        }\r\n        return result;\r\n    };\r\n}\r\n\r\nfunction decrypt(/*Buffer*/ data, /*Object*/ header, /*String, Buffer*/ pwd) {\r\n    if (!data || !Buffer.isBuffer(data) || data.length < 12) {\r\n        return Buffer.alloc(0);\r\n    }\r\n\r\n    // 1. We Initialize and generate decrypting function\r\n    const decrypter = make_decrypter(pwd);\r\n\r\n    // 2. decrypt salt what is always 12 bytes and is a part of file content\r\n    const salt = decrypter(data.slice(0, 12));\r\n\r\n    // 3. does password meet expectations\r\n    if (salt[11] !== header.crc >>> 24) {\r\n        throw \"ADM-ZIP: Wrong Password\";\r\n    }\r\n\r\n    // 4. decode content\r\n    return decrypter(data.slice(12));\r\n}\r\n\r\n// lets add way to populate salt, NOT RECOMMENDED for production but maybe useful for testing general functionality\r\nfunction _salter(data) {\r\n    if (Buffer.isBuffer(data) && data.length >= 12) {\r\n        // be aware - currently salting buffer data is modified\r\n        config.genSalt = function () {\r\n            return data.slice(0, 12);\r\n        };\r\n    } else if (data === \"node\") {\r\n        // test salt generation with node random function\r\n        config.genSalt = genSalt.node;\r\n    } else {\r\n        // if value is not acceptable config gets reset.\r\n        config.genSalt = genSalt;\r\n    }\r\n}\r\n\r\nfunction encrypt(/*Buffer*/ data, /*Object*/ header, /*String, Buffer*/ pwd, /*Boolean*/ oldlike = false) {\r\n    // 1. test data if data is not Buffer we make buffer from it\r\n    if (data == null) data = Buffer.alloc(0);\r\n    // if data is not buffer be make buffer from it\r\n    if (!Buffer.isBuffer(data)) data = Buffer.from(data.toString());\r\n\r\n    // 2. We Initialize and generate encrypting function\r\n    const encrypter = make_encrypter(pwd);\r\n\r\n    // 3. generate salt (12-bytes of random data)\r\n    const salt = config.genSalt();\r\n    salt[11] = (header.crc >>> 24) & 0xff;\r\n\r\n    // old implementations (before PKZip 2.04g) used two byte check\r\n    if (oldlike) salt[10] = (header.crc >>> 16) & 0xff;\r\n\r\n    // 4. create output\r\n    const result = Buffer.alloc(data.length + 12);\r\n    encrypter(salt, result);\r\n\r\n    // finally encode content\r\n    return encrypter(data, result, 12);\r\n}\r\n\r\nmodule.exports = { decrypt, encrypt, _salter };\r\n","module.exports = {\r\n    /* The local file header */\r\n    LOCHDR           : 30, // LOC header size\r\n    LOCSIG           : 0x04034b50, // \"PK\\003\\004\"\r\n    LOCVER           : 4,\t// version needed to extract\r\n    LOCFLG           : 6, // general purpose bit flag\r\n    LOCHOW           : 8, // compression method\r\n    LOCTIM           : 10, // modification time (2 bytes time, 2 bytes date)\r\n    LOCCRC           : 14, // uncompressed file crc-32 value\r\n    LOCSIZ           : 18, // compressed size\r\n    LOCLEN           : 22, // uncompressed size\r\n    LOCNAM           : 26, // filename length\r\n    LOCEXT           : 28, // extra field length\r\n\r\n    /* The Data descriptor */\r\n    EXTSIG           : 0x08074b50, // \"PK\\007\\008\"\r\n    EXTHDR           : 16, // EXT header size\r\n    EXTCRC           : 4, // uncompressed file crc-32 value\r\n    EXTSIZ           : 8, // compressed size\r\n    EXTLEN           : 12, // uncompressed size\r\n\r\n    /* The central directory file header */\r\n    CENHDR           : 46, // CEN header size\r\n    CENSIG           : 0x02014b50, // \"PK\\001\\002\"\r\n    CENVEM           : 4, // version made by\r\n    CENVER           : 6, // version needed to extract\r\n    CENFLG           : 8, // encrypt, decrypt flags\r\n    CENHOW           : 10, // compression method\r\n    CENTIM           : 12, // modification time (2 bytes time, 2 bytes date)\r\n    CENCRC           : 16, // uncompressed file crc-32 value\r\n    CENSIZ           : 20, // compressed size\r\n    CENLEN           : 24, // uncompressed size\r\n    CENNAM           : 28, // filename length\r\n    CENEXT           : 30, // extra field length\r\n    CENCOM           : 32, // file comment length\r\n    CENDSK           : 34, // volume number start\r\n    CENATT           : 36, // internal file attributes\r\n    CENATX           : 38, // external file attributes (host system dependent)\r\n    CENOFF           : 42, // LOC header offset\r\n\r\n    /* The entries in the end of central directory */\r\n    ENDHDR           : 22, // END header size\r\n    ENDSIG           : 0x06054b50, // \"PK\\005\\006\"\r\n    ENDSUB           : 8, // number of entries on this disk\r\n    ENDTOT           : 10, // total number of entries\r\n    ENDSIZ           : 12, // central directory size in bytes\r\n    ENDOFF           : 16, // offset of first CEN header\r\n    ENDCOM           : 20, // zip file comment length\r\n\r\n    END64HDR         : 20, // zip64 END header size\r\n    END64SIG         : 0x07064b50, // zip64 Locator signature, \"PK\\006\\007\"\r\n    END64START       : 4, // number of the disk with the start of the zip64\r\n    END64OFF         : 8, // relative offset of the zip64 end of central directory\r\n    END64NUMDISKS    : 16, // total number of disks\r\n\r\n    ZIP64SIG         : 0x06064b50, // zip64 signature, \"PK\\006\\006\"\r\n    ZIP64HDR         : 56, // zip64 record minimum size\r\n    ZIP64LEAD        : 12, // leading bytes at the start of the record, not counted by the value stored in ZIP64SIZE\r\n    ZIP64SIZE        : 4, // zip64 size of the central directory record\r\n    ZIP64VEM         : 12, // zip64 version made by\r\n    ZIP64VER         : 14, // zip64 version needed to extract\r\n    ZIP64DSK         : 16, // zip64 number of this disk\r\n    ZIP64DSKDIR      : 20, // number of the disk with the start of the record directory\r\n    ZIP64SUB         : 24, // number of entries on this disk\r\n    ZIP64TOT         : 32, // total number of entries\r\n    ZIP64SIZB        : 40, // zip64 central directory size in bytes\r\n    ZIP64OFF         : 48, // offset of start of central directory with respect to the starting disk number\r\n    ZIP64EXTRA       : 56, // extensible data sector\r\n\r\n    /* Compression methods */\r\n    STORED           : 0, // no compression\r\n    SHRUNK           : 1, // shrunk\r\n    REDUCED1         : 2, // reduced with compression factor 1\r\n    REDUCED2         : 3, // reduced with compression factor 2\r\n    REDUCED3         : 4, // reduced with compression factor 3\r\n    REDUCED4         : 5, // reduced with compression factor 4\r\n    IMPLODED         : 6, // imploded\r\n    // 7 reserved\r\n    DEFLATED         : 8, // deflated\r\n    ENHANCED_DEFLATED: 9, // enhanced deflated\r\n    PKWARE           : 10,// PKWare DCL imploded\r\n    // 11 reserved\r\n    BZIP2            : 12, //  compressed using BZIP2\r\n    // 13 reserved\r\n    LZMA             : 14, // LZMA\r\n    // 15-17 reserved\r\n    IBM_TERSE        : 18, // compressed using IBM TERSE\r\n    IBM_LZ77         : 19, //IBM LZ77 z\r\n\r\n    /* General purpose bit flag */\r\n    FLG_ENC          : 0,  // encripted file\r\n    FLG_COMP1        : 1,  // compression option\r\n    FLG_COMP2        : 2,  // compression option\r\n    FLG_DESC         : 4,  // data descriptor\r\n    FLG_ENH          : 8,  // enhanced deflation\r\n    FLG_STR          : 16, // strong encryption\r\n    FLG_LNG          : 1024, // language encoding\r\n    FLG_MSK          : 4096, // mask header values\r\n\r\n    /* Load type */\r\n    FILE             : 2,\r\n    BUFFER           : 1,\r\n    NONE             : 0,\r\n\r\n    /* 4.5 Extensible data fields */\r\n    EF_ID            : 0,\r\n    EF_SIZE          : 2,\r\n\r\n    /* Header IDs */\r\n    ID_ZIP64         : 0x0001,\r\n    ID_AVINFO        : 0x0007,\r\n    ID_PFS           : 0x0008,\r\n    ID_OS2           : 0x0009,\r\n    ID_NTFS          : 0x000a,\r\n    ID_OPENVMS       : 0x000c,\r\n    ID_UNIX          : 0x000d,\r\n    ID_FORK          : 0x000e,\r\n    ID_PATCH         : 0x000f,\r\n    ID_X509_PKCS7    : 0x0014,\r\n    ID_X509_CERTID_F : 0x0015,\r\n    ID_X509_CERTID_C : 0x0016,\r\n    ID_STRONGENC     : 0x0017,\r\n    ID_RECORD_MGT    : 0x0018,\r\n    ID_X509_PKCS7_RL : 0x0019,\r\n    ID_IBM1          : 0x0065,\r\n    ID_IBM2          : 0x0066,\r\n    ID_POSZIP        : 0x4690,\r\n\r\n    EF_ZIP64_OR_32   : 0xffffffff,\r\n    EF_ZIP64_OR_16   : 0xffff,\r\n    EF_ZIP64_SUNCOMP : 0,\r\n    EF_ZIP64_SCOMP   : 8,\r\n    EF_ZIP64_RHO     : 16,\r\n    EF_ZIP64_DSN     : 24\r\n};\r\n","module.exports = {\r\n    /* Header error messages */\r\n    \"INVALID_LOC\" : \"Invalid LOC header (bad signature)\",\r\n    \"INVALID_CEN\" : \"Invalid CEN header (bad signature)\",\r\n    \"INVALID_END\" : \"Invalid END header (bad signature)\",\r\n\r\n    /* ZipEntry error messages*/\r\n    \"NO_DATA\" : \"Nothing to decompress\",\r\n    \"BAD_CRC\" : \"CRC32 checksum failed\",\r\n    \"FILE_IN_THE_WAY\" : \"There is a file in the way: %s\",\r\n    \"UNKNOWN_METHOD\" : \"Invalid/unsupported compression method\",\r\n\r\n    /* Inflater error messages */\r\n    \"AVAIL_DATA\" : \"inflate::Available inflate data did not terminate\",\r\n    \"INVALID_DISTANCE\" : \"inflate::Invalid literal/length or distance code in fixed or dynamic block\",\r\n    \"TO_MANY_CODES\" : \"inflate::Dynamic block code description: too many length or distance codes\",\r\n    \"INVALID_REPEAT_LEN\" : \"inflate::Dynamic block code description: repeat more than specified lengths\",\r\n    \"INVALID_REPEAT_FIRST\" : \"inflate::Dynamic block code description: repeat lengths with no first length\",\r\n    \"INCOMPLETE_CODES\" : \"inflate::Dynamic block code description: code lengths codes incomplete\",\r\n    \"INVALID_DYN_DISTANCE\": \"inflate::Dynamic block code description: invalid distance code lengths\",\r\n    \"INVALID_CODES_LEN\": \"inflate::Dynamic block code description: invalid literal/length code lengths\",\r\n    \"INVALID_STORE_BLOCK\" : \"inflate::Stored block length did not match one's complement\",\r\n    \"INVALID_BLOCK_TYPE\" : \"inflate::Invalid block type (type == 3)\",\r\n\r\n    /* ADM-ZIP error messages */\r\n    \"CANT_EXTRACT_FILE\" : \"Could not extract the file\",\r\n    \"CANT_OVERRIDE\" : \"Target file already exists\",\r\n    \"NO_ZIP\" : \"No zip file was loaded\",\r\n    \"NO_ENTRY\" : \"Entry doesn't exist\",\r\n    \"DIRECTORY_CONTENT_ERROR\" : \"A directory cannot have content\",\r\n    \"FILE_NOT_FOUND\" : \"File not found: %s\",\r\n    \"NOT_IMPLEMENTED\" : \"Not implemented\",\r\n    \"INVALID_FILENAME\" : \"Invalid filename\",\r\n    \"INVALID_FORMAT\" : \"Invalid or unsupported zip format. No END header found\"\r\n};","var fs = require(\"./fileSystem\").require(),\r\n    pth = require(\"path\");\r\n\t\r\nfs.existsSync = fs.existsSync || pth.existsSync;\r\n\r\nmodule.exports = function(/*String*/path) {\r\n\r\n    var _path = path || \"\",\r\n        _permissions = 0,\r\n        _obj = newAttr(),\r\n        _stat = null;\r\n\r\n    function newAttr() {\r\n        return {\r\n            directory : false,\r\n            readonly : false,\r\n            hidden : false,\r\n            executable : false,\r\n            mtime : 0,\r\n            atime : 0\r\n        }\r\n    }\r\n\r\n    if (_path && fs.existsSync(_path)) {\r\n        _stat = fs.statSync(_path);\r\n        _obj.directory = _stat.isDirectory();\r\n        _obj.mtime = _stat.mtime;\r\n        _obj.atime = _stat.atime;\r\n        _obj.executable = (0o111 & _stat.mode) != 0;    // file is executable who ever har right not just owner\r\n        _obj.readonly   = (0o200 & _stat.mode) == 0;    // readonly if owner has no write right\r\n        _obj.hidden = pth.basename(_path)[0] === \".\";\r\n    } else {\r\n        console.warn(\"Invalid path: \" + _path)\r\n    }\r\n\r\n    return {\r\n\r\n        get directory () {\r\n            return _obj.directory;\r\n        },\r\n\r\n        get readOnly () {\r\n            return _obj.readonly;\r\n        },\r\n\r\n        get hidden () {\r\n            return _obj.hidden;\r\n        },\r\n\r\n        get mtime () {\r\n            return _obj.mtime;\r\n        },\r\n\r\n        get atime () {\r\n           return _obj.atime;\r\n        },\r\n\r\n\r\n        get executable () {\r\n            return _obj.executable;\r\n        },\r\n\r\n        decodeAttributes : function(val) {\r\n\r\n        },\r\n\r\n        encodeAttributes : function (val) {\r\n\r\n        },\r\n\r\n        toString : function() {\r\n           return '{\\n' +\r\n               '\\t\"path\" : \"' + _path + \",\\n\" +\r\n               '\\t\"isDirectory\" : ' + _obj.directory + \",\\n\" +\r\n               '\\t\"isReadOnly\" : ' + _obj.readonly + \",\\n\" +\r\n               '\\t\"isHidden\" : ' + _obj.hidden + \",\\n\" +\r\n               '\\t\"isExecutable\" : ' + _obj.executable + \",\\n\" +\r\n               '\\t\"mTime\" : ' + _obj.mtime + \"\\n\" +\r\n               '\\t\"aTime\" : ' + _obj.atime + \"\\n\" +\r\n           '}';\r\n        }\r\n    }\r\n\r\n};\r\n","exports.require = function() {\r\n  var fs = require(\"fs\");\r\n  if (process && process.versions && process.versions['electron']) {\r\n\t  try {\r\n\t    originalFs = require(\"original-fs\");\r\n\t    if (Object.keys(originalFs).length > 0) {\r\n\t      fs = originalFs;\r\n      }\r\n\t  } catch (e) {}\r\n  }\r\n  return fs\r\n};\r\n","module.exports = require(\"./utils\");\r\nmodule.exports.FileSystem = require(\"./fileSystem\");\r\nmodule.exports.Constants = require(\"./constants\");\r\nmodule.exports.Errors = require(\"./errors\");\r\nmodule.exports.FileAttr = require(\"./fattr\");","var fs = require(\"./fileSystem\").require(),\r\n    pth = require('path');\r\n\r\nfs.existsSync = fs.existsSync || pth.existsSync;\r\n\r\nmodule.exports = (function() {\r\n\r\n    var crcTable = [],\r\n        Constants = require('./constants'),\r\n        Errors = require('./errors'),\r\n\r\n        PATH_SEPARATOR = pth.sep;\r\n\r\n\r\n    function mkdirSync(/*String*/path) {\r\n        var resolvedPath = path.split(PATH_SEPARATOR)[0];\r\n        path.split(PATH_SEPARATOR).forEach(function(name) {\r\n            if (!name || name.substr(-1,1) === \":\") return;\r\n            resolvedPath += PATH_SEPARATOR + name;\r\n            var stat;\r\n            try {\r\n                stat = fs.statSync(resolvedPath);\r\n            } catch (e) {\r\n                fs.mkdirSync(resolvedPath);\r\n            }\r\n            if (stat && stat.isFile())\r\n                throw Errors.FILE_IN_THE_WAY.replace(\"%s\", resolvedPath);\r\n        });\r\n    }\r\n\r\n    function findSync(/*String*/dir, /*RegExp*/pattern, /*Boolean*/recoursive) {\r\n        if (typeof pattern === 'boolean') {\r\n            recoursive = pattern;\r\n            pattern = undefined;\r\n        }\r\n        var files = [];\r\n        fs.readdirSync(dir).forEach(function(file) {\r\n            var path = pth.join(dir, file);\r\n\r\n            if (fs.statSync(path).isDirectory() && recoursive)\r\n                files = files.concat(findSync(path, pattern, recoursive));\r\n\r\n            if (!pattern || pattern.test(path)) {\r\n                files.push(pth.normalize(path) + (fs.statSync(path).isDirectory() ? PATH_SEPARATOR : \"\"));\r\n            }\r\n\r\n        });\r\n        return files;\r\n    }\r\n\r\n    function readBigUInt64LE(/*Buffer*/buffer, /*int*/index) {\r\n        var slice = Buffer.from(buffer.slice(index, index + 8));\r\n        slice.swap64();\r\n\r\n        return parseInt(`0x${ slice.toString('hex') }`);\r\n    }\r\n\r\n    return {\r\n        makeDir : function(/*String*/path) {\r\n            mkdirSync(path);\r\n        },\r\n\r\n        crc32 : function(buf) {\r\n            if (typeof buf === 'string') {\r\n                buf = Buffer.from(buf);\r\n            }\r\n            var b = Buffer.alloc(4);\r\n            if (!crcTable.length) {\r\n                for (var n = 0; n < 256; n++) {\r\n                    var c = n;\r\n                    for (var k = 8; --k >= 0;)  //\r\n                        if ((c & 1) !== 0)  { c = 0xedb88320 ^ (c >>> 1); } else { c = c >>> 1; }\r\n                    if (c < 0) {\r\n                        b.writeInt32LE(c, 0);\r\n                        c = b.readUInt32LE(0);\r\n                    }\r\n                    crcTable[n] = c;\r\n                }\r\n            }\r\n            var crc = 0, off = 0, len = buf.length, c1 = ~crc;\r\n            while(--len >= 0) c1 = crcTable[(c1 ^ buf[off++]) & 0xff] ^ (c1 >>> 8);\r\n            crc = ~c1;\r\n            b.writeInt32LE(crc & 0xffffffff, 0);\r\n            return b.readUInt32LE(0);\r\n        },\r\n\r\n        methodToString : function(/*Number*/method) {\r\n            switch (method) {\r\n                case Constants.STORED:\r\n                    return 'STORED (' + method + ')';\r\n                case Constants.DEFLATED:\r\n                    return 'DEFLATED (' + method + ')';\r\n                default:\r\n                    return 'UNSUPPORTED (' + method + ')';\r\n            }\r\n\r\n        },\r\n\r\n        writeFileTo : function(/*String*/path, /*Buffer*/content, /*Boolean*/overwrite, /*Number*/attr) {\r\n            if (fs.existsSync(path)) {\r\n                if (!overwrite)\r\n                    return false; // cannot overwrite\r\n\r\n                var stat = fs.statSync(path);\r\n                if (stat.isDirectory()) {\r\n                    return false;\r\n                }\r\n            }\r\n            var folder = pth.dirname(path);\r\n            if (!fs.existsSync(folder)) {\r\n                mkdirSync(folder);\r\n            }\r\n\r\n            var fd;\r\n            try {\r\n                fd = fs.openSync(path, 'w', 438); // 0666\r\n            } catch(e) {\r\n                fs.chmodSync(path, 438);\r\n                fd = fs.openSync(path, 'w', 438);\r\n            }\r\n            if (fd) {\r\n                try {\r\n                    fs.writeSync(fd, content, 0, content.length, 0);\r\n                }\r\n                catch (e){\r\n                    throw e;\r\n                }\r\n                finally {\r\n                    fs.closeSync(fd);\r\n                }\r\n            }\r\n            fs.chmodSync(path, attr || 438);\r\n            return true;\r\n        },\r\n\r\n        writeFileToAsync : function(/*String*/path, /*Buffer*/content, /*Boolean*/overwrite, /*Number*/attr, /*Function*/callback) {\r\n            if(typeof attr === 'function') {\r\n                callback = attr;\r\n                attr = undefined;\r\n            }\r\n\r\n            fs.exists(path, function(exists) {\r\n                if(exists && !overwrite)\r\n                    return callback(false);\r\n\r\n                fs.stat(path, function(err, stat) {\r\n                    if(exists &&stat.isDirectory()) {\r\n                        return callback(false);\r\n                    }\r\n\r\n                    var folder = pth.dirname(path);\r\n                    fs.exists(folder, function(exists) {\r\n                        if(!exists)\r\n                            mkdirSync(folder);\r\n\r\n                        fs.open(path, 'w', 438, function(err, fd) {\r\n                            if(err) {\r\n                                fs.chmod(path, 438, function() {\r\n                                    fs.open(path, 'w', 438, function(err, fd) {\r\n                                        fs.write(fd, content, 0, content.length, 0, function() {\r\n                                            fs.close(fd, function() {\r\n                                                fs.chmod(path, attr || 438, function() {\r\n                                                    callback(true);\r\n                                                })\r\n                                            });\r\n                                        });\r\n                                    });\r\n                                })\r\n                            } else {\r\n                                if(fd) {\r\n                                    fs.write(fd, content, 0, content.length, 0, function() {\r\n                                        fs.close(fd, function() {\r\n                                            fs.chmod(path, attr || 438, function() {\r\n                                                callback(true);\r\n                                            })\r\n                                        });\r\n                                    });\r\n                                } else {\r\n                                    fs.chmod(path, attr || 438, function() {\r\n                                        callback(true);\r\n                                    })\r\n                                }\r\n                            }\r\n                        });\r\n                    })\r\n                })\r\n            })\r\n        },\r\n\r\n        findFiles : function(/*String*/path) {\r\n            return findSync(path, true);\r\n        },\r\n\r\n        getAttributes : function(/*String*/path) {\r\n\r\n        },\r\n\r\n        setAttributes : function(/*String*/path) {\r\n\r\n        },\r\n\r\n        toBuffer : function(input) {\r\n            if (Buffer.isBuffer(input)) {\r\n                return input;\r\n            } else {\r\n                if (input.length === 0) {\r\n                    return Buffer.alloc(0)\r\n                }\r\n                return Buffer.from(input, 'utf8');\r\n            }\r\n        },\r\n\r\n        readBigUInt64LE,\r\n\r\n        Constants : Constants,\r\n        Errors : Errors\r\n    }\r\n})();\r\n","var Utils = require(\"./util\"),\r\n    Headers = require(\"./headers\"),\r\n    Constants = Utils.Constants,\r\n    Methods = require(\"./methods\");\r\n\r\nmodule.exports = function (/*Buffer*/input) {\r\n    var _entryHeader = new Headers.EntryHeader(),\r\n        _entryName = Buffer.alloc(0),\r\n        _comment = Buffer.alloc(0),\r\n        _isDirectory = false,\r\n        uncompressedData = null,\r\n        _extra = Buffer.alloc(0);\r\n\r\n    function getCompressedDataFromZip() {\r\n        if (!input || !Buffer.isBuffer(input)) {\r\n            return Buffer.alloc(0);\r\n        }\r\n        _entryHeader.loadDataHeaderFromBinary(input);\r\n        return input.slice(_entryHeader.realDataOffset, _entryHeader.realDataOffset + _entryHeader.compressedSize)\r\n    }\r\n\r\n    function crc32OK(data) {\r\n        // if bit 3 (0x08) of the general-purpose flags field is set, then the CRC-32 and file sizes are not known when the header is written\r\n        if ((_entryHeader.flags & 0x8) !== 0x8) {\r\n           if (Utils.crc32(data) !== _entryHeader.dataHeader.crc) {\r\n               return false;\r\n           }\r\n        } else {\r\n            // @TODO: load and check data descriptor header\r\n            // The fields in the local header are filled with zero, and the CRC-32 and size are appended in a 12-byte structure\r\n            // (optionally preceded by a 4-byte signature) immediately after the compressed data:\r\n        }\r\n        return true;\r\n    }\r\n\r\n    function decompress(/*Boolean*/async, /*Function*/callback, /*String, Buffer*/pass) {\r\n        if(typeof callback === 'undefined' && typeof async === 'string') {\r\n            pass=async;\r\n            async=void 0;\r\n        }\r\n        if (_isDirectory) {\r\n            if (async && callback) {\r\n                callback(Buffer.alloc(0), Utils.Errors.DIRECTORY_CONTENT_ERROR); //si added error.\r\n            }\r\n            return Buffer.alloc(0);\r\n        }\r\n\r\n        var compressedData = getCompressedDataFromZip();\r\n\r\n        if (compressedData.length === 0) {\r\n            // File is empty, nothing to decompress.\r\n            if (async && callback) callback(compressedData);\r\n            return compressedData;\r\n        }\r\n\r\n        if (_entryHeader.encripted){\r\n            if ('string' !== typeof pass && !Buffer.isBuffer(pass)){\r\n                throw new Error('ADM-ZIP: Incompatible password parameter');\r\n            }\r\n            compressedData = Methods.ZipCrypto.decrypt(compressedData, _entryHeader, pass);\r\n        }\r\n\r\n        var data = Buffer.alloc(_entryHeader.size);\r\n\r\n        switch (_entryHeader.method) {\r\n            case Utils.Constants.STORED:\r\n                compressedData.copy(data);\r\n                if (!crc32OK(data)) {\r\n                    if (async && callback) callback(data, Utils.Errors.BAD_CRC);//si added error\r\n                    throw new Error(Utils.Errors.BAD_CRC);\r\n                } else {//si added otherwise did not seem to return data.\r\n                    if (async && callback) callback(data);\r\n                    return data;\r\n                }\r\n            case Utils.Constants.DEFLATED:\r\n                var inflater = new Methods.Inflater(compressedData);\r\n                if (!async) {\r\n                    var result = inflater.inflate(data);\r\n                    result.copy(data, 0);\r\n                    if (!crc32OK(data)) {\r\n                        throw new Error(Utils.Errors.BAD_CRC + \" \" + _entryName.toString());\r\n                    }\r\n                    return data;\r\n                } else {\r\n                    inflater.inflateAsync(function(result) {\r\n                        result.copy(data, 0);\r\n                        if (!crc32OK(data)) {\r\n                            if (callback) callback(data, Utils.Errors.BAD_CRC); //si added error\r\n                        } else { //si added otherwise did not seem to return data.\r\n                            if (callback) callback(data);\r\n                        }\r\n                    });\r\n                }\r\n                break;\r\n            default:\r\n                if (async && callback) callback(Buffer.alloc(0), Utils.Errors.UNKNOWN_METHOD);\r\n                throw new Error(Utils.Errors.UNKNOWN_METHOD);\r\n        }\r\n    }\r\n\r\n    function compress(/*Boolean*/async, /*Function*/callback) {\r\n        if ((!uncompressedData || !uncompressedData.length) && Buffer.isBuffer(input)) {\r\n            // no data set or the data wasn't changed to require recompression\r\n            if (async && callback) callback(getCompressedDataFromZip());\r\n            return getCompressedDataFromZip();\r\n        }\r\n\r\n        if (uncompressedData.length && !_isDirectory) {\r\n            var compressedData;\r\n            // Local file header\r\n            switch (_entryHeader.method) {\r\n                case Utils.Constants.STORED:\r\n                    _entryHeader.compressedSize = _entryHeader.size;\r\n\r\n                    compressedData = Buffer.alloc(uncompressedData.length);\r\n                    uncompressedData.copy(compressedData);\r\n\r\n                    if (async && callback) callback(compressedData);\r\n                    return compressedData;\r\n                default:\r\n                case Utils.Constants.DEFLATED:\r\n\r\n                    var deflater = new Methods.Deflater(uncompressedData);\r\n                    if (!async) {\r\n                        var deflated = deflater.deflate();\r\n                        _entryHeader.compressedSize = deflated.length;\r\n                        return deflated;\r\n                    } else {\r\n                        deflater.deflateAsync(function(data) {\r\n                            compressedData = Buffer.alloc(data.length);\r\n                            _entryHeader.compressedSize = data.length;\r\n                            data.copy(compressedData);\r\n                            callback && callback(compressedData);\r\n                        });\r\n                    }\r\n                    deflater = null;\r\n                    break;\r\n            }\r\n        } else {\r\n            if (async && callback) {\r\n                callback(Buffer.alloc(0));\r\n            } else {\r\n                return Buffer.alloc(0);\r\n            }\r\n        }\r\n    }\r\n\r\n    function readUInt64LE(buffer, offset) {\r\n        return (buffer.readUInt32LE(offset + 4) << 4) + buffer.readUInt32LE(offset);\r\n    }\r\n\r\n    function parseExtra(data) {\r\n        var offset = 0;\r\n        var signature, size, part;\r\n        while(offset<data.length) {\r\n            signature = data.readUInt16LE(offset);\r\n            offset += 2;\r\n            size = data.readUInt16LE(offset);\r\n            offset += 2;\r\n            part = data.slice(offset, offset+size);\r\n            offset += size;\r\n            if(Constants.ID_ZIP64 === signature) {\r\n                parseZip64ExtendedInformation(part);\r\n            }\r\n        }\r\n    }\r\n\r\n    //Override header field values with values from the ZIP64 extra field\r\n    function parseZip64ExtendedInformation(data) {\r\n        var size, compressedSize, offset, diskNumStart;\r\n\r\n        if(data.length >= Constants.EF_ZIP64_SCOMP) {\r\n            size = readUInt64LE(data, Constants.EF_ZIP64_SUNCOMP);\r\n            if(_entryHeader.size === Constants.EF_ZIP64_OR_32) {\r\n                _entryHeader.size = size;\r\n            }\r\n        }\r\n        if(data.length >= Constants.EF_ZIP64_RHO) {\r\n            compressedSize = readUInt64LE(data, Constants.EF_ZIP64_SCOMP);\r\n            if(_entryHeader.compressedSize === Constants.EF_ZIP64_OR_32) {\r\n                _entryHeader.compressedSize = compressedSize;\r\n            }\r\n        }\r\n        if(data.length >= Constants.EF_ZIP64_DSN) {\r\n            offset = readUInt64LE(data, Constants.EF_ZIP64_RHO);\r\n            if(_entryHeader.offset === Constants.EF_ZIP64_OR_32) {\r\n                _entryHeader.offset = offset;\r\n            }\r\n        }\r\n        if(data.length >= Constants.EF_ZIP64_DSN+4) {\r\n            diskNumStart = data.readUInt32LE(Constants.EF_ZIP64_DSN);\r\n            if(_entryHeader.diskNumStart === Constants.EF_ZIP64_OR_16) {\r\n                _entryHeader.diskNumStart = diskNumStart;\r\n            }\r\n        }\r\n    }\r\n\r\n\r\n    return {\r\n        get entryName () { return _entryName.toString(); },\r\n        get rawEntryName() { return _entryName; },\r\n        set entryName (val) {\r\n            _entryName = Utils.toBuffer(val);\r\n            var lastChar = _entryName[_entryName.length - 1];\r\n            _isDirectory = (lastChar === 47) || (lastChar === 92);\r\n            _entryHeader.fileNameLength = _entryName.length;\r\n        },\r\n\r\n        get extra () { return _extra; },\r\n        set extra (val) {\r\n            _extra = val;\r\n            _entryHeader.extraLength = val.length;\r\n            parseExtra(val);\r\n        },\r\n\r\n        get comment () { return _comment.toString(); },\r\n        set comment (val) {\r\n            _comment = Utils.toBuffer(val);\r\n            _entryHeader.commentLength = _comment.length;\r\n        },\r\n\r\n        get name () { var n = _entryName.toString(); return _isDirectory ? n.substr(n.length - 1).split(\"/\").pop() : n.split(\"/\").pop(); },\r\n        get isDirectory () { return _isDirectory },\r\n\r\n        getCompressedData : function() {\r\n            return compress(false, null)\r\n        },\r\n\r\n        getCompressedDataAsync : function(/*Function*/callback) {\r\n            compress(true, callback)\r\n        },\r\n\r\n        setData : function(value) {\r\n            uncompressedData = Utils.toBuffer(value);\r\n            if (!_isDirectory && uncompressedData.length) {\r\n                _entryHeader.size = uncompressedData.length;\r\n                _entryHeader.method = Utils.Constants.DEFLATED;\r\n                _entryHeader.crc = Utils.crc32(value);\r\n                _entryHeader.changed = true;\r\n            } else { // folders and blank files should be stored\r\n                _entryHeader.method = Utils.Constants.STORED;\r\n            }\r\n        },\r\n\r\n        getData : function(pass) {\r\n            if (_entryHeader.changed) {\r\n                return uncompressedData;\r\n            } else {\r\n                return decompress(false, null, pass);\r\n            }\r\n        },\r\n\r\n        getDataAsync : function(/*Function*/callback, pass) {\r\n            if (_entryHeader.changed) {\r\n                callback(uncompressedData);\r\n            } else {\r\n                decompress(true, callback, pass);\r\n            }\r\n        },\r\n\r\n        set attr(attr) { _entryHeader.attr = attr; },\r\n        get attr() { return _entryHeader.attr; },\r\n\r\n        set header(/*Buffer*/data) {\r\n            _entryHeader.loadFromBinary(data);\r\n        },\r\n\r\n        get header() {\r\n            return _entryHeader;\r\n        },\r\n\r\n        packHeader : function() {\r\n            // 1. create header (buffer)\r\n            var header = _entryHeader.entryHeaderToBinary();\r\n            var addpos = Utils.Constants.CENHDR;\r\n            // 2. add file name\r\n            _entryName.copy(header, addpos);\r\n            addpos += _entryName.length;\r\n            // 3. add extra data\r\n            if (_entryHeader.extraLength) {\r\n                _extra.copy(header, addpos);\r\n                addpos += _entryHeader.extraLength;\r\n            }\r\n            // 4. add file comment\r\n            if (_entryHeader.commentLength) {\r\n                _comment.copy(header, addpos);\r\n            }\r\n            return header;\r\n        },\r\n\r\n        toString : function() {\r\n            return '{\\n' +\r\n                '\\t\"entryName\" : \"' + _entryName.toString() + \"\\\",\\n\" +\r\n                '\\t\"name\" : \"' + (_isDirectory ? _entryName.toString().replace(/\\/$/, '').split(\"/\").pop() : _entryName.toString().split(\"/\").pop()) + \"\\\",\\n\" +\r\n                '\\t\"comment\" : \"' + _comment.toString() + \"\\\",\\n\" +\r\n                '\\t\"isDirectory\" : ' + _isDirectory + \",\\n\" +\r\n                '\\t\"header\" : ' + _entryHeader.toString().replace(/\\t/mg, \"\\t\\t\").replace(/}/mg, \"\\t}\")  + \",\\n\" +\r\n                '\\t\"compressedData\" : <' + (input && input.length  + \" bytes buffer\" || \"null\") + \">\\n\" +\r\n                '\\t\"data\" : <' + (uncompressedData && uncompressedData.length  + \" bytes buffer\" || \"null\") + \">\\n\" +\r\n                '}';\r\n        }\r\n    }\r\n};\r\n","const ZipEntry = require(\"./zipEntry\");\r\nconst Headers = require(\"./headers\");\r\nconst Utils = require(\"./util\");\r\n\r\nmodule.exports = function (/*Buffer|null*/inBuffer, /** object */options) {\r\n    var entryList = [],\r\n        entryTable = {},\r\n        _comment = Buffer.alloc(0),\r\n        mainHeader = new Headers.MainHeader(),\r\n        loadedEntries = false;\r\n\r\n    // assign options\r\n    const opts = Object.assign(Object.create(null), options);\r\n\r\n    if (inBuffer){\r\n        // is a memory buffer\r\n        readMainHeader(opts.readEntries);\r\n    } else {\r\n        // none. is a new file\r\n        loadedEntries = true;\r\n    }\r\n\r\n\tfunction iterateEntries(callback) {\r\n\t\tconst totalEntries = mainHeader.diskEntries; // total number of entries\r\n\t\tlet index = mainHeader.offset; // offset of first CEN header\r\n\r\n\t\tfor (let i = 0; i < totalEntries; i++) {\r\n\t\t\tlet tmp = index;\r\n\t\t\tconst entry = new ZipEntry(inBuffer);\r\n\r\n\t\t\tentry.header = inBuffer.slice(tmp, tmp += Utils.Constants.CENHDR);\r\n\t\t\tentry.entryName = inBuffer.slice(tmp, tmp += entry.header.fileNameLength);\r\n\r\n\t\t\tindex += entry.header.entryHeaderSize;\r\n\r\n\t\t\tcallback(entry);\r\n\t\t}\r\n\t}\r\n\r\n\tfunction readEntries() {\r\n\t\tloadedEntries = true;\r\n\t\tentryTable = {};\r\n\t\tentryList = new Array(mainHeader.diskEntries);  // total number of entries\r\n\t\tvar index = mainHeader.offset;  // offset of first CEN header\r\n\t\tfor (var i = 0; i < entryList.length; i++) {\r\n\r\n\t\t\tvar tmp = index,\r\n\t\t\t\tentry = new ZipEntry(inBuffer);\r\n\t\t\tentry.header = inBuffer.slice(tmp, tmp += Utils.Constants.CENHDR);\r\n\r\n\t\t\tentry.entryName = inBuffer.slice(tmp, tmp += entry.header.fileNameLength);\r\n\r\n\t\t\tif (entry.header.extraLength) {\r\n\t\t\t\tentry.extra = inBuffer.slice(tmp, tmp += entry.header.extraLength);\r\n\t\t\t}\r\n\r\n\t\t\tif (entry.header.commentLength)\r\n\t\t\t\tentry.comment = inBuffer.slice(tmp, tmp + entry.header.commentLength);\r\n\r\n\t\t\tindex += entry.header.entryHeaderSize;\r\n\r\n\t\t\tentryList[i] = entry;\r\n\t\t\tentryTable[entry.entryName] = entry;\r\n\t\t}\r\n\t}\r\n\r\n    function readMainHeader(/*Boolean*/ readNow) {\r\n\t\tvar i = inBuffer.length - Utils.Constants.ENDHDR, // END header size\r\n\t\t\tmax = Math.max(0, i - 0xFFFF), // 0xFFFF is the max zip file comment length\r\n\t\t\tn = max,\r\n\t\t\tendStart = inBuffer.length,\r\n\t\t\tendOffset = -1, // Start offset of the END header\r\n\t\t\tcommentEnd = 0;\r\n\r\n\t\tfor (i; i >= n; i--) {\r\n\t\t\tif (inBuffer[i] !== 0x50) continue; // quick check that the byte is 'P'\r\n\t\t\tif (inBuffer.readUInt32LE(i) === Utils.Constants.ENDSIG) { // \"PK\\005\\006\"\r\n\t\t\t\tendOffset = i;\r\n\t\t\t\tcommentEnd = i;\r\n\t\t\t\tendStart = i + Utils.Constants.ENDHDR;\r\n\t\t\t\t// We already found a regular signature, let's look just a bit further to check if there's any zip64 signature\r\n\t\t\t\tn = i - Utils.Constants.END64HDR;\r\n\t\t\t\tcontinue;\r\n\t\t\t}\r\n\r\n\t\t\tif (inBuffer.readUInt32LE(i) === Utils.Constants.END64SIG) {\r\n\t\t\t\t// Found a zip64 signature, let's continue reading the whole zip64 record\r\n\t\t\t\tn = max;\r\n\t\t\t\tcontinue;\r\n\t\t\t}\r\n\r\n\t\t\tif (inBuffer.readUInt32LE(i) == Utils.Constants.ZIP64SIG) {\r\n\t\t\t\t// Found the zip64 record, let's determine it's size\r\n\t\t\t\tendOffset = i;\r\n\t\t\t\tendStart = i + Utils.readBigUInt64LE(inBuffer, i + Utils.Constants.ZIP64SIZE) + Utils.Constants.ZIP64LEAD;\r\n\t\t\t\tbreak;\r\n\t\t\t}\r\n\t\t}\r\n\r\n\t\tif (!~endOffset)\r\n\t\t\tthrow new Error(Utils.Errors.INVALID_FORMAT);\r\n\r\n\t\tmainHeader.loadFromBinary(inBuffer.slice(endOffset, endStart));\r\n\t\tif (mainHeader.commentLength) {\r\n\t\t\t_comment = inBuffer.slice(commentEnd + Utils.Constants.ENDHDR);\r\n\t\t}\r\n        if (readNow) readEntries();\r\n    }\r\n\r\n\treturn {\r\n\t\t/**\r\n\t\t * Returns an array of ZipEntry objects existent in the current opened archive\r\n\t\t * @return Array\r\n\t\t */\r\n\t\tget entries() {\r\n\t\t\tif (!loadedEntries) {\r\n\t\t\t\treadEntries();\r\n\t\t\t}\r\n\t\t\treturn entryList;\r\n\t\t},\r\n\r\n\t\t/**\r\n\t\t * Archive comment\r\n\t\t * @return {String}\r\n\t\t */\r\n\t\tget comment() {\r\n\t\t\treturn _comment.toString();\r\n\t\t},\r\n\t\tset comment(val) {\r\n\t\t\t_comment = Utils.toBuffer(val);\r\n\t\t\tmainHeader.commentLength = _comment.length;\r\n\t\t},\r\n\r\n\t\tgetEntryCount: function() {\r\n\t\t\tif (!loadedEntries) {\r\n\t\t\t\treturn mainHeader.diskEntries;\r\n\t\t\t}\r\n\r\n\t\t\treturn entryList.length;\r\n\t\t},\r\n\r\n\t\tforEach: function(callback) {\r\n\t\t\tif (!loadedEntries) {\r\n\t\t\t\titerateEntries(callback);\r\n\t\t\t\treturn;\r\n\t\t\t}\r\n\r\n\t\t\tentryList.forEach(callback);\r\n\t\t},\r\n\r\n\t\t/**\r\n\t\t * Returns a reference to the entry with the given name or null if entry is inexistent\r\n\t\t *\r\n\t\t * @param entryName\r\n\t\t * @return ZipEntry\r\n\t\t */\r\n\t\tgetEntry: function (/*String*/entryName) {\r\n\t\t\tif (!loadedEntries) {\r\n\t\t\t\treadEntries();\r\n\t\t\t}\r\n\t\t\treturn entryTable[entryName] || null;\r\n\t\t},\r\n\r\n\t\t/**\r\n\t\t * Adds the given entry to the entry list\r\n\t\t *\r\n\t\t * @param entry\r\n\t\t */\r\n\t\tsetEntry: function (/*ZipEntry*/entry) {\r\n\t\t\tif (!loadedEntries) {\r\n\t\t\t\treadEntries();\r\n\t\t\t}\r\n\t\t\tentryList.push(entry);\r\n\t\t\tentryTable[entry.entryName] = entry;\r\n\t\t\tmainHeader.totalEntries = entryList.length;\r\n\t\t},\r\n\r\n\t\t/**\r\n\t\t * Removes the entry with the given name from the entry list.\r\n\t\t *\r\n\t\t * If the entry is a directory, then all nested files and directories will be removed\r\n\t\t * @param entryName\r\n\t\t */\r\n\t\tdeleteEntry: function (/*String*/entryName) {\r\n\t\t\tif (!loadedEntries) {\r\n\t\t\t\treadEntries();\r\n\t\t\t}\r\n\t\t\tvar entry = entryTable[entryName];\r\n\t\t\tif (entry && entry.isDirectory) {\r\n\t\t\t\tvar _self = this;\r\n\t\t\t\tthis.getEntryChildren(entry).forEach(function (child) {\r\n\t\t\t\t\tif (child.entryName !== entryName) {\r\n\t\t\t\t\t\t_self.deleteEntry(child.entryName)\r\n\t\t\t\t\t}\r\n\t\t\t\t})\r\n\t\t\t}\r\n\t\t\tentryList.splice(entryList.indexOf(entry), 1);\r\n\t\t\tdelete(entryTable[entryName]);\r\n\t\t\tmainHeader.totalEntries = entryList.length;\r\n\t\t},\r\n\r\n\t\t/**\r\n\t\t *  Iterates and returns all nested files and directories of the given entry\r\n\t\t *\r\n\t\t * @param entry\r\n\t\t * @return Array\r\n\t\t */\r\n\t\tgetEntryChildren: function (/*ZipEntry*/entry) {\r\n\t\t\tif (!loadedEntries) {\r\n\t\t\t\treadEntries();\r\n\t\t\t}\r\n\t\t\tif (entry.isDirectory) {\r\n\t\t\t\tvar list = [],\r\n\t\t\t\t\tname = entry.entryName,\r\n\t\t\t\t\tlen = name.length;\r\n\r\n\t\t\t\tentryList.forEach(function (zipEntry) {\r\n\t\t\t\t\tif (zipEntry.entryName.substr(0, len) === name) {\r\n\t\t\t\t\t\tlist.push(zipEntry);\r\n\t\t\t\t\t}\r\n\t\t\t\t});\r\n\t\t\t\treturn list;\r\n\t\t\t}\r\n\t\t\treturn []\r\n\t\t},\r\n\r\n\t\t/**\r\n\t\t * Returns the zip file\r\n\t\t *\r\n\t\t * @return Buffer\r\n\t\t */\r\n\t\tcompressToBuffer: function () {\r\n\t\t\tif (!loadedEntries) {\r\n\t\t\t\treadEntries();\r\n\t\t\t}\r\n\t\t\tif (entryList.length > 1) {\r\n\t\t\t\tentryList.sort(function (a, b) {\r\n\t\t\t\t\tvar nameA = a.entryName.toLowerCase();\r\n\t\t\t\t\tvar nameB = b.entryName.toLowerCase();\r\n\t\t\t\t\tif (nameA < nameB) {\r\n\t\t\t\t\t\treturn -1\r\n\t\t\t\t\t}\r\n\t\t\t\t\tif (nameA > nameB) {\r\n\t\t\t\t\t\treturn 1\r\n\t\t\t\t\t}\r\n\t\t\t\t\treturn 0;\r\n\t\t\t\t});\r\n\t\t\t}\r\n\r\n\t\t\tvar totalSize = 0,\r\n\t\t\t\tdataBlock = [],\r\n\t\t\t\tentryHeaders = [],\r\n\t\t\t\tdindex = 0;\r\n\r\n\t\t\tmainHeader.size = 0;\r\n\t\t\tmainHeader.offset = 0;\r\n\r\n\t\t\tentryList.forEach(function (entry) {\r\n\t\t\t\t// compress data and set local and entry header accordingly. Reason why is called first\r\n\t\t\t\tvar compressedData = entry.getCompressedData();\r\n\t\t\t\t// data header\r\n\t\t\t\tentry.header.offset = dindex;\r\n\t\t\t\tvar dataHeader = entry.header.dataHeaderToBinary();\r\n\t\t\t\tvar entryNameLen = entry.rawEntryName.length;\r\n\t\t\t\tvar extra = entry.extra.toString();\r\n\t\t\t\tvar postHeader = Buffer.alloc(entryNameLen + extra.length);\r\n\t\t\t\tentry.rawEntryName.copy(postHeader, 0);\r\n\t\t\t\tpostHeader.fill(extra, entryNameLen);\r\n\r\n\t\t\t\tvar dataLength = dataHeader.length + postHeader.length + compressedData.length;\r\n\r\n\t\t\t\tdindex += dataLength;\r\n\r\n\t\t\t\tdataBlock.push(dataHeader);\r\n\t\t\t\tdataBlock.push(postHeader);\r\n\t\t\t\tdataBlock.push(compressedData);\r\n\r\n\t\t\t\tvar entryHeader = entry.packHeader();\r\n\t\t\t\tentryHeaders.push(entryHeader);\r\n\t\t\t\tmainHeader.size += entryHeader.length;\r\n\t\t\t\ttotalSize += (dataLength + entryHeader.length);\r\n\t\t\t});\r\n\r\n\t\t\ttotalSize += mainHeader.mainHeaderSize; // also includes zip file comment length\r\n\t\t\t// point to end of data and beginning of central directory first record\r\n\t\t\tmainHeader.offset = dindex;\r\n\r\n\t\t\tdindex = 0;\r\n\t\t\tvar outBuffer = Buffer.alloc(totalSize);\r\n\t\t\tdataBlock.forEach(function (content) {\r\n\t\t\t\tcontent.copy(outBuffer, dindex); // write data blocks\r\n\t\t\t\tdindex += content.length;\r\n\t\t\t});\r\n\t\t\tentryHeaders.forEach(function (content) {\r\n\t\t\t\tcontent.copy(outBuffer, dindex); // write central directory entries\r\n\t\t\t\tdindex += content.length;\r\n\t\t\t});\r\n\r\n\t\t\tvar mh = mainHeader.toBinary();\r\n\t\t\tif (_comment) {\r\n\t\t\t\tBuffer.from(_comment).copy(mh, Utils.Constants.ENDHDR); // add zip file comment\r\n\t\t\t}\r\n\r\n\t\t\tmh.copy(outBuffer, dindex); // write main header\r\n\r\n\t\t\treturn outBuffer;\r\n\t\t},\r\n\r\n\t\ttoAsyncBuffer: function (/*Function*/onSuccess, /*Function*/onFail, /*Function*/onItemStart, /*Function*/onItemEnd) {\r\n\t\t\tif (!loadedEntries) {\r\n\t\t\t\treadEntries();\r\n\t\t\t}\r\n\t\t\tif (entryList.length > 1) {\r\n\t\t\t\tentryList.sort(function (a, b) {\r\n\t\t\t\t\tvar nameA = a.entryName.toLowerCase();\r\n\t\t\t\t\tvar nameB = b.entryName.toLowerCase();\r\n\t\t\t\t\tif (nameA > nameB) {\r\n\t\t\t\t\t\treturn -1\r\n\t\t\t\t\t}\r\n\t\t\t\t\tif (nameA < nameB) {\r\n\t\t\t\t\t\treturn 1\r\n\t\t\t\t\t}\r\n\t\t\t\t\treturn 0;\r\n\t\t\t\t});\r\n\t\t\t}\r\n\r\n\t\t\tvar totalSize = 0,\r\n\t\t\t\tdataBlock = [],\r\n\t\t\t\tentryHeaders = [],\r\n\t\t\t\tdindex = 0;\r\n\r\n\t\t\tmainHeader.size = 0;\r\n\t\t\tmainHeader.offset = 0;\r\n\r\n\t\t\tvar compress = function (entryList) {\r\n\t\t\t\tvar self = arguments.callee;\r\n\t\t\t\tif (entryList.length) {\r\n\t\t\t\t\tvar entry = entryList.pop();\r\n\t\t\t\t\tvar name = entry.entryName + entry.extra.toString();\r\n\t\t\t\t\tif (onItemStart) onItemStart(name);\r\n\t\t\t\t\tentry.getCompressedDataAsync(function (compressedData) {\r\n\t\t\t\t\t\tif (onItemEnd) onItemEnd(name);\r\n\r\n\t\t\t\t\t\tentry.header.offset = dindex;\r\n\t\t\t\t\t\t// data header\r\n\t\t\t\t\t\tvar dataHeader = entry.header.dataHeaderToBinary();\r\n\t\t\t\t\t\tvar postHeader;\r\n\t\t\t\t\t\ttry {\r\n\t\t\t\t\t\t\tpostHeader = Buffer.alloc(name.length, name);  // using alloc will work on node  5.x+\r\n\t\t\t\t\t\t} catch(e){\r\n\t\t\t\t\t\t\tpostHeader = new Buffer(name); // use deprecated method if alloc fails...\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t\tvar dataLength = dataHeader.length + postHeader.length + compressedData.length;\r\n\r\n\t\t\t\t\t\tdindex += dataLength;\r\n\r\n\t\t\t\t\t\tdataBlock.push(dataHeader);\r\n\t\t\t\t\t\tdataBlock.push(postHeader);\r\n\t\t\t\t\t\tdataBlock.push(compressedData);\r\n\r\n\t\t\t\t\t\tvar entryHeader = entry.packHeader();\r\n\t\t\t\t\t\tentryHeaders.push(entryHeader);\r\n\t\t\t\t\t\tmainHeader.size += entryHeader.length;\r\n\t\t\t\t\t\ttotalSize += (dataLength + entryHeader.length);\r\n\r\n\t\t\t\t\t\tif (entryList.length) {\r\n\t\t\t\t\t\t\tself(entryList);\r\n\t\t\t\t\t\t} else {\r\n\r\n\r\n\t\t\t\t\t\t\ttotalSize += mainHeader.mainHeaderSize; // also includes zip file comment length\r\n\t\t\t\t\t\t\t// point to end of data and beginning of central directory first record\r\n\t\t\t\t\t\t\tmainHeader.offset = dindex;\r\n\r\n\t\t\t\t\t\t\tdindex = 0;\r\n\t\t\t\t\t\t\tvar outBuffer = Buffer.alloc(totalSize);\r\n\t\t\t\t\t\t\tdataBlock.forEach(function (content) {\r\n\t\t\t\t\t\t\t\tcontent.copy(outBuffer, dindex); // write data blocks\r\n\t\t\t\t\t\t\t\tdindex += content.length;\r\n\t\t\t\t\t\t\t});\r\n\t\t\t\t\t\t\tentryHeaders.forEach(function (content) {\r\n\t\t\t\t\t\t\t\tcontent.copy(outBuffer, dindex); // write central directory entries\r\n\t\t\t\t\t\t\t\tdindex += content.length;\r\n\t\t\t\t\t\t\t});\r\n\r\n\t\t\t\t\t\t\tvar mh = mainHeader.toBinary();\r\n\t\t\t\t\t\t\tif (_comment) {\r\n\t\t\t\t\t\t\t\t_comment.copy(mh, Utils.Constants.ENDHDR); // add zip file comment\r\n\t\t\t\t\t\t\t}\r\n\r\n\t\t\t\t\t\t\tmh.copy(outBuffer, dindex); // write main header\r\n\r\n\t\t\t\t\t\t\tonSuccess(outBuffer);\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t});\r\n\t\t\t\t}\r\n\t\t\t};\r\n\r\n\t\t\tcompress(entryList);\r\n\t\t}\r\n\t}\r\n};\r\n","var register = require('./lib/register')\nvar addHook = require('./lib/add')\nvar removeHook = require('./lib/remove')\n\n// bind with array of arguments: https://stackoverflow.com/a/21792913\nvar bind = Function.bind\nvar bindable = bind.bind(bind)\n\nfunction bindApi (hook, state, name) {\n  var removeHookRef = bindable(removeHook, null).apply(null, name ? [state, name] : [state])\n  hook.api = { remove: removeHookRef }\n  hook.remove = removeHookRef\n\n  ;['before', 'error', 'after', 'wrap'].forEach(function (kind) {\n    var args = name ? [state, kind, name] : [state, kind]\n    hook[kind] = hook.api[kind] = bindable(addHook, null).apply(null, args)\n  })\n}\n\nfunction HookSingular () {\n  var singularHookName = 'h'\n  var singularHookState = {\n    registry: {}\n  }\n  var singularHook = register.bind(null, singularHookState, singularHookName)\n  bindApi(singularHook, singularHookState, singularHookName)\n  return singularHook\n}\n\nfunction HookCollection () {\n  var state = {\n    registry: {}\n  }\n\n  var hook = register.bind(null, state)\n  bindApi(hook, state)\n\n  return hook\n}\n\nvar collectionHookDeprecationMessageDisplayed = false\nfunction Hook () {\n  if (!collectionHookDeprecationMessageDisplayed) {\n    console.warn('[before-after-hook]: \"Hook()\" repurposing warning, use \"Hook.Collection()\". Read more: https://git.io/upgrade-before-after-hook-to-1.4')\n    collectionHookDeprecationMessageDisplayed = true\n  }\n  return HookCollection()\n}\n\nHook.Singular = HookSingular.bind()\nHook.Collection = HookCollection.bind()\n\nmodule.exports = Hook\n// expose constructors as a named property for TypeScript\nmodule.exports.Hook = Hook\nmodule.exports.Singular = Hook.Singular\nmodule.exports.Collection = Hook.Collection\n","module.exports = addHook;\n\nfunction addHook(state, kind, name, hook) {\n  var orig = hook;\n  if (!state.registry[name]) {\n    state.registry[name] = [];\n  }\n\n  if (kind === \"before\") {\n    hook = function (method, options) {\n      return Promise.resolve()\n        .then(orig.bind(null, options))\n        .then(method.bind(null, options));\n    };\n  }\n\n  if (kind === \"after\") {\n    hook = function (method, options) {\n      var result;\n      return Promise.resolve()\n        .then(method.bind(null, options))\n        .then(function (result_) {\n          result = result_;\n          return orig(result, options);\n        })\n        .then(function () {\n          return result;\n        });\n    };\n  }\n\n  if (kind === \"error\") {\n    hook = function (method, options) {\n      return Promise.resolve()\n        .then(method.bind(null, options))\n        .catch(function (error) {\n          return orig(error, options);\n        });\n    };\n  }\n\n  state.registry[name].push({\n    hook: hook,\n    orig: orig,\n  });\n}\n","module.exports = register;\n\nfunction register(state, name, method, options) {\n  if (typeof method !== \"function\") {\n    throw new Error(\"method for before hook must be a function\");\n  }\n\n  if (!options) {\n    options = {};\n  }\n\n  if (Array.isArray(name)) {\n    return name.reverse().reduce(function (callback, name) {\n      return register.bind(null, state, name, callback, options);\n    }, method)();\n  }\n\n  return Promise.resolve().then(function () {\n    if (!state.registry[name]) {\n      return method(options);\n    }\n\n    return state.registry[name].reduce(function (method, registered) {\n      return registered.hook.bind(null, method, options);\n    }, method)();\n  });\n}\n","module.exports = removeHook;\n\nfunction removeHook(state, name, method) {\n  if (!state.registry[name]) {\n    return;\n  }\n\n  var index = state.registry[name]\n    .map(function (registered) {\n      return registered.orig;\n    })\n    .indexOf(method);\n\n  if (index === -1) {\n    return;\n  }\n\n  state.registry[name].splice(index, 1);\n}\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nclass Deprecation extends Error {\n  constructor(message) {\n    super(message); // Maintains proper stack trace (only available on V8)\n\n    /* istanbul ignore next */\n\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, this.constructor);\n    }\n\n    this.name = 'Deprecation';\n  }\n\n}\n\nexports.Deprecation = Deprecation;\n","'use strict';\n\nvar iconvLite = require('iconv-lite');\n\n// Expose to the world\nmodule.exports.convert = convert;\n\n/**\n * Convert encoding of an UTF-8 string or a buffer\n *\n * @param {String|Buffer} str String to be converted\n * @param {String} to Encoding to be converted to\n * @param {String} [from='UTF-8'] Encoding to be converted from\n * @return {Buffer} Encoded string\n */\nfunction convert(str, to, from) {\n    from = checkEncoding(from || 'UTF-8');\n    to = checkEncoding(to || 'UTF-8');\n    str = str || '';\n\n    var result;\n\n    if (from !== 'UTF-8' && typeof str === 'string') {\n        str = Buffer.from(str, 'binary');\n    }\n\n    if (from === to) {\n        if (typeof str === 'string') {\n            result = Buffer.from(str);\n        } else {\n            result = str;\n        }\n    } else {\n        try {\n            result = convertIconvLite(str, to, from);\n        } catch (E) {\n            console.error(E);\n            result = str;\n        }\n    }\n\n    if (typeof result === 'string') {\n        result = Buffer.from(result, 'utf-8');\n    }\n\n    return result;\n}\n\n/**\n * Convert encoding of astring with iconv-lite\n *\n * @param {String|Buffer} str String to be converted\n * @param {String} to Encoding to be converted to\n * @param {String} [from='UTF-8'] Encoding to be converted from\n * @return {Buffer} Encoded string\n */\nfunction convertIconvLite(str, to, from) {\n    if (to === 'UTF-8') {\n        return iconvLite.decode(str, from);\n    } else if (from === 'UTF-8') {\n        return iconvLite.encode(str, to);\n    } else {\n        return iconvLite.encode(iconvLite.decode(str, from), to);\n    }\n}\n\n/**\n * Converts charset name if needed\n *\n * @param {String} name Character set\n * @return {String} Character set name\n */\nfunction checkEncoding(name) {\n    return (name || '')\n        .toString()\n        .trim()\n        .replace(/^latin[\\-_]?(\\d+)$/i, 'ISO-8859-$1')\n        .replace(/^win(?:dows)?[\\-_]?(\\d+)$/i, 'WINDOWS-$1')\n        .replace(/^utf[\\-_]?(\\d+)$/i, 'UTF-$1')\n        .replace(/^ks_c_5601\\-1987$/i, 'CP949')\n        .replace(/^us[\\-_]?ascii$/i, 'ASCII')\n        .toUpperCase();\n}\n","\"use strict\";\nvar Buffer = require(\"safer-buffer\").Buffer;\n\n// Multibyte codec. In this scheme, a character is represented by 1 or more bytes.\n// Our codec supports UTF-16 surrogates, extensions for GB18030 and unicode sequences.\n// To save memory and loading time, we read table files only when requested.\n\nexports._dbcs = DBCSCodec;\n\nvar UNASSIGNED = -1,\n    GB18030_CODE = -2,\n    SEQ_START  = -10,\n    NODE_START = -1000,\n    UNASSIGNED_NODE = new Array(0x100),\n    DEF_CHAR = -1;\n\nfor (var i = 0; i < 0x100; i++)\n    UNASSIGNED_NODE[i] = UNASSIGNED;\n\n\n// Class DBCSCodec reads and initializes mapping tables.\nfunction DBCSCodec(codecOptions, iconv) {\n    this.encodingName = codecOptions.encodingName;\n    if (!codecOptions)\n        throw new Error(\"DBCS codec is called without the data.\")\n    if (!codecOptions.table)\n        throw new Error(\"Encoding '\" + this.encodingName + \"' has no data.\");\n\n    // Load tables.\n    var mappingTable = codecOptions.table();\n\n\n    // Decode tables: MBCS -> Unicode.\n\n    // decodeTables is a trie, encoded as an array of arrays of integers. Internal arrays are trie nodes and all have len = 256.\n    // Trie root is decodeTables[0].\n    // Values: >=  0 -> unicode character code. can be > 0xFFFF\n    //         == UNASSIGNED -> unknown/unassigned sequence.\n    //         == GB18030_CODE -> this is the end of a GB18030 4-byte sequence.\n    //         <= NODE_START -> index of the next node in our trie to process next byte.\n    //         <= SEQ_START  -> index of the start of a character code sequence, in decodeTableSeq.\n    this.decodeTables = [];\n    this.decodeTables[0] = UNASSIGNED_NODE.slice(0); // Create root node.\n\n    // Sometimes a MBCS char corresponds to a sequence of unicode chars. We store them as arrays of integers here. \n    this.decodeTableSeq = [];\n\n    // Actual mapping tables consist of chunks. Use them to fill up decode tables.\n    for (var i = 0; i < mappingTable.length; i++)\n        this._addDecodeChunk(mappingTable[i]);\n\n    // Load & create GB18030 tables when needed.\n    if (typeof codecOptions.gb18030 === 'function') {\n        this.gb18030 = codecOptions.gb18030(); // Load GB18030 ranges.\n\n        // Add GB18030 common decode nodes.\n        var commonThirdByteNodeIdx = this.decodeTables.length;\n        this.decodeTables.push(UNASSIGNED_NODE.slice(0));\n\n        var commonFourthByteNodeIdx = this.decodeTables.length;\n        this.decodeTables.push(UNASSIGNED_NODE.slice(0));\n\n        // Fill out the tree\n        var firstByteNode = this.decodeTables[0];\n        for (var i = 0x81; i <= 0xFE; i++) {\n            var secondByteNode = this.decodeTables[NODE_START - firstByteNode[i]];\n            for (var j = 0x30; j <= 0x39; j++) {\n                if (secondByteNode[j] === UNASSIGNED) {\n                    secondByteNode[j] = NODE_START - commonThirdByteNodeIdx;\n                } else if (secondByteNode[j] > NODE_START) {\n                    throw new Error(\"gb18030 decode tables conflict at byte 2\");\n                }\n\n                var thirdByteNode = this.decodeTables[NODE_START - secondByteNode[j]];\n                for (var k = 0x81; k <= 0xFE; k++) {\n                    if (thirdByteNode[k] === UNASSIGNED) {\n                        thirdByteNode[k] = NODE_START - commonFourthByteNodeIdx;\n                    } else if (thirdByteNode[k] === NODE_START - commonFourthByteNodeIdx) {\n                        continue;\n                    } else if (thirdByteNode[k] > NODE_START) {\n                        throw new Error(\"gb18030 decode tables conflict at byte 3\");\n                    }\n\n                    var fourthByteNode = this.decodeTables[NODE_START - thirdByteNode[k]];\n                    for (var l = 0x30; l <= 0x39; l++) {\n                        if (fourthByteNode[l] === UNASSIGNED)\n                            fourthByteNode[l] = GB18030_CODE;\n                    }\n                }\n            }\n        }\n    }\n\n    this.defaultCharUnicode = iconv.defaultCharUnicode;\n\n    \n    // Encode tables: Unicode -> DBCS.\n\n    // `encodeTable` is array mapping from unicode char to encoded char. All its values are integers for performance.\n    // Because it can be sparse, it is represented as array of buckets by 256 chars each. Bucket can be null.\n    // Values: >=  0 -> it is a normal char. Write the value (if <=256 then 1 byte, if <=65536 then 2 bytes, etc.).\n    //         == UNASSIGNED -> no conversion found. Output a default char.\n    //         <= SEQ_START  -> it's an index in encodeTableSeq, see below. The character starts a sequence.\n    this.encodeTable = [];\n    \n    // `encodeTableSeq` is used when a sequence of unicode characters is encoded as a single code. We use a tree of\n    // objects where keys correspond to characters in sequence and leafs are the encoded dbcs values. A special DEF_CHAR key\n    // means end of sequence (needed when one sequence is a strict subsequence of another).\n    // Objects are kept separately from encodeTable to increase performance.\n    this.encodeTableSeq = [];\n\n    // Some chars can be decoded, but need not be encoded.\n    var skipEncodeChars = {};\n    if (codecOptions.encodeSkipVals)\n        for (var i = 0; i < codecOptions.encodeSkipVals.length; i++) {\n            var val = codecOptions.encodeSkipVals[i];\n            if (typeof val === 'number')\n                skipEncodeChars[val] = true;\n            else\n                for (var j = val.from; j <= val.to; j++)\n                    skipEncodeChars[j] = true;\n        }\n        \n    // Use decode trie to recursively fill out encode tables.\n    this._fillEncodeTable(0, 0, skipEncodeChars);\n\n    // Add more encoding pairs when needed.\n    if (codecOptions.encodeAdd) {\n        for (var uChar in codecOptions.encodeAdd)\n            if (Object.prototype.hasOwnProperty.call(codecOptions.encodeAdd, uChar))\n                this._setEncodeChar(uChar.charCodeAt(0), codecOptions.encodeAdd[uChar]);\n    }\n\n    this.defCharSB  = this.encodeTable[0][iconv.defaultCharSingleByte.charCodeAt(0)];\n    if (this.defCharSB === UNASSIGNED) this.defCharSB = this.encodeTable[0]['?'];\n    if (this.defCharSB === UNASSIGNED) this.defCharSB = \"?\".charCodeAt(0);\n}\n\nDBCSCodec.prototype.encoder = DBCSEncoder;\nDBCSCodec.prototype.decoder = DBCSDecoder;\n\n// Decoder helpers\nDBCSCodec.prototype._getDecodeTrieNode = function(addr) {\n    var bytes = [];\n    for (; addr > 0; addr >>>= 8)\n        bytes.push(addr & 0xFF);\n    if (bytes.length == 0)\n        bytes.push(0);\n\n    var node = this.decodeTables[0];\n    for (var i = bytes.length-1; i > 0; i--) { // Traverse nodes deeper into the trie.\n        var val = node[bytes[i]];\n\n        if (val == UNASSIGNED) { // Create new node.\n            node[bytes[i]] = NODE_START - this.decodeTables.length;\n            this.decodeTables.push(node = UNASSIGNED_NODE.slice(0));\n        }\n        else if (val <= NODE_START) { // Existing node.\n            node = this.decodeTables[NODE_START - val];\n        }\n        else\n            throw new Error(\"Overwrite byte in \" + this.encodingName + \", addr: \" + addr.toString(16));\n    }\n    return node;\n}\n\n\nDBCSCodec.prototype._addDecodeChunk = function(chunk) {\n    // First element of chunk is the hex mbcs code where we start.\n    var curAddr = parseInt(chunk[0], 16);\n\n    // Choose the decoding node where we'll write our chars.\n    var writeTable = this._getDecodeTrieNode(curAddr);\n    curAddr = curAddr & 0xFF;\n\n    // Write all other elements of the chunk to the table.\n    for (var k = 1; k < chunk.length; k++) {\n        var part = chunk[k];\n        if (typeof part === \"string\") { // String, write as-is.\n            for (var l = 0; l < part.length;) {\n                var code = part.charCodeAt(l++);\n                if (0xD800 <= code && code < 0xDC00) { // Decode surrogate\n                    var codeTrail = part.charCodeAt(l++);\n                    if (0xDC00 <= codeTrail && codeTrail < 0xE000)\n                        writeTable[curAddr++] = 0x10000 + (code - 0xD800) * 0x400 + (codeTrail - 0xDC00);\n                    else\n                        throw new Error(\"Incorrect surrogate pair in \"  + this.encodingName + \" at chunk \" + chunk[0]);\n                }\n                else if (0x0FF0 < code && code <= 0x0FFF) { // Character sequence (our own encoding used)\n                    var len = 0xFFF - code + 2;\n                    var seq = [];\n                    for (var m = 0; m < len; m++)\n                        seq.push(part.charCodeAt(l++)); // Simple variation: don't support surrogates or subsequences in seq.\n\n                    writeTable[curAddr++] = SEQ_START - this.decodeTableSeq.length;\n                    this.decodeTableSeq.push(seq);\n                }\n                else\n                    writeTable[curAddr++] = code; // Basic char\n            }\n        } \n        else if (typeof part === \"number\") { // Integer, meaning increasing sequence starting with prev character.\n            var charCode = writeTable[curAddr - 1] + 1;\n            for (var l = 0; l < part; l++)\n                writeTable[curAddr++] = charCode++;\n        }\n        else\n            throw new Error(\"Incorrect type '\" + typeof part + \"' given in \"  + this.encodingName + \" at chunk \" + chunk[0]);\n    }\n    if (curAddr > 0xFF)\n        throw new Error(\"Incorrect chunk in \"  + this.encodingName + \" at addr \" + chunk[0] + \": too long\" + curAddr);\n}\n\n// Encoder helpers\nDBCSCodec.prototype._getEncodeBucket = function(uCode) {\n    var high = uCode >> 8; // This could be > 0xFF because of astral characters.\n    if (this.encodeTable[high] === undefined)\n        this.encodeTable[high] = UNASSIGNED_NODE.slice(0); // Create bucket on demand.\n    return this.encodeTable[high];\n}\n\nDBCSCodec.prototype._setEncodeChar = function(uCode, dbcsCode) {\n    var bucket = this._getEncodeBucket(uCode);\n    var low = uCode & 0xFF;\n    if (bucket[low] <= SEQ_START)\n        this.encodeTableSeq[SEQ_START-bucket[low]][DEF_CHAR] = dbcsCode; // There's already a sequence, set a single-char subsequence of it.\n    else if (bucket[low] == UNASSIGNED)\n        bucket[low] = dbcsCode;\n}\n\nDBCSCodec.prototype._setEncodeSequence = function(seq, dbcsCode) {\n    \n    // Get the root of character tree according to first character of the sequence.\n    var uCode = seq[0];\n    var bucket = this._getEncodeBucket(uCode);\n    var low = uCode & 0xFF;\n\n    var node;\n    if (bucket[low] <= SEQ_START) {\n        // There's already a sequence with  - use it.\n        node = this.encodeTableSeq[SEQ_START-bucket[low]];\n    }\n    else {\n        // There was no sequence object - allocate a new one.\n        node = {};\n        if (bucket[low] !== UNASSIGNED) node[DEF_CHAR] = bucket[low]; // If a char was set before - make it a single-char subsequence.\n        bucket[low] = SEQ_START - this.encodeTableSeq.length;\n        this.encodeTableSeq.push(node);\n    }\n\n    // Traverse the character tree, allocating new nodes as needed.\n    for (var j = 1; j < seq.length-1; j++) {\n        var oldVal = node[uCode];\n        if (typeof oldVal === 'object')\n            node = oldVal;\n        else {\n            node = node[uCode] = {}\n            if (oldVal !== undefined)\n                node[DEF_CHAR] = oldVal\n        }\n    }\n\n    // Set the leaf to given dbcsCode.\n    uCode = seq[seq.length-1];\n    node[uCode] = dbcsCode;\n}\n\nDBCSCodec.prototype._fillEncodeTable = function(nodeIdx, prefix, skipEncodeChars) {\n    var node = this.decodeTables[nodeIdx];\n    var hasValues = false;\n    var subNodeEmpty = {};\n    for (var i = 0; i < 0x100; i++) {\n        var uCode = node[i];\n        var mbCode = prefix + i;\n        if (skipEncodeChars[mbCode])\n            continue;\n\n        if (uCode >= 0) {\n            this._setEncodeChar(uCode, mbCode);\n            hasValues = true;\n        } else if (uCode <= NODE_START) {\n            var subNodeIdx = NODE_START - uCode;\n            if (!subNodeEmpty[subNodeIdx]) {  // Skip empty subtrees (they are too large in gb18030).\n                var newPrefix = (mbCode << 8) >>> 0;  // NOTE: '>>> 0' keeps 32-bit num positive.\n                if (this._fillEncodeTable(subNodeIdx, newPrefix, skipEncodeChars))\n                    hasValues = true;\n                else\n                    subNodeEmpty[subNodeIdx] = true;\n            }\n        } else if (uCode <= SEQ_START) {\n            this._setEncodeSequence(this.decodeTableSeq[SEQ_START - uCode], mbCode);\n            hasValues = true;\n        }\n    }\n    return hasValues;\n}\n\n\n\n// == Encoder ==================================================================\n\nfunction DBCSEncoder(options, codec) {\n    // Encoder state\n    this.leadSurrogate = -1;\n    this.seqObj = undefined;\n    \n    // Static data\n    this.encodeTable = codec.encodeTable;\n    this.encodeTableSeq = codec.encodeTableSeq;\n    this.defaultCharSingleByte = codec.defCharSB;\n    this.gb18030 = codec.gb18030;\n}\n\nDBCSEncoder.prototype.write = function(str) {\n    var newBuf = Buffer.alloc(str.length * (this.gb18030 ? 4 : 3)),\n        leadSurrogate = this.leadSurrogate,\n        seqObj = this.seqObj, nextChar = -1,\n        i = 0, j = 0;\n\n    while (true) {\n        // 0. Get next character.\n        if (nextChar === -1) {\n            if (i == str.length) break;\n            var uCode = str.charCodeAt(i++);\n        }\n        else {\n            var uCode = nextChar;\n            nextChar = -1;    \n        }\n\n        // 1. Handle surrogates.\n        if (0xD800 <= uCode && uCode < 0xE000) { // Char is one of surrogates.\n            if (uCode < 0xDC00) { // We've got lead surrogate.\n                if (leadSurrogate === -1) {\n                    leadSurrogate = uCode;\n                    continue;\n                } else {\n                    leadSurrogate = uCode;\n                    // Double lead surrogate found.\n                    uCode = UNASSIGNED;\n                }\n            } else { // We've got trail surrogate.\n                if (leadSurrogate !== -1) {\n                    uCode = 0x10000 + (leadSurrogate - 0xD800) * 0x400 + (uCode - 0xDC00);\n                    leadSurrogate = -1;\n                } else {\n                    // Incomplete surrogate pair - only trail surrogate found.\n                    uCode = UNASSIGNED;\n                }\n                \n            }\n        }\n        else if (leadSurrogate !== -1) {\n            // Incomplete surrogate pair - only lead surrogate found.\n            nextChar = uCode; uCode = UNASSIGNED; // Write an error, then current char.\n            leadSurrogate = -1;\n        }\n\n        // 2. Convert uCode character.\n        var dbcsCode = UNASSIGNED;\n        if (seqObj !== undefined && uCode != UNASSIGNED) { // We are in the middle of the sequence\n            var resCode = seqObj[uCode];\n            if (typeof resCode === 'object') { // Sequence continues.\n                seqObj = resCode;\n                continue;\n\n            } else if (typeof resCode == 'number') { // Sequence finished. Write it.\n                dbcsCode = resCode;\n\n            } else if (resCode == undefined) { // Current character is not part of the sequence.\n\n                // Try default character for this sequence\n                resCode = seqObj[DEF_CHAR];\n                if (resCode !== undefined) {\n                    dbcsCode = resCode; // Found. Write it.\n                    nextChar = uCode; // Current character will be written too in the next iteration.\n\n                } else {\n                    // TODO: What if we have no default? (resCode == undefined)\n                    // Then, we should write first char of the sequence as-is and try the rest recursively.\n                    // Didn't do it for now because no encoding has this situation yet.\n                    // Currently, just skip the sequence and write current char.\n                }\n            }\n            seqObj = undefined;\n        }\n        else if (uCode >= 0) {  // Regular character\n            var subtable = this.encodeTable[uCode >> 8];\n            if (subtable !== undefined)\n                dbcsCode = subtable[uCode & 0xFF];\n            \n            if (dbcsCode <= SEQ_START) { // Sequence start\n                seqObj = this.encodeTableSeq[SEQ_START-dbcsCode];\n                continue;\n            }\n\n            if (dbcsCode == UNASSIGNED && this.gb18030) {\n                // Use GB18030 algorithm to find character(s) to write.\n                var idx = findIdx(this.gb18030.uChars, uCode);\n                if (idx != -1) {\n                    var dbcsCode = this.gb18030.gbChars[idx] + (uCode - this.gb18030.uChars[idx]);\n                    newBuf[j++] = 0x81 + Math.floor(dbcsCode / 12600); dbcsCode = dbcsCode % 12600;\n                    newBuf[j++] = 0x30 + Math.floor(dbcsCode / 1260); dbcsCode = dbcsCode % 1260;\n                    newBuf[j++] = 0x81 + Math.floor(dbcsCode / 10); dbcsCode = dbcsCode % 10;\n                    newBuf[j++] = 0x30 + dbcsCode;\n                    continue;\n                }\n            }\n        }\n\n        // 3. Write dbcsCode character.\n        if (dbcsCode === UNASSIGNED)\n            dbcsCode = this.defaultCharSingleByte;\n        \n        if (dbcsCode < 0x100) {\n            newBuf[j++] = dbcsCode;\n        }\n        else if (dbcsCode < 0x10000) {\n            newBuf[j++] = dbcsCode >> 8;   // high byte\n            newBuf[j++] = dbcsCode & 0xFF; // low byte\n        }\n        else if (dbcsCode < 0x1000000) {\n            newBuf[j++] = dbcsCode >> 16;\n            newBuf[j++] = (dbcsCode >> 8) & 0xFF;\n            newBuf[j++] = dbcsCode & 0xFF;\n        } else {\n            newBuf[j++] = dbcsCode >>> 24;\n            newBuf[j++] = (dbcsCode >>> 16) & 0xFF;\n            newBuf[j++] = (dbcsCode >>> 8) & 0xFF;\n            newBuf[j++] = dbcsCode & 0xFF;\n        }\n    }\n\n    this.seqObj = seqObj;\n    this.leadSurrogate = leadSurrogate;\n    return newBuf.slice(0, j);\n}\n\nDBCSEncoder.prototype.end = function() {\n    if (this.leadSurrogate === -1 && this.seqObj === undefined)\n        return; // All clean. Most often case.\n\n    var newBuf = Buffer.alloc(10), j = 0;\n\n    if (this.seqObj) { // We're in the sequence.\n        var dbcsCode = this.seqObj[DEF_CHAR];\n        if (dbcsCode !== undefined) { // Write beginning of the sequence.\n            if (dbcsCode < 0x100) {\n                newBuf[j++] = dbcsCode;\n            }\n            else {\n                newBuf[j++] = dbcsCode >> 8;   // high byte\n                newBuf[j++] = dbcsCode & 0xFF; // low byte\n            }\n        } else {\n            // See todo above.\n        }\n        this.seqObj = undefined;\n    }\n\n    if (this.leadSurrogate !== -1) {\n        // Incomplete surrogate pair - only lead surrogate found.\n        newBuf[j++] = this.defaultCharSingleByte;\n        this.leadSurrogate = -1;\n    }\n    \n    return newBuf.slice(0, j);\n}\n\n// Export for testing\nDBCSEncoder.prototype.findIdx = findIdx;\n\n\n// == Decoder ==================================================================\n\nfunction DBCSDecoder(options, codec) {\n    // Decoder state\n    this.nodeIdx = 0;\n    this.prevBytes = [];\n\n    // Static data\n    this.decodeTables = codec.decodeTables;\n    this.decodeTableSeq = codec.decodeTableSeq;\n    this.defaultCharUnicode = codec.defaultCharUnicode;\n    this.gb18030 = codec.gb18030;\n}\n\nDBCSDecoder.prototype.write = function(buf) {\n    var newBuf = Buffer.alloc(buf.length*2),\n        nodeIdx = this.nodeIdx, \n        prevBytes = this.prevBytes, prevOffset = this.prevBytes.length,\n        seqStart = -this.prevBytes.length, // idx of the start of current parsed sequence.\n        uCode;\n\n    for (var i = 0, j = 0; i < buf.length; i++) {\n        var curByte = (i >= 0) ? buf[i] : prevBytes[i + prevOffset];\n\n        // Lookup in current trie node.\n        var uCode = this.decodeTables[nodeIdx][curByte];\n\n        if (uCode >= 0) { \n            // Normal character, just use it.\n        }\n        else if (uCode === UNASSIGNED) { // Unknown char.\n            // TODO: Callback with seq.\n            uCode = this.defaultCharUnicode.charCodeAt(0);\n            i = seqStart; // Skip one byte ('i' will be incremented by the for loop) and try to parse again.\n        }\n        else if (uCode === GB18030_CODE) {\n            if (i >= 3) {\n                var ptr = (buf[i-3]-0x81)*12600 + (buf[i-2]-0x30)*1260 + (buf[i-1]-0x81)*10 + (curByte-0x30);\n            } else {\n                var ptr = (prevBytes[i-3+prevOffset]-0x81)*12600 + \n                          (((i-2 >= 0) ? buf[i-2] : prevBytes[i-2+prevOffset])-0x30)*1260 + \n                          (((i-1 >= 0) ? buf[i-1] : prevBytes[i-1+prevOffset])-0x81)*10 + \n                          (curByte-0x30);\n            }\n            var idx = findIdx(this.gb18030.gbChars, ptr);\n            uCode = this.gb18030.uChars[idx] + ptr - this.gb18030.gbChars[idx];\n        }\n        else if (uCode <= NODE_START) { // Go to next trie node.\n            nodeIdx = NODE_START - uCode;\n            continue;\n        }\n        else if (uCode <= SEQ_START) { // Output a sequence of chars.\n            var seq = this.decodeTableSeq[SEQ_START - uCode];\n            for (var k = 0; k < seq.length - 1; k++) {\n                uCode = seq[k];\n                newBuf[j++] = uCode & 0xFF;\n                newBuf[j++] = uCode >> 8;\n            }\n            uCode = seq[seq.length-1];\n        }\n        else\n            throw new Error(\"iconv-lite internal error: invalid decoding table value \" + uCode + \" at \" + nodeIdx + \"/\" + curByte);\n\n        // Write the character to buffer, handling higher planes using surrogate pair.\n        if (uCode >= 0x10000) { \n            uCode -= 0x10000;\n            var uCodeLead = 0xD800 | (uCode >> 10);\n            newBuf[j++] = uCodeLead & 0xFF;\n            newBuf[j++] = uCodeLead >> 8;\n\n            uCode = 0xDC00 | (uCode & 0x3FF);\n        }\n        newBuf[j++] = uCode & 0xFF;\n        newBuf[j++] = uCode >> 8;\n\n        // Reset trie node.\n        nodeIdx = 0; seqStart = i+1;\n    }\n\n    this.nodeIdx = nodeIdx;\n    this.prevBytes = (seqStart >= 0)\n        ? Array.prototype.slice.call(buf, seqStart)\n        : prevBytes.slice(seqStart + prevOffset).concat(Array.prototype.slice.call(buf));\n\n    return newBuf.slice(0, j).toString('ucs2');\n}\n\nDBCSDecoder.prototype.end = function() {\n    var ret = '';\n\n    // Try to parse all remaining chars.\n    while (this.prevBytes.length > 0) {\n        // Skip 1 character in the buffer.\n        ret += this.defaultCharUnicode;\n        var bytesArr = this.prevBytes.slice(1);\n\n        // Parse remaining as usual.\n        this.prevBytes = [];\n        this.nodeIdx = 0;\n        if (bytesArr.length > 0)\n            ret += this.write(bytesArr);\n    }\n\n    this.prevBytes = [];\n    this.nodeIdx = 0;\n    return ret;\n}\n\n// Binary search for GB18030. Returns largest i such that table[i] <= val.\nfunction findIdx(table, val) {\n    if (table[0] > val)\n        return -1;\n\n    var l = 0, r = table.length;\n    while (l < r-1) { // always table[l] <= val < table[r]\n        var mid = l + ((r-l+1) >> 1);\n        if (table[mid] <= val)\n            l = mid;\n        else\n            r = mid;\n    }\n    return l;\n}\n\n","\"use strict\";\n\n// Description of supported double byte encodings and aliases.\n// Tables are not require()-d until they are needed to speed up library load.\n// require()-s are direct to support Browserify.\n\nmodule.exports = {\n    \n    // == Japanese/ShiftJIS ====================================================\n    // All japanese encodings are based on JIS X set of standards:\n    // JIS X 0201 - Single-byte encoding of ASCII + ¥ + Kana chars at 0xA1-0xDF.\n    // JIS X 0208 - Main set of 6879 characters, placed in 94x94 plane, to be encoded by 2 bytes. \n    //              Has several variations in 1978, 1983, 1990 and 1997.\n    // JIS X 0212 - Supplementary plane of 6067 chars in 94x94 plane. 1990. Effectively dead.\n    // JIS X 0213 - Extension and modern replacement of 0208 and 0212. Total chars: 11233.\n    //              2 planes, first is superset of 0208, second - revised 0212.\n    //              Introduced in 2000, revised 2004. Some characters are in Unicode Plane 2 (0x2xxxx)\n\n    // Byte encodings are:\n    //  * Shift_JIS: Compatible with 0201, uses not defined chars in top half as lead bytes for double-byte\n    //               encoding of 0208. Lead byte ranges: 0x81-0x9F, 0xE0-0xEF; Trail byte ranges: 0x40-0x7E, 0x80-0x9E, 0x9F-0xFC.\n    //               Windows CP932 is a superset of Shift_JIS. Some companies added more chars, notably KDDI.\n    //  * EUC-JP:    Up to 3 bytes per character. Used mostly on *nixes.\n    //               0x00-0x7F       - lower part of 0201\n    //               0x8E, 0xA1-0xDF - upper part of 0201\n    //               (0xA1-0xFE)x2   - 0208 plane (94x94).\n    //               0x8F, (0xA1-0xFE)x2 - 0212 plane (94x94).\n    //  * JIS X 208: 7-bit, direct encoding of 0208. Byte ranges: 0x21-0x7E (94 values). Uncommon.\n    //               Used as-is in ISO2022 family.\n    //  * ISO2022-JP: Stateful encoding, with escape sequences to switch between ASCII, \n    //                0201-1976 Roman, 0208-1978, 0208-1983.\n    //  * ISO2022-JP-1: Adds esc seq for 0212-1990.\n    //  * ISO2022-JP-2: Adds esc seq for GB2313-1980, KSX1001-1992, ISO8859-1, ISO8859-7.\n    //  * ISO2022-JP-3: Adds esc seq for 0201-1976 Kana set, 0213-2000 Planes 1, 2.\n    //  * ISO2022-JP-2004: Adds 0213-2004 Plane 1.\n    //\n    // After JIS X 0213 appeared, Shift_JIS-2004, EUC-JISX0213 and ISO2022-JP-2004 followed, with just changing the planes.\n    //\n    // Overall, it seems that it's a mess :( http://www8.plala.or.jp/tkubota1/unicode-symbols-map2.html\n\n    'shiftjis': {\n        type: '_dbcs',\n        table: function() { return require('./tables/shiftjis.json') },\n        encodeAdd: {'\\u00a5': 0x5C, '\\u203E': 0x7E},\n        encodeSkipVals: [{from: 0xED40, to: 0xF940}],\n    },\n    'csshiftjis': 'shiftjis',\n    'mskanji': 'shiftjis',\n    'sjis': 'shiftjis',\n    'windows31j': 'shiftjis',\n    'ms31j': 'shiftjis',\n    'xsjis': 'shiftjis',\n    'windows932': 'shiftjis',\n    'ms932': 'shiftjis',\n    '932': 'shiftjis',\n    'cp932': 'shiftjis',\n\n    'eucjp': {\n        type: '_dbcs',\n        table: function() { return require('./tables/eucjp.json') },\n        encodeAdd: {'\\u00a5': 0x5C, '\\u203E': 0x7E},\n    },\n\n    // TODO: KDDI extension to Shift_JIS\n    // TODO: IBM CCSID 942 = CP932, but F0-F9 custom chars and other char changes.\n    // TODO: IBM CCSID 943 = Shift_JIS = CP932 with original Shift_JIS lower 128 chars.\n\n\n    // == Chinese/GBK ==========================================================\n    // http://en.wikipedia.org/wiki/GBK\n    // We mostly implement W3C recommendation: https://www.w3.org/TR/encoding/#gbk-encoder\n\n    // Oldest GB2312 (1981, ~7600 chars) is a subset of CP936\n    'gb2312': 'cp936',\n    'gb231280': 'cp936',\n    'gb23121980': 'cp936',\n    'csgb2312': 'cp936',\n    'csiso58gb231280': 'cp936',\n    'euccn': 'cp936',\n\n    // Microsoft's CP936 is a subset and approximation of GBK.\n    'windows936': 'cp936',\n    'ms936': 'cp936',\n    '936': 'cp936',\n    'cp936': {\n        type: '_dbcs',\n        table: function() { return require('./tables/cp936.json') },\n    },\n\n    // GBK (~22000 chars) is an extension of CP936 that added user-mapped chars and some other.\n    'gbk': {\n        type: '_dbcs',\n        table: function() { return require('./tables/cp936.json').concat(require('./tables/gbk-added.json')) },\n    },\n    'xgbk': 'gbk',\n    'isoir58': 'gbk',\n\n    // GB18030 is an algorithmic extension of GBK.\n    // Main source: https://www.w3.org/TR/encoding/#gbk-encoder\n    // http://icu-project.org/docs/papers/gb18030.html\n    // http://source.icu-project.org/repos/icu/data/trunk/charset/data/xml/gb-18030-2000.xml\n    // http://www.khngai.com/chinese/charmap/tblgbk.php?page=0\n    'gb18030': {\n        type: '_dbcs',\n        table: function() { return require('./tables/cp936.json').concat(require('./tables/gbk-added.json')) },\n        gb18030: function() { return require('./tables/gb18030-ranges.json') },\n        encodeSkipVals: [0x80],\n        encodeAdd: {'€': 0xA2E3},\n    },\n\n    'chinese': 'gb18030',\n\n\n    // == Korean ===============================================================\n    // EUC-KR, KS_C_5601 and KS X 1001 are exactly the same.\n    'windows949': 'cp949',\n    'ms949': 'cp949',\n    '949': 'cp949',\n    'cp949': {\n        type: '_dbcs',\n        table: function() { return require('./tables/cp949.json') },\n    },\n\n    'cseuckr': 'cp949',\n    'csksc56011987': 'cp949',\n    'euckr': 'cp949',\n    'isoir149': 'cp949',\n    'korean': 'cp949',\n    'ksc56011987': 'cp949',\n    'ksc56011989': 'cp949',\n    'ksc5601': 'cp949',\n\n\n    // == Big5/Taiwan/Hong Kong ================================================\n    // There are lots of tables for Big5 and cp950. Please see the following links for history:\n    // http://moztw.org/docs/big5/  http://www.haible.de/bruno/charsets/conversion-tables/Big5.html\n    // Variations, in roughly number of defined chars:\n    //  * Windows CP 950: Microsoft variant of Big5. Canonical: http://www.unicode.org/Public/MAPPINGS/VENDORS/MICSFT/WINDOWS/CP950.TXT\n    //  * Windows CP 951: Microsoft variant of Big5-HKSCS-2001. Seems to be never public. http://me.abelcheung.org/articles/research/what-is-cp951/\n    //  * Big5-2003 (Taiwan standard) almost superset of cp950.\n    //  * Unicode-at-on (UAO) / Mozilla 1.8. Falling out of use on the Web. Not supported by other browsers.\n    //  * Big5-HKSCS (-2001, -2004, -2008). Hong Kong standard. \n    //    many unicode code points moved from PUA to Supplementary plane (U+2XXXX) over the years.\n    //    Plus, it has 4 combining sequences.\n    //    Seems that Mozilla refused to support it for 10 yrs. https://bugzilla.mozilla.org/show_bug.cgi?id=162431 https://bugzilla.mozilla.org/show_bug.cgi?id=310299\n    //    because big5-hkscs is the only encoding to include astral characters in non-algorithmic way.\n    //    Implementations are not consistent within browsers; sometimes labeled as just big5.\n    //    MS Internet Explorer switches from big5 to big5-hkscs when a patch applied.\n    //    Great discussion & recap of what's going on https://bugzilla.mozilla.org/show_bug.cgi?id=912470#c31\n    //    In the encoder, it might make sense to support encoding old PUA mappings to Big5 bytes seq-s.\n    //    Official spec: http://www.ogcio.gov.hk/en/business/tech_promotion/ccli/terms/doc/2003cmp_2008.txt\n    //                   http://www.ogcio.gov.hk/tc/business/tech_promotion/ccli/terms/doc/hkscs-2008-big5-iso.txt\n    // \n    // Current understanding of how to deal with Big5(-HKSCS) is in the Encoding Standard, http://encoding.spec.whatwg.org/#big5-encoder\n    // Unicode mapping (http://www.unicode.org/Public/MAPPINGS/OBSOLETE/EASTASIA/OTHER/BIG5.TXT) is said to be wrong.\n\n    'windows950': 'cp950',\n    'ms950': 'cp950',\n    '950': 'cp950',\n    'cp950': {\n        type: '_dbcs',\n        table: function() { return require('./tables/cp950.json') },\n    },\n\n    // Big5 has many variations and is an extension of cp950. We use Encoding Standard's as a consensus.\n    'big5': 'big5hkscs',\n    'big5hkscs': {\n        type: '_dbcs',\n        table: function() { return require('./tables/cp950.json').concat(require('./tables/big5-added.json')) },\n        encodeSkipVals: [\n            // Although Encoding Standard says we should avoid encoding to HKSCS area (See Step 1 of\n            // https://encoding.spec.whatwg.org/#index-big5-pointer), we still do it to increase compatibility with ICU.\n            // But if a single unicode point can be encoded both as HKSCS and regular Big5, we prefer the latter.\n            0x8e69, 0x8e6f, 0x8e7e, 0x8eab, 0x8eb4, 0x8ecd, 0x8ed0, 0x8f57, 0x8f69, 0x8f6e, 0x8fcb, 0x8ffe,\n            0x906d, 0x907a, 0x90c4, 0x90dc, 0x90f1, 0x91bf, 0x92af, 0x92b0, 0x92b1, 0x92b2, 0x92d1, 0x9447, 0x94ca,\n            0x95d9, 0x96fc, 0x9975, 0x9b76, 0x9b78, 0x9b7b, 0x9bc6, 0x9bde, 0x9bec, 0x9bf6, 0x9c42, 0x9c53, 0x9c62,\n            0x9c68, 0x9c6b, 0x9c77, 0x9cbc, 0x9cbd, 0x9cd0, 0x9d57, 0x9d5a, 0x9dc4, 0x9def, 0x9dfb, 0x9ea9, 0x9eef,\n            0x9efd, 0x9f60, 0x9fcb, 0xa077, 0xa0dc, 0xa0df, 0x8fcc, 0x92c8, 0x9644, 0x96ed,\n\n            // Step 2 of https://encoding.spec.whatwg.org/#index-big5-pointer: Use last pointer for U+2550, U+255E, U+2561, U+256A, U+5341, or U+5345\n            0xa2a4, 0xa2a5, 0xa2a7, 0xa2a6, 0xa2cc, 0xa2ce,\n        ],\n    },\n\n    'cnbig5': 'big5hkscs',\n    'csbig5': 'big5hkscs',\n    'xxbig5': 'big5hkscs',\n};\n","\"use strict\";\n\n// Update this array if you add/rename/remove files in this directory.\n// We support Browserify by skipping automatic module discovery and requiring modules directly.\nvar modules = [\n    require(\"./internal\"),\n    require(\"./utf32\"),\n    require(\"./utf16\"),\n    require(\"./utf7\"),\n    require(\"./sbcs-codec\"),\n    require(\"./sbcs-data\"),\n    require(\"./sbcs-data-generated\"),\n    require(\"./dbcs-codec\"),\n    require(\"./dbcs-data\"),\n];\n\n// Put all encoding/alias/codec definitions to single object and export it.\nfor (var i = 0; i < modules.length; i++) {\n    var module = modules[i];\n    for (var enc in module)\n        if (Object.prototype.hasOwnProperty.call(module, enc))\n            exports[enc] = module[enc];\n}\n","\"use strict\";\nvar Buffer = require(\"safer-buffer\").Buffer;\n\n// Export Node.js internal encodings.\n\nmodule.exports = {\n    // Encodings\n    utf8:   { type: \"_internal\", bomAware: true},\n    cesu8:  { type: \"_internal\", bomAware: true},\n    unicode11utf8: \"utf8\",\n\n    ucs2:   { type: \"_internal\", bomAware: true},\n    utf16le: \"ucs2\",\n\n    binary: { type: \"_internal\" },\n    base64: { type: \"_internal\" },\n    hex:    { type: \"_internal\" },\n\n    // Codec.\n    _internal: InternalCodec,\n};\n\n//------------------------------------------------------------------------------\n\nfunction InternalCodec(codecOptions, iconv) {\n    this.enc = codecOptions.encodingName;\n    this.bomAware = codecOptions.bomAware;\n\n    if (this.enc === \"base64\")\n        this.encoder = InternalEncoderBase64;\n    else if (this.enc === \"cesu8\") {\n        this.enc = \"utf8\"; // Use utf8 for decoding.\n        this.encoder = InternalEncoderCesu8;\n\n        // Add decoder for versions of Node not supporting CESU-8\n        if (Buffer.from('eda0bdedb2a9', 'hex').toString() !== '💩') {\n            this.decoder = InternalDecoderCesu8;\n            this.defaultCharUnicode = iconv.defaultCharUnicode;\n        }\n    }\n}\n\nInternalCodec.prototype.encoder = InternalEncoder;\nInternalCodec.prototype.decoder = InternalDecoder;\n\n//------------------------------------------------------------------------------\n\n// We use node.js internal decoder. Its signature is the same as ours.\nvar StringDecoder = require('string_decoder').StringDecoder;\n\nif (!StringDecoder.prototype.end) // Node v0.8 doesn't have this method.\n    StringDecoder.prototype.end = function() {};\n\n\nfunction InternalDecoder(options, codec) {\n    this.decoder = new StringDecoder(codec.enc);\n}\n\nInternalDecoder.prototype.write = function(buf) {\n    if (!Buffer.isBuffer(buf)) {\n        buf = Buffer.from(buf);\n    }\n\n    return this.decoder.write(buf);\n}\n\nInternalDecoder.prototype.end = function() {\n    return this.decoder.end();\n}\n\n\n//------------------------------------------------------------------------------\n// Encoder is mostly trivial\n\nfunction InternalEncoder(options, codec) {\n    this.enc = codec.enc;\n}\n\nInternalEncoder.prototype.write = function(str) {\n    return Buffer.from(str, this.enc);\n}\n\nInternalEncoder.prototype.end = function() {\n}\n\n\n//------------------------------------------------------------------------------\n// Except base64 encoder, which must keep its state.\n\nfunction InternalEncoderBase64(options, codec) {\n    this.prevStr = '';\n}\n\nInternalEncoderBase64.prototype.write = function(str) {\n    str = this.prevStr + str;\n    var completeQuads = str.length - (str.length % 4);\n    this.prevStr = str.slice(completeQuads);\n    str = str.slice(0, completeQuads);\n\n    return Buffer.from(str, \"base64\");\n}\n\nInternalEncoderBase64.prototype.end = function() {\n    return Buffer.from(this.prevStr, \"base64\");\n}\n\n\n//------------------------------------------------------------------------------\n// CESU-8 encoder is also special.\n\nfunction InternalEncoderCesu8(options, codec) {\n}\n\nInternalEncoderCesu8.prototype.write = function(str) {\n    var buf = Buffer.alloc(str.length * 3), bufIdx = 0;\n    for (var i = 0; i < str.length; i++) {\n        var charCode = str.charCodeAt(i);\n        // Naive implementation, but it works because CESU-8 is especially easy\n        // to convert from UTF-16 (which all JS strings are encoded in).\n        if (charCode < 0x80)\n            buf[bufIdx++] = charCode;\n        else if (charCode < 0x800) {\n            buf[bufIdx++] = 0xC0 + (charCode >>> 6);\n            buf[bufIdx++] = 0x80 + (charCode & 0x3f);\n        }\n        else { // charCode will always be < 0x10000 in javascript.\n            buf[bufIdx++] = 0xE0 + (charCode >>> 12);\n            buf[bufIdx++] = 0x80 + ((charCode >>> 6) & 0x3f);\n            buf[bufIdx++] = 0x80 + (charCode & 0x3f);\n        }\n    }\n    return buf.slice(0, bufIdx);\n}\n\nInternalEncoderCesu8.prototype.end = function() {\n}\n\n//------------------------------------------------------------------------------\n// CESU-8 decoder is not implemented in Node v4.0+\n\nfunction InternalDecoderCesu8(options, codec) {\n    this.acc = 0;\n    this.contBytes = 0;\n    this.accBytes = 0;\n    this.defaultCharUnicode = codec.defaultCharUnicode;\n}\n\nInternalDecoderCesu8.prototype.write = function(buf) {\n    var acc = this.acc, contBytes = this.contBytes, accBytes = this.accBytes, \n        res = '';\n    for (var i = 0; i < buf.length; i++) {\n        var curByte = buf[i];\n        if ((curByte & 0xC0) !== 0x80) { // Leading byte\n            if (contBytes > 0) { // Previous code is invalid\n                res += this.defaultCharUnicode;\n                contBytes = 0;\n            }\n\n            if (curByte < 0x80) { // Single-byte code\n                res += String.fromCharCode(curByte);\n            } else if (curByte < 0xE0) { // Two-byte code\n                acc = curByte & 0x1F;\n                contBytes = 1; accBytes = 1;\n            } else if (curByte < 0xF0) { // Three-byte code\n                acc = curByte & 0x0F;\n                contBytes = 2; accBytes = 1;\n            } else { // Four or more are not supported for CESU-8.\n                res += this.defaultCharUnicode;\n            }\n        } else { // Continuation byte\n            if (contBytes > 0) { // We're waiting for it.\n                acc = (acc << 6) | (curByte & 0x3f);\n                contBytes--; accBytes++;\n                if (contBytes === 0) {\n                    // Check for overlong encoding, but support Modified UTF-8 (encoding NULL as C0 80)\n                    if (accBytes === 2 && acc < 0x80 && acc > 0)\n                        res += this.defaultCharUnicode;\n                    else if (accBytes === 3 && acc < 0x800)\n                        res += this.defaultCharUnicode;\n                    else\n                        // Actually add character.\n                        res += String.fromCharCode(acc);\n                }\n            } else { // Unexpected continuation byte\n                res += this.defaultCharUnicode;\n            }\n        }\n    }\n    this.acc = acc; this.contBytes = contBytes; this.accBytes = accBytes;\n    return res;\n}\n\nInternalDecoderCesu8.prototype.end = function() {\n    var res = 0;\n    if (this.contBytes > 0)\n        res += this.defaultCharUnicode;\n    return res;\n}\n","\"use strict\";\nvar Buffer = require(\"safer-buffer\").Buffer;\n\n// Single-byte codec. Needs a 'chars' string parameter that contains 256 or 128 chars that\n// correspond to encoded bytes (if 128 - then lower half is ASCII). \n\nexports._sbcs = SBCSCodec;\nfunction SBCSCodec(codecOptions, iconv) {\n    if (!codecOptions)\n        throw new Error(\"SBCS codec is called without the data.\")\n    \n    // Prepare char buffer for decoding.\n    if (!codecOptions.chars || (codecOptions.chars.length !== 128 && codecOptions.chars.length !== 256))\n        throw new Error(\"Encoding '\"+codecOptions.type+\"' has incorrect 'chars' (must be of len 128 or 256)\");\n    \n    if (codecOptions.chars.length === 128) {\n        var asciiString = \"\";\n        for (var i = 0; i < 128; i++)\n            asciiString += String.fromCharCode(i);\n        codecOptions.chars = asciiString + codecOptions.chars;\n    }\n\n    this.decodeBuf = Buffer.from(codecOptions.chars, 'ucs2');\n    \n    // Encoding buffer.\n    var encodeBuf = Buffer.alloc(65536, iconv.defaultCharSingleByte.charCodeAt(0));\n\n    for (var i = 0; i < codecOptions.chars.length; i++)\n        encodeBuf[codecOptions.chars.charCodeAt(i)] = i;\n\n    this.encodeBuf = encodeBuf;\n}\n\nSBCSCodec.prototype.encoder = SBCSEncoder;\nSBCSCodec.prototype.decoder = SBCSDecoder;\n\n\nfunction SBCSEncoder(options, codec) {\n    this.encodeBuf = codec.encodeBuf;\n}\n\nSBCSEncoder.prototype.write = function(str) {\n    var buf = Buffer.alloc(str.length);\n    for (var i = 0; i < str.length; i++)\n        buf[i] = this.encodeBuf[str.charCodeAt(i)];\n    \n    return buf;\n}\n\nSBCSEncoder.prototype.end = function() {\n}\n\n\nfunction SBCSDecoder(options, codec) {\n    this.decodeBuf = codec.decodeBuf;\n}\n\nSBCSDecoder.prototype.write = function(buf) {\n    // Strings are immutable in JS -> we use ucs2 buffer to speed up computations.\n    var decodeBuf = this.decodeBuf;\n    var newBuf = Buffer.alloc(buf.length*2);\n    var idx1 = 0, idx2 = 0;\n    for (var i = 0; i < buf.length; i++) {\n        idx1 = buf[i]*2; idx2 = i*2;\n        newBuf[idx2] = decodeBuf[idx1];\n        newBuf[idx2+1] = decodeBuf[idx1+1];\n    }\n    return newBuf.toString('ucs2');\n}\n\nSBCSDecoder.prototype.end = function() {\n}\n","\"use strict\";\n\n// Generated data for sbcs codec. Don't edit manually. Regenerate using generation/gen-sbcs.js script.\nmodule.exports = {\n  \"437\": \"cp437\",\n  \"737\": \"cp737\",\n  \"775\": \"cp775\",\n  \"850\": \"cp850\",\n  \"852\": \"cp852\",\n  \"855\": \"cp855\",\n  \"856\": \"cp856\",\n  \"857\": \"cp857\",\n  \"858\": \"cp858\",\n  \"860\": \"cp860\",\n  \"861\": \"cp861\",\n  \"862\": \"cp862\",\n  \"863\": \"cp863\",\n  \"864\": \"cp864\",\n  \"865\": \"cp865\",\n  \"866\": \"cp866\",\n  \"869\": \"cp869\",\n  \"874\": \"windows874\",\n  \"922\": \"cp922\",\n  \"1046\": \"cp1046\",\n  \"1124\": \"cp1124\",\n  \"1125\": \"cp1125\",\n  \"1129\": \"cp1129\",\n  \"1133\": \"cp1133\",\n  \"1161\": \"cp1161\",\n  \"1162\": \"cp1162\",\n  \"1163\": \"cp1163\",\n  \"1250\": \"windows1250\",\n  \"1251\": \"windows1251\",\n  \"1252\": \"windows1252\",\n  \"1253\": \"windows1253\",\n  \"1254\": \"windows1254\",\n  \"1255\": \"windows1255\",\n  \"1256\": \"windows1256\",\n  \"1257\": \"windows1257\",\n  \"1258\": \"windows1258\",\n  \"28591\": \"iso88591\",\n  \"28592\": \"iso88592\",\n  \"28593\": \"iso88593\",\n  \"28594\": \"iso88594\",\n  \"28595\": \"iso88595\",\n  \"28596\": \"iso88596\",\n  \"28597\": \"iso88597\",\n  \"28598\": \"iso88598\",\n  \"28599\": \"iso88599\",\n  \"28600\": \"iso885910\",\n  \"28601\": \"iso885911\",\n  \"28603\": \"iso885913\",\n  \"28604\": \"iso885914\",\n  \"28605\": \"iso885915\",\n  \"28606\": \"iso885916\",\n  \"windows874\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"€����…�����������‘’“”•–—�������� กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรฤลฦวศษสหฬอฮฯะัาำิีึืฺุู����฿เแโใไๅๆ็่้๊๋์ํ๎๏๐๑๒๓๔๕๖๗๘๙๚๛����\"\n  },\n  \"win874\": \"windows874\",\n  \"cp874\": \"windows874\",\n  \"windows1250\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"€�‚�„…†‡�‰Š‹ŚŤŽŹ�‘’“”•–—�™š›śťžź ˇ˘Ł¤Ą¦§¨©Ş«¬­®Ż°±˛ł´µ¶·¸ąş»Ľ˝ľżŔÁÂĂÄĹĆÇČÉĘËĚÍÎĎĐŃŇÓÔŐÖ×ŘŮÚŰÜÝŢßŕáâăäĺćçčéęëěíîďđńňóôőö÷řůúűüýţ˙\"\n  },\n  \"win1250\": \"windows1250\",\n  \"cp1250\": \"windows1250\",\n  \"windows1251\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"ЂЃ‚ѓ„…†‡€‰Љ‹ЊЌЋЏђ‘’“”•–—�™љ›њќћџ ЎўЈ¤Ґ¦§Ё©Є«¬­®Ї°±Ііґµ¶·ё№є»јЅѕїАБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдежзийклмнопрстуфхцчшщъыьэюя\"\n  },\n  \"win1251\": \"windows1251\",\n  \"cp1251\": \"windows1251\",\n  \"windows1252\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"€�‚ƒ„…†‡ˆ‰Š‹Œ�Ž��‘’“”•–—˜™š›œ�žŸ ¡¢£¤¥¦§¨©ª«¬­®¯°±²³´µ¶·¸¹º»¼½¾¿ÀÁÂÃÄÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖ×ØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõö÷øùúûüýþÿ\"\n  },\n  \"win1252\": \"windows1252\",\n  \"cp1252\": \"windows1252\",\n  \"windows1253\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"€�‚ƒ„…†‡�‰�‹�����‘’“”•–—�™�›���� ΅Ά£¤¥¦§¨©�«¬­®―°±²³΄µ¶·ΈΉΊ»Ό½ΎΏΐΑΒΓΔΕΖΗΘΙΚΛΜΝΞΟΠΡ�ΣΤΥΦΧΨΩΪΫάέήίΰαβγδεζηθικλμνξοπρςστυφχψωϊϋόύώ�\"\n  },\n  \"win1253\": \"windows1253\",\n  \"cp1253\": \"windows1253\",\n  \"windows1254\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"€�‚ƒ„…†‡ˆ‰Š‹Œ����‘’“”•–—˜™š›œ��Ÿ ¡¢£¤¥¦§¨©ª«¬­®¯°±²³´µ¶·¸¹º»¼½¾¿ÀÁÂÃÄÅÆÇÈÉÊËÌÍÎÏĞÑÒÓÔÕÖ×ØÙÚÛÜİŞßàáâãäåæçèéêëìíîïğñòóôõö÷øùúûüışÿ\"\n  },\n  \"win1254\": \"windows1254\",\n  \"cp1254\": \"windows1254\",\n  \"windows1255\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"€�‚ƒ„…†‡ˆ‰�‹�����‘’“”•–—˜™�›���� ¡¢£₪¥¦§¨©×«¬­®¯°±²³´µ¶·¸¹÷»¼½¾¿ְֱֲֳִֵֶַָֹֺֻּֽ־ֿ׀ׁׂ׃װױײ׳״�������אבגדהוזחטיךכלםמןנסעףפץצקרשת��‎‏�\"\n  },\n  \"win1255\": \"windows1255\",\n  \"cp1255\": \"windows1255\",\n  \"windows1256\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"€پ‚ƒ„…†‡ˆ‰ٹ‹Œچژڈگ‘’“”•–—ک™ڑ›œ‌‍ں ،¢£¤¥¦§¨©ھ«¬­®¯°±²³´µ¶·¸¹؛»¼½¾؟ہءآأؤإئابةتثجحخدذرزسشصض×طظعغـفقكàلâمنهوçèéêëىيîïًٌٍَôُِ÷ّùْûü‎‏ے\"\n  },\n  \"win1256\": \"windows1256\",\n  \"cp1256\": \"windows1256\",\n  \"windows1257\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"€�‚�„…†‡�‰�‹�¨ˇ¸�‘’“”•–—�™�›�¯˛� �¢£¤�¦§Ø©Ŗ«¬­®Æ°±²³´µ¶·ø¹ŗ»¼½¾æĄĮĀĆÄÅĘĒČÉŹĖĢĶĪĻŠŃŅÓŌÕÖ×ŲŁŚŪÜŻŽßąįāćäåęēčéźėģķīļšńņóōõö÷ųłśūüżž˙\"\n  },\n  \"win1257\": \"windows1257\",\n  \"cp1257\": \"windows1257\",\n  \"windows1258\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"€�‚ƒ„…†‡ˆ‰�‹Œ����‘’“”•–—˜™�›œ��Ÿ ¡¢£¤¥¦§¨©ª«¬­®¯°±²³´µ¶·¸¹º»¼½¾¿ÀÁÂĂÄÅÆÇÈÉÊË̀ÍÎÏĐÑ̉ÓÔƠÖ×ØÙÚÛÜỮßàáâăäåæçèéêë́íîïđṇ̃óôơö÷øùúûüư₫ÿ\"\n  },\n  \"win1258\": \"windows1258\",\n  \"cp1258\": \"windows1258\",\n  \"iso88591\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \" ¡¢£¤¥¦§¨©ª«¬­®¯°±²³´µ¶·¸¹º»¼½¾¿ÀÁÂÃÄÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖ×ØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõö÷øùúûüýþÿ\"\n  },\n  \"cp28591\": \"iso88591\",\n  \"iso88592\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \" Ą˘Ł¤ĽŚ§¨ŠŞŤŹ­ŽŻ°ą˛ł´ľśˇ¸šşťź˝žżŔÁÂĂÄĹĆÇČÉĘËĚÍÎĎĐŃŇÓÔŐÖ×ŘŮÚŰÜÝŢßŕáâăäĺćçčéęëěíîďđńňóôőö÷řůúűüýţ˙\"\n  },\n  \"cp28592\": \"iso88592\",\n  \"iso88593\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \" Ħ˘£¤�Ĥ§¨İŞĞĴ­�Ż°ħ²³´µĥ·¸ışğĵ½�żÀÁÂ�ÄĊĈÇÈÉÊËÌÍÎÏ�ÑÒÓÔĠÖ×ĜÙÚÛÜŬŜßàáâ�äċĉçèéêëìíîï�ñòóôġö÷ĝùúûüŭŝ˙\"\n  },\n  \"cp28593\": \"iso88593\",\n  \"iso88594\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \" ĄĸŖ¤ĨĻ§¨ŠĒĢŦ­Ž¯°ą˛ŗ´ĩļˇ¸šēģŧŊžŋĀÁÂÃÄÅÆĮČÉĘËĖÍÎĪĐŅŌĶÔÕÖ×ØŲÚÛÜŨŪßāáâãäåæįčéęëėíîīđņōķôõö÷øųúûüũū˙\"\n  },\n  \"cp28594\": \"iso88594\",\n  \"iso88595\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \" ЁЂЃЄЅІЇЈЉЊЋЌ­ЎЏАБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдежзийклмнопрстуфхцчшщъыьэюя№ёђѓєѕіїјљњћќ§ўџ\"\n  },\n  \"cp28595\": \"iso88595\",\n  \"iso88596\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \" ���¤�������،­�������������؛���؟�ءآأؤإئابةتثجحخدذرزسشصضطظعغ�����ـفقكلمنهوىيًٌٍَُِّْ�������������\"\n  },\n  \"cp28596\": \"iso88596\",\n  \"iso88597\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \" ‘’£€₯¦§¨©ͺ«¬­�―°±²³΄΅Ά·ΈΉΊ»Ό½ΎΏΐΑΒΓΔΕΖΗΘΙΚΛΜΝΞΟΠΡ�ΣΤΥΦΧΨΩΪΫάέήίΰαβγδεζηθικλμνξοπρςστυφχψωϊϋόύώ�\"\n  },\n  \"cp28597\": \"iso88597\",\n  \"iso88598\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \" �¢£¤¥¦§¨©×«¬­®¯°±²³´µ¶·¸¹÷»¼½¾��������������������������������‗אבגדהוזחטיךכלםמןנסעףפץצקרשת��‎‏�\"\n  },\n  \"cp28598\": \"iso88598\",\n  \"iso88599\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \" ¡¢£¤¥¦§¨©ª«¬­®¯°±²³´µ¶·¸¹º»¼½¾¿ÀÁÂÃÄÅÆÇÈÉÊËÌÍÎÏĞÑÒÓÔÕÖ×ØÙÚÛÜİŞßàáâãäåæçèéêëìíîïğñòóôõö÷øùúûüışÿ\"\n  },\n  \"cp28599\": \"iso88599\",\n  \"iso885910\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \" ĄĒĢĪĨĶ§ĻĐŠŦŽ­ŪŊ°ąēģīĩķ·ļđšŧž―ūŋĀÁÂÃÄÅÆĮČÉĘËĖÍÎÏÐŅŌÓÔÕÖŨØŲÚÛÜÝÞßāáâãäåæįčéęëėíîïðņōóôõöũøųúûüýþĸ\"\n  },\n  \"cp28600\": \"iso885910\",\n  \"iso885911\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \" กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรฤลฦวศษสหฬอฮฯะัาำิีึืฺุู����฿เแโใไๅๆ็่้๊๋์ํ๎๏๐๑๒๓๔๕๖๗๘๙๚๛����\"\n  },\n  \"cp28601\": \"iso885911\",\n  \"iso885913\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \" ”¢£¤„¦§Ø©Ŗ«¬­®Æ°±²³“µ¶·ø¹ŗ»¼½¾æĄĮĀĆÄÅĘĒČÉŹĖĢĶĪĻŠŃŅÓŌÕÖ×ŲŁŚŪÜŻŽßąįāćäåęēčéźėģķīļšńņóōõö÷ųłśūüżž’\"\n  },\n  \"cp28603\": \"iso885913\",\n  \"iso885914\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \" Ḃḃ£ĊċḊ§Ẁ©ẂḋỲ­®ŸḞḟĠġṀṁ¶ṖẁṗẃṠỳẄẅṡÀÁÂÃÄÅÆÇÈÉÊËÌÍÎÏŴÑÒÓÔÕÖṪØÙÚÛÜÝŶßàáâãäåæçèéêëìíîïŵñòóôõöṫøùúûüýŷÿ\"\n  },\n  \"cp28604\": \"iso885914\",\n  \"iso885915\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \" ¡¢£€¥Š§š©ª«¬­®¯°±²³Žµ¶·ž¹º»ŒœŸ¿ÀÁÂÃÄÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖ×ØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõö÷øùúûüýþÿ\"\n  },\n  \"cp28605\": \"iso885915\",\n  \"iso885916\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \" ĄąŁ€„Š§š©Ș«Ź­źŻ°±ČłŽ”¶·žčș»ŒœŸżÀÁÂĂÄĆÆÇÈÉÊËÌÍÎÏĐŃÒÓÔŐÖŚŰÙÚÛÜĘȚßàáâăäćæçèéêëìíîïđńòóôőöśűùúûüęțÿ\"\n  },\n  \"cp28606\": \"iso885916\",\n  \"cp437\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"ÇüéâäàåçêëèïîìÄÅÉæÆôöòûùÿÖÜ¢£¥₧ƒáíóúñÑªº¿⌐¬½¼¡«»░▒▓│┤╡╢╖╕╣║╗╝╜╛┐└┴┬├─┼╞╟╚╔╩╦╠═╬╧╨╤╥╙╘╒╓╫╪┘┌█▄▌▐▀αßΓπΣσµτΦΘΩδ∞φε∩≡±≥≤⌠⌡÷≈°∙·√ⁿ²■ \"\n  },\n  \"ibm437\": \"cp437\",\n  \"csibm437\": \"cp437\",\n  \"cp737\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"ΑΒΓΔΕΖΗΘΙΚΛΜΝΞΟΠΡΣΤΥΦΧΨΩαβγδεζηθικλμνξοπρσςτυφχψ░▒▓│┤╡╢╖╕╣║╗╝╜╛┐└┴┬├─┼╞╟╚╔╩╦╠═╬╧╨╤╥╙╘╒╓╫╪┘┌█▄▌▐▀ωάέήϊίόύϋώΆΈΉΊΌΎΏ±≥≤ΪΫ÷≈°∙·√ⁿ²■ \"\n  },\n  \"ibm737\": \"cp737\",\n  \"csibm737\": \"cp737\",\n  \"cp775\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"ĆüéāäģåćłēŖŗīŹÄÅÉæÆōöĢ¢ŚśÖÜø£Ø×¤ĀĪóŻżź”¦©®¬½¼Ł«»░▒▓│┤ĄČĘĖ╣║╗╝ĮŠ┐└┴┬├─┼ŲŪ╚╔╩╦╠═╬Žąčęėįšųūž┘┌█▄▌▐▀ÓßŌŃõÕµńĶķĻļņĒŅ’­±“¾¶§÷„°∙·¹³²■ \"\n  },\n  \"ibm775\": \"cp775\",\n  \"csibm775\": \"cp775\",\n  \"cp850\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"ÇüéâäàåçêëèïîìÄÅÉæÆôöòûùÿÖÜø£Ø×ƒáíóúñÑªº¿®¬½¼¡«»░▒▓│┤ÁÂÀ©╣║╗╝¢¥┐└┴┬├─┼ãÃ╚╔╩╦╠═╬¤ðÐÊËÈıÍÎÏ┘┌█▄¦Ì▀ÓßÔÒõÕµþÞÚÛÙýÝ¯´­±‗¾¶§÷¸°¨·¹³²■ \"\n  },\n  \"ibm850\": \"cp850\",\n  \"csibm850\": \"cp850\",\n  \"cp852\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"ÇüéâäůćçłëŐőîŹÄĆÉĹĺôöĽľŚśÖÜŤťŁ×čáíóúĄąŽžĘę¬źČş«»░▒▓│┤ÁÂĚŞ╣║╗╝Żż┐└┴┬├─┼Ăă╚╔╩╦╠═╬¤đĐĎËďŇÍÎě┘┌█▄ŢŮ▀ÓßÔŃńňŠšŔÚŕŰýÝţ´­˝˛ˇ˘§÷¸°¨˙űŘř■ \"\n  },\n  \"ibm852\": \"cp852\",\n  \"csibm852\": \"cp852\",\n  \"cp855\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"ђЂѓЃёЁєЄѕЅіІїЇјЈљЉњЊћЋќЌўЎџЏюЮъЪаАбБцЦдДеЕфФгГ«»░▒▓│┤хХиИ╣║╗╝йЙ┐└┴┬├─┼кК╚╔╩╦╠═╬¤лЛмМнНоОп┘┌█▄Пя▀ЯрРсСтТуУжЖвВьЬ№­ыЫзЗшШэЭщЩчЧ§■ \"\n  },\n  \"ibm855\": \"cp855\",\n  \"csibm855\": \"cp855\",\n  \"cp856\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"אבגדהוזחטיךכלםמןנסעףפץצקרשת�£�×����������®¬½¼�«»░▒▓│┤���©╣║╗╝¢¥┐└┴┬├─┼��╚╔╩╦╠═╬¤���������┘┌█▄¦�▀������µ�������¯´­±‗¾¶§÷¸°¨·¹³²■ \"\n  },\n  \"ibm856\": \"cp856\",\n  \"csibm856\": \"cp856\",\n  \"cp857\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"ÇüéâäàåçêëèïîıÄÅÉæÆôöòûùİÖÜø£ØŞşáíóúñÑĞğ¿®¬½¼¡«»░▒▓│┤ÁÂÀ©╣║╗╝¢¥┐└┴┬├─┼ãÃ╚╔╩╦╠═╬¤ºªÊËÈ�ÍÎÏ┘┌█▄¦Ì▀ÓßÔÒõÕµ�×ÚÛÙìÿ¯´­±�¾¶§÷¸°¨·¹³²■ \"\n  },\n  \"ibm857\": \"cp857\",\n  \"csibm857\": \"cp857\",\n  \"cp858\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"ÇüéâäàåçêëèïîìÄÅÉæÆôöòûùÿÖÜø£Ø×ƒáíóúñÑªº¿®¬½¼¡«»░▒▓│┤ÁÂÀ©╣║╗╝¢¥┐└┴┬├─┼ãÃ╚╔╩╦╠═╬¤ðÐÊËÈ€ÍÎÏ┘┌█▄¦Ì▀ÓßÔÒõÕµþÞÚÛÙýÝ¯´­±‗¾¶§÷¸°¨·¹³²■ \"\n  },\n  \"ibm858\": \"cp858\",\n  \"csibm858\": \"cp858\",\n  \"cp860\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"ÇüéâãàÁçêÊèÍÔìÃÂÉÀÈôõòÚùÌÕÜ¢£Ù₧ÓáíóúñÑªº¿Ò¬½¼¡«»░▒▓│┤╡╢╖╕╣║╗╝╜╛┐└┴┬├─┼╞╟╚╔╩╦╠═╬╧╨╤╥╙╘╒╓╫╪┘┌█▄▌▐▀αßΓπΣσµτΦΘΩδ∞φε∩≡±≥≤⌠⌡÷≈°∙·√ⁿ²■ \"\n  },\n  \"ibm860\": \"cp860\",\n  \"csibm860\": \"cp860\",\n  \"cp861\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"ÇüéâäàåçêëèÐðÞÄÅÉæÆôöþûÝýÖÜø£Ø₧ƒáíóúÁÍÓÚ¿⌐¬½¼¡«»░▒▓│┤╡╢╖╕╣║╗╝╜╛┐└┴┬├─┼╞╟╚╔╩╦╠═╬╧╨╤╥╙╘╒╓╫╪┘┌█▄▌▐▀αßΓπΣσµτΦΘΩδ∞φε∩≡±≥≤⌠⌡÷≈°∙·√ⁿ²■ \"\n  },\n  \"ibm861\": \"cp861\",\n  \"csibm861\": \"cp861\",\n  \"cp862\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"אבגדהוזחטיךכלםמןנסעףפץצקרשת¢£¥₧ƒáíóúñÑªº¿⌐¬½¼¡«»░▒▓│┤╡╢╖╕╣║╗╝╜╛┐└┴┬├─┼╞╟╚╔╩╦╠═╬╧╨╤╥╙╘╒╓╫╪┘┌█▄▌▐▀αßΓπΣσµτΦΘΩδ∞φε∩≡±≥≤⌠⌡÷≈°∙·√ⁿ²■ \"\n  },\n  \"ibm862\": \"cp862\",\n  \"csibm862\": \"cp862\",\n  \"cp863\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"ÇüéâÂà¶çêëèïî‗À§ÉÈÊôËÏûù¤ÔÜ¢£ÙÛƒ¦´óú¨¸³¯Î⌐¬½¼¾«»░▒▓│┤╡╢╖╕╣║╗╝╜╛┐└┴┬├─┼╞╟╚╔╩╦╠═╬╧╨╤╥╙╘╒╓╫╪┘┌█▄▌▐▀αßΓπΣσµτΦΘΩδ∞φε∩≡±≥≤⌠⌡÷≈°∙·√ⁿ²■ \"\n  },\n  \"ibm863\": \"cp863\",\n  \"csibm863\": \"cp863\",\n  \"cp864\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"\\u0000\\u0001\\u0002\\u0003\\u0004\\u0005\\u0006\\u0007\\b\\t\\n\\u000b\\f\\r\\u000e\\u000f\\u0010\\u0011\\u0012\\u0013\\u0014\\u0015\\u0016\\u0017\\u0018\\u0019\\u001a\\u001b\\u001c\\u001d\\u001e\\u001f !\\\"#$٪&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~°·∙√▒─│┼┤┬├┴┐┌└┘β∞φ±½¼≈«»ﻷﻸ��ﻻﻼ� ­ﺂ£¤ﺄ��ﺎﺏﺕﺙ،ﺝﺡﺥ٠١٢٣٤٥٦٧٨٩ﻑ؛ﺱﺵﺹ؟¢ﺀﺁﺃﺅﻊﺋﺍﺑﺓﺗﺛﺟﺣﺧﺩﺫﺭﺯﺳﺷﺻﺿﻁﻅﻋﻏ¦¬÷×ﻉـﻓﻗﻛﻟﻣﻧﻫﻭﻯﻳﺽﻌﻎﻍﻡﹽّﻥﻩﻬﻰﻲﻐﻕﻵﻶﻝﻙﻱ■�\"\n  },\n  \"ibm864\": \"cp864\",\n  \"csibm864\": \"cp864\",\n  \"cp865\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"ÇüéâäàåçêëèïîìÄÅÉæÆôöòûùÿÖÜø£Ø₧ƒáíóúñÑªº¿⌐¬½¼¡«¤░▒▓│┤╡╢╖╕╣║╗╝╜╛┐└┴┬├─┼╞╟╚╔╩╦╠═╬╧╨╤╥╙╘╒╓╫╪┘┌█▄▌▐▀αßΓπΣσµτΦΘΩδ∞φε∩≡±≥≤⌠⌡÷≈°∙·√ⁿ²■ \"\n  },\n  \"ibm865\": \"cp865\",\n  \"csibm865\": \"cp865\",\n  \"cp866\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"АБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдежзийклмноп░▒▓│┤╡╢╖╕╣║╗╝╜╛┐└┴┬├─┼╞╟╚╔╩╦╠═╬╧╨╤╥╙╘╒╓╫╪┘┌█▄▌▐▀рстуфхцчшщъыьэюяЁёЄєЇїЎў°∙·√№¤■ \"\n  },\n  \"ibm866\": \"cp866\",\n  \"csibm866\": \"cp866\",\n  \"cp869\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"������Ά�·¬¦‘’Έ―ΉΊΪΌ��ΎΫ©Ώ²³ά£έήίϊΐόύΑΒΓΔΕΖΗ½ΘΙ«»░▒▓│┤ΚΛΜΝ╣║╗╝ΞΟ┐└┴┬├─┼ΠΡ╚╔╩╦╠═╬ΣΤΥΦΧΨΩαβγ┘┌█▄δε▀ζηθικλμνξοπρσςτ΄­±υφχ§ψ΅°¨ωϋΰώ■ \"\n  },\n  \"ibm869\": \"cp869\",\n  \"csibm869\": \"cp869\",\n  \"cp922\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \" ¡¢£¤¥¦§¨©ª«¬­®‾°±²³´µ¶·¸¹º»¼½¾¿ÀÁÂÃÄÅÆÇÈÉÊËÌÍÎÏŠÑÒÓÔÕÖ×ØÙÚÛÜÝŽßàáâãäåæçèéêëìíîïšñòóôõö÷øùúûüýžÿ\"\n  },\n  \"ibm922\": \"cp922\",\n  \"csibm922\": \"cp922\",\n  \"cp1046\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"ﺈ×÷ﹱ■│─┐┌└┘ﹹﹻﹽﹿﹷﺊﻰﻳﻲﻎﻏﻐﻶﻸﻺﻼ ¤ﺋﺑﺗﺛﺟﺣ،­ﺧﺳ٠١٢٣٤٥٦٧٨٩ﺷ؛ﺻﺿﻊ؟ﻋءآأؤإئابةتثجحخدذرزسشصضطﻇعغﻌﺂﺄﺎﻓـفقكلمنهوىيًٌٍَُِّْﻗﻛﻟﻵﻷﻹﻻﻣﻧﻬﻩ�\"\n  },\n  \"ibm1046\": \"cp1046\",\n  \"csibm1046\": \"cp1046\",\n  \"cp1124\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \" ЁЂҐЄЅІЇЈЉЊЋЌ­ЎЏАБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдежзийклмнопрстуфхцчшщъыьэюя№ёђґєѕіїјљњћќ§ўџ\"\n  },\n  \"ibm1124\": \"cp1124\",\n  \"csibm1124\": \"cp1124\",\n  \"cp1125\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"АБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдежзийклмноп░▒▓│┤╡╢╖╕╣║╗╝╜╛┐└┴┬├─┼╞╟╚╔╩╦╠═╬╧╨╤╥╙╘╒╓╫╪┘┌█▄▌▐▀рстуфхцчшщъыьэюяЁёҐґЄєІіЇї·√№¤■ \"\n  },\n  \"ibm1125\": \"cp1125\",\n  \"csibm1125\": \"cp1125\",\n  \"cp1129\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \" ¡¢£¤¥¦§œ©ª«¬­®¯°±²³Ÿµ¶·Œ¹º»¼½¾¿ÀÁÂĂÄÅÆÇÈÉÊË̀ÍÎÏĐÑ̉ÓÔƠÖ×ØÙÚÛÜỮßàáâăäåæçèéêë́íîïđṇ̃óôơö÷øùúûüư₫ÿ\"\n  },\n  \"ibm1129\": \"cp1129\",\n  \"csibm1129\": \"cp1129\",\n  \"cp1133\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \" ກຂຄງຈສຊຍດຕຖທນບປຜຝພຟມຢຣລວຫອຮ���ຯະາຳິີຶືຸູຼັົຽ���ເແໂໃໄ່້໊໋໌ໍໆ�ໜໝ₭����������������໐໑໒໓໔໕໖໗໘໙��¢¬¦�\"\n  },\n  \"ibm1133\": \"cp1133\",\n  \"csibm1133\": \"cp1133\",\n  \"cp1161\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"��������������������������������่กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรฤลฦวศษสหฬอฮฯะัาำิีึืฺุู้๊๋€฿เแโใไๅๆ็่้๊๋์ํ๎๏๐๑๒๓๔๕๖๗๘๙๚๛¢¬¦ \"\n  },\n  \"ibm1161\": \"cp1161\",\n  \"csibm1161\": \"cp1161\",\n  \"cp1162\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"€…‘’“”•–— กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรฤลฦวศษสหฬอฮฯะัาำิีึืฺุู����฿เแโใไๅๆ็่้๊๋์ํ๎๏๐๑๒๓๔๕๖๗๘๙๚๛����\"\n  },\n  \"ibm1162\": \"cp1162\",\n  \"csibm1162\": \"cp1162\",\n  \"cp1163\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \" ¡¢£€¥¦§œ©ª«¬­®¯°±²³Ÿµ¶·Œ¹º»¼½¾¿ÀÁÂĂÄÅÆÇÈÉÊË̀ÍÎÏĐÑ̉ÓÔƠÖ×ØÙÚÛÜỮßàáâăäåæçèéêë́íîïđṇ̃óôơö÷øùúûüư₫ÿ\"\n  },\n  \"ibm1163\": \"cp1163\",\n  \"csibm1163\": \"cp1163\",\n  \"maccroatian\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"ÄÅÇÉÑÖÜáàâäãåçéèêëíìîïñóòôöõúùûü†°¢£§•¶ß®Š™´¨≠ŽØ∞±≤≥∆µ∂∑∏š∫ªºΩžø¿¡¬√ƒ≈Ć«Č… ÀÃÕŒœĐ—“”‘’÷◊�©⁄¤‹›Æ»–·‚„‰ÂćÁčÈÍÎÏÌÓÔđÒÚÛÙıˆ˜¯πË˚¸Êæˇ\"\n  },\n  \"maccyrillic\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"АБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ†°¢£§•¶І®©™Ђђ≠Ѓѓ∞±≤≥іµ∂ЈЄєЇїЉљЊњјЅ¬√ƒ≈∆«»… ЋћЌќѕ–—“”‘’÷„ЎўЏџ№Ёёяабвгдежзийклмнопрстуфхцчшщъыьэю¤\"\n  },\n  \"macgreek\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"Ä¹²É³ÖÜ΅àâä΄¨çéèêë£™îï•½‰ôö¦­ùûü†ΓΔΘΛΞΠß®©ΣΪ§≠°·Α±≤≥¥ΒΕΖΗΙΚΜΦΫΨΩάΝ¬ΟΡ≈Τ«»… ΥΧΆΈœ–―“”‘’÷ΉΊΌΎέήίόΏύαβψδεφγηιξκλμνοπώρστθωςχυζϊϋΐΰ�\"\n  },\n  \"maciceland\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"ÄÅÇÉÑÖÜáàâäãåçéèêëíìîïñóòôöõúùûüÝ°¢£§•¶ß®©™´¨≠ÆØ∞±≤≥¥µ∂∑∏π∫ªºΩæø¿¡¬√ƒ≈∆«»… ÀÃÕŒœ–—“”‘’÷◊ÿŸ⁄¤ÐðÞþý·‚„‰ÂÊÁËÈÍÎÏÌÓÔ�ÒÚÛÙıˆ˜¯˘˙˚¸˝˛ˇ\"\n  },\n  \"macroman\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"ÄÅÇÉÑÖÜáàâäãåçéèêëíìîïñóòôöõúùûü†°¢£§•¶ß®©™´¨≠ÆØ∞±≤≥¥µ∂∑∏π∫ªºΩæø¿¡¬√ƒ≈∆«»… ÀÃÕŒœ–—“”‘’÷◊ÿŸ⁄¤‹›ﬁﬂ‡·‚„‰ÂÊÁËÈÍÎÏÌÓÔ�ÒÚÛÙıˆ˜¯˘˙˚¸˝˛ˇ\"\n  },\n  \"macromania\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"ÄÅÇÉÑÖÜáàâäãåçéèêëíìîïñóòôöõúùûü†°¢£§•¶ß®©™´¨≠ĂŞ∞±≤≥¥µ∂∑∏π∫ªºΩăş¿¡¬√ƒ≈∆«»… ÀÃÕŒœ–—“”‘’÷◊ÿŸ⁄¤‹›Ţţ‡·‚„‰ÂÊÁËÈÍÎÏÌÓÔ�ÒÚÛÙıˆ˜¯˘˙˚¸˝˛ˇ\"\n  },\n  \"macthai\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"«»…“”�•‘’� กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรฤลฦวศษสหฬอฮฯะัาำิีึืฺุู﻿​–—฿เแโใไๅๆ็่้๊๋์ํ™๏๐๑๒๓๔๕๖๗๘๙®©����\"\n  },\n  \"macturkish\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"ÄÅÇÉÑÖÜáàâäãåçéèêëíìîïñóòôöõúùûü†°¢£§•¶ß®©™´¨≠ÆØ∞±≤≥¥µ∂∑∏π∫ªºΩæø¿¡¬√ƒ≈∆«»… ÀÃÕŒœ–—“”‘’÷◊ÿŸĞğİıŞş‡·‚„‰ÂÊÁËÈÍÎÏÌÓÔ�ÒÚÛÙ�ˆ˜¯˘˙˚¸˝˛ˇ\"\n  },\n  \"macukraine\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"АБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ†°Ґ£§•¶І®©™Ђђ≠Ѓѓ∞±≤≥іµґЈЄєЇїЉљЊњјЅ¬√ƒ≈∆«»… ЋћЌќѕ–—“”‘’÷„ЎўЏџ№Ёёяабвгдежзийклмнопрстуфхцчшщъыьэю¤\"\n  },\n  \"koi8r\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"─│┌┐└┘├┤┬┴┼▀▄█▌▐░▒▓⌠■∙√≈≤≥ ⌡°²·÷═║╒ё╓╔╕╖╗╘╙╚╛╜╝╞╟╠╡Ё╢╣╤╥╦╧╨╩╪╫╬©юабцдефгхийклмнопярстужвьызшэщчъЮАБЦДЕФГХИЙКЛМНОПЯРСТУЖВЬЫЗШЭЩЧЪ\"\n  },\n  \"koi8u\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"─│┌┐└┘├┤┬┴┼▀▄█▌▐░▒▓⌠■∙√≈≤≥ ⌡°²·÷═║╒ёє╔ії╗╘╙╚╛ґ╝╞╟╠╡ЁЄ╣ІЇ╦╧╨╩╪Ґ╬©юабцдефгхийклмнопярстужвьызшэщчъЮАБЦДЕФГХИЙКЛМНОПЯРСТУЖВЬЫЗШЭЩЧЪ\"\n  },\n  \"koi8ru\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"─│┌┐└┘├┤┬┴┼▀▄█▌▐░▒▓⌠■∙√≈≤≥ ⌡°²·÷═║╒ёє╔ії╗╘╙╚╛ґў╞╟╠╡ЁЄ╣ІЇ╦╧╨╩╪ҐЎ©юабцдефгхийклмнопярстужвьызшэщчъЮАБЦДЕФГХИЙКЛМНОПЯРСТУЖВЬЫЗШЭЩЧЪ\"\n  },\n  \"koi8t\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"қғ‚Ғ„…†‡�‰ҳ‹ҲҷҶ�Қ‘’“”•–—�™�›�����ӯӮё¤ӣ¦§���«¬­®�°±²Ё�Ӣ¶·�№�»���©юабцдефгхийклмнопярстужвьызшэщчъЮАБЦДЕФГХИЙКЛМНОПЯРСТУЖВЬЫЗШЭЩЧЪ\"\n  },\n  \"armscii8\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \" �և։)(»«—.՝,-֊…՜՛՞ԱաԲբԳգԴդԵեԶզԷէԸըԹթԺժԻիԼլԽխԾծԿկՀհՁձՂղՃճՄմՅյՆնՇշՈոՉչՊպՋջՌռՍսՎվՏտՐրՑցՒւՓփՔքՕօՖֆ՚�\"\n  },\n  \"rk1048\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"ЂЃ‚ѓ„…†‡€‰Љ‹ЊҚҺЏђ‘’“”•–—�™љ›њқһџ ҰұӘ¤Ө¦§Ё©Ғ«¬­®Ү°±Ііөµ¶·ё№ғ»әҢңүАБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдежзийклмнопрстуфхцчшщъыьэюя\"\n  },\n  \"tcvn\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"\\u0000ÚỤ\\u0003ỪỬỮ\\u0007\\b\\t\\n\\u000b\\f\\r\\u000e\\u000f\\u0010ỨỰỲỶỸÝỴ\\u0018\\u0019\\u001a\\u001b\\u001c\\u001d\\u001e\\u001f !\\\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~ÀẢÃÁẠẶẬÈẺẼÉẸỆÌỈĨÍỊÒỎÕÓỌỘỜỞỠỚỢÙỦŨ ĂÂÊÔƠƯĐăâêôơưđẶ̀̀̉̃́àảãáạẲằẳẵắẴẮẦẨẪẤỀặầẩẫấậèỂẻẽéẹềểễếệìỉỄẾỒĩíịòỔỏõóọồổỗốộờởỡớợùỖủũúụừửữứựỳỷỹýỵỐ\"\n  },\n  \"georgianacademy\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"‚ƒ„…†‡ˆ‰Š‹Œ‘’“”•–—˜™š›œŸ ¡¢£¤¥¦§¨©ª«¬­®¯°±²³´µ¶·¸¹º»¼½¾¿აბგდევზთიკლმნოპჟრსტუფქღყშჩცძწჭხჯჰჱჲჳჴჵჶçèéêëìíîïðñòóôõö÷øùúûüýþÿ\"\n  },\n  \"georgianps\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"‚ƒ„…†‡ˆ‰Š‹Œ‘’“”•–—˜™š›œŸ ¡¢£¤¥¦§¨©ª«¬­®¯°±²³´µ¶·¸¹º»¼½¾¿აბგდევზჱთიკლმნჲოპჟრსტჳუფქღყშჩცძწჭხჴჯჰჵæçèéêëìíîïðñòóôõö÷øùúûüýþÿ\"\n  },\n  \"pt154\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"ҖҒӮғ„…ҶҮҲүҠӢҢҚҺҸҗ‘’“”•–—ҳҷҡӣңқһҹ ЎўЈӨҘҰ§Ё©Ә«¬ӯ®Ҝ°ұІіҙө¶·ё№ә»јҪҫҝАБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдежзийклмнопрстуфхцчшщъыьэюя\"\n  },\n  \"viscii\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"\\u0000\\u0001Ẳ\\u0003\\u0004ẴẪ\\u0007\\b\\t\\n\\u000b\\f\\r\\u000e\\u000f\\u0010\\u0011\\u0012\\u0013Ỷ\\u0015\\u0016\\u0017\\u0018Ỹ\\u001a\\u001b\\u001c\\u001dỴ\\u001f !\\\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~ẠẮẰẶẤẦẨẬẼẸẾỀỂỄỆỐỒỔỖỘỢỚỜỞỊỎỌỈỦŨỤỲÕắằặấầẩậẽẹếềểễệốồổỗỠƠộờởịỰỨỪỬơớƯÀÁÂÃẢĂẳẵÈÉÊẺÌÍĨỳĐứÒÓÔạỷừửÙÚỹỵÝỡưàáâãảăữẫèéêẻìíĩỉđựòóôõỏọụùúũủýợỮ\"\n  },\n  \"iso646cn\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"\\u0000\\u0001\\u0002\\u0003\\u0004\\u0005\\u0006\\u0007\\b\\t\\n\\u000b\\f\\r\\u000e\\u000f\\u0010\\u0011\\u0012\\u0013\\u0014\\u0015\\u0016\\u0017\\u0018\\u0019\\u001a\\u001b\\u001c\\u001d\\u001e\\u001f !\\\"#¥%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}‾��������������������������������������������������������������������������������������������������������������������������������\"\n  },\n  \"iso646jp\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"\\u0000\\u0001\\u0002\\u0003\\u0004\\u0005\\u0006\\u0007\\b\\t\\n\\u000b\\f\\r\\u000e\\u000f\\u0010\\u0011\\u0012\\u0013\\u0014\\u0015\\u0016\\u0017\\u0018\\u0019\\u001a\\u001b\\u001c\\u001d\\u001e\\u001f !\\\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[¥]^_`abcdefghijklmnopqrstuvwxyz{|}‾��������������������������������������������������������������������������������������������������������������������������������\"\n  },\n  \"hproman8\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \" ÀÂÈÊËÎÏ´ˋˆ¨˜ÙÛ₤¯Ýý°ÇçÑñ¡¿¤£¥§ƒ¢âêôûáéóúàèòùäëöüÅîØÆåíøæÄìÖÜÉïßÔÁÃãÐðÍÌÓÒÕõŠšÚŸÿÞþ·µ¶¾—¼½ªº«■»±�\"\n  },\n  \"macintosh\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"ÄÅÇÉÑÖÜáàâäãåçéèêëíìîïñóòôöõúùûü†°¢£§•¶ß®©™´¨≠ÆØ∞±≤≥¥µ∂∑∏π∫ªºΩæø¿¡¬√ƒ≈∆«»… ÀÃÕŒœ–—“”‘’÷◊ÿŸ⁄¤‹›ﬁﬂ‡·‚„‰ÂÊÁËÈÍÎÏÌÓÔ�ÒÚÛÙıˆ˜¯˘˙˚¸˝˛ˇ\"\n  },\n  \"ascii\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"��������������������������������������������������������������������������������������������������������������������������������\"\n  },\n  \"tis620\": {\n    \"type\": \"_sbcs\",\n    \"chars\": \"���������������������������������กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรฤลฦวศษสหฬอฮฯะัาำิีึืฺุู����฿เแโใไๅๆ็่้๊๋์ํ๎๏๐๑๒๓๔๕๖๗๘๙๚๛����\"\n  }\n}","\"use strict\";\n\n// Manually added data to be used by sbcs codec in addition to generated one.\n\nmodule.exports = {\n    // Not supported by iconv, not sure why.\n    \"10029\": \"maccenteuro\",\n    \"maccenteuro\": {\n        \"type\": \"_sbcs\",\n        \"chars\": \"ÄĀāÉĄÖÜáąČäčĆćéŹźĎíďĒēĖóėôöõúĚěü†°Ę£§•¶ß®©™ę¨≠ģĮįĪ≤≥īĶ∂∑łĻļĽľĹĺŅņŃ¬√ńŇ∆«»… ňŐÕőŌ–—“”‘’÷◊ōŔŕŘ‹›řŖŗŠ‚„šŚśÁŤťÍŽžŪÓÔūŮÚůŰűŲųÝýķŻŁżĢˇ\"\n    },\n\n    \"808\": \"cp808\",\n    \"ibm808\": \"cp808\",\n    \"cp808\": {\n        \"type\": \"_sbcs\",\n        \"chars\": \"АБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдежзийклмноп░▒▓│┤╡╢╖╕╣║╗╝╜╛┐└┴┬├─┼╞╟╚╔╩╦╠═╬╧╨╤╥╙╘╒╓╫╪┘┌█▄▌▐▀рстуфхцчшщъыьэюяЁёЄєЇїЎў°∙·√№€■ \"\n    },\n\n    \"mik\": {\n        \"type\": \"_sbcs\",\n        \"chars\": \"АБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдежзийклмнопрстуфхцчшщъыьэюя└┴┬├─┼╣║╚╔╩╦╠═╬┐░▒▓│┤№§╗╝┘┌█▄▌▐▀αßΓπΣσµτΦΘΩδ∞φε∩≡±≥≤⌠⌡÷≈°∙·√ⁿ²■ \"\n    },\n\n    \"cp720\": {\n        \"type\": \"_sbcs\",\n        \"chars\": \"\\x80\\x81éâ\\x84à\\x86çêëèïî\\x8d\\x8e\\x8f\\x90\\u0651\\u0652ô¤ـûùءآأؤ£إئابةتثجحخدذرزسشص«»░▒▓│┤╡╢╖╕╣║╗╝╜╛┐└┴┬├─┼╞╟╚╔╩╦╠═╬╧╨╤╥╙╘╒╓╫╪┘┌█▄▌▐▀ضطظعغفµقكلمنهوىي≡\\u064b\\u064c\\u064d\\u064e\\u064f\\u0650≈°∙·√ⁿ²■\\u00a0\"\n    },\n\n    // Aliases of generated encodings.\n    \"ascii8bit\": \"ascii\",\n    \"usascii\": \"ascii\",\n    \"ansix34\": \"ascii\",\n    \"ansix341968\": \"ascii\",\n    \"ansix341986\": \"ascii\",\n    \"csascii\": \"ascii\",\n    \"cp367\": \"ascii\",\n    \"ibm367\": \"ascii\",\n    \"isoir6\": \"ascii\",\n    \"iso646us\": \"ascii\",\n    \"iso646irv\": \"ascii\",\n    \"us\": \"ascii\",\n\n    \"latin1\": \"iso88591\",\n    \"latin2\": \"iso88592\",\n    \"latin3\": \"iso88593\",\n    \"latin4\": \"iso88594\",\n    \"latin5\": \"iso88599\",\n    \"latin6\": \"iso885910\",\n    \"latin7\": \"iso885913\",\n    \"latin8\": \"iso885914\",\n    \"latin9\": \"iso885915\",\n    \"latin10\": \"iso885916\",\n\n    \"csisolatin1\": \"iso88591\",\n    \"csisolatin2\": \"iso88592\",\n    \"csisolatin3\": \"iso88593\",\n    \"csisolatin4\": \"iso88594\",\n    \"csisolatincyrillic\": \"iso88595\",\n    \"csisolatinarabic\": \"iso88596\",\n    \"csisolatingreek\" : \"iso88597\",\n    \"csisolatinhebrew\": \"iso88598\",\n    \"csisolatin5\": \"iso88599\",\n    \"csisolatin6\": \"iso885910\",\n\n    \"l1\": \"iso88591\",\n    \"l2\": \"iso88592\",\n    \"l3\": \"iso88593\",\n    \"l4\": \"iso88594\",\n    \"l5\": \"iso88599\",\n    \"l6\": \"iso885910\",\n    \"l7\": \"iso885913\",\n    \"l8\": \"iso885914\",\n    \"l9\": \"iso885915\",\n    \"l10\": \"iso885916\",\n\n    \"isoir14\": \"iso646jp\",\n    \"isoir57\": \"iso646cn\",\n    \"isoir100\": \"iso88591\",\n    \"isoir101\": \"iso88592\",\n    \"isoir109\": \"iso88593\",\n    \"isoir110\": \"iso88594\",\n    \"isoir144\": \"iso88595\",\n    \"isoir127\": \"iso88596\",\n    \"isoir126\": \"iso88597\",\n    \"isoir138\": \"iso88598\",\n    \"isoir148\": \"iso88599\",\n    \"isoir157\": \"iso885910\",\n    \"isoir166\": \"tis620\",\n    \"isoir179\": \"iso885913\",\n    \"isoir199\": \"iso885914\",\n    \"isoir203\": \"iso885915\",\n    \"isoir226\": \"iso885916\",\n\n    \"cp819\": \"iso88591\",\n    \"ibm819\": \"iso88591\",\n\n    \"cyrillic\": \"iso88595\",\n\n    \"arabic\": \"iso88596\",\n    \"arabic8\": \"iso88596\",\n    \"ecma114\": \"iso88596\",\n    \"asmo708\": \"iso88596\",\n\n    \"greek\" : \"iso88597\",\n    \"greek8\" : \"iso88597\",\n    \"ecma118\" : \"iso88597\",\n    \"elot928\" : \"iso88597\",\n\n    \"hebrew\": \"iso88598\",\n    \"hebrew8\": \"iso88598\",\n\n    \"turkish\": \"iso88599\",\n    \"turkish8\": \"iso88599\",\n\n    \"thai\": \"iso885911\",\n    \"thai8\": \"iso885911\",\n\n    \"celtic\": \"iso885914\",\n    \"celtic8\": \"iso885914\",\n    \"isoceltic\": \"iso885914\",\n\n    \"tis6200\": \"tis620\",\n    \"tis62025291\": \"tis620\",\n    \"tis62025330\": \"tis620\",\n\n    \"10000\": \"macroman\",\n    \"10006\": \"macgreek\",\n    \"10007\": \"maccyrillic\",\n    \"10079\": \"maciceland\",\n    \"10081\": \"macturkish\",\n\n    \"cspc8codepage437\": \"cp437\",\n    \"cspc775baltic\": \"cp775\",\n    \"cspc850multilingual\": \"cp850\",\n    \"cspcp852\": \"cp852\",\n    \"cspc862latinhebrew\": \"cp862\",\n    \"cpgr\": \"cp869\",\n\n    \"msee\": \"cp1250\",\n    \"mscyrl\": \"cp1251\",\n    \"msansi\": \"cp1252\",\n    \"msgreek\": \"cp1253\",\n    \"msturk\": \"cp1254\",\n    \"mshebr\": \"cp1255\",\n    \"msarab\": \"cp1256\",\n    \"winbaltrim\": \"cp1257\",\n\n    \"cp20866\": \"koi8r\",\n    \"20866\": \"koi8r\",\n    \"ibm878\": \"koi8r\",\n    \"cskoi8r\": \"koi8r\",\n\n    \"cp21866\": \"koi8u\",\n    \"21866\": \"koi8u\",\n    \"ibm1168\": \"koi8u\",\n\n    \"strk10482002\": \"rk1048\",\n\n    \"tcvn5712\": \"tcvn\",\n    \"tcvn57121\": \"tcvn\",\n\n    \"gb198880\": \"iso646cn\",\n    \"cn\": \"iso646cn\",\n\n    \"csiso14jisc6220ro\": \"iso646jp\",\n    \"jisc62201969ro\": \"iso646jp\",\n    \"jp\": \"iso646jp\",\n\n    \"cshproman8\": \"hproman8\",\n    \"r8\": \"hproman8\",\n    \"roman8\": \"hproman8\",\n    \"xroman8\": \"hproman8\",\n    \"ibm1051\": \"hproman8\",\n\n    \"mac\": \"macintosh\",\n    \"csmacintosh\": \"macintosh\",\n};\n\n","\"use strict\";\nvar Buffer = require(\"safer-buffer\").Buffer;\n\n// Note: UTF16-LE (or UCS2) codec is Node.js native. See encodings/internal.js\n\n// == UTF16-BE codec. ==========================================================\n\nexports.utf16be = Utf16BECodec;\nfunction Utf16BECodec() {\n}\n\nUtf16BECodec.prototype.encoder = Utf16BEEncoder;\nUtf16BECodec.prototype.decoder = Utf16BEDecoder;\nUtf16BECodec.prototype.bomAware = true;\n\n\n// -- Encoding\n\nfunction Utf16BEEncoder() {\n}\n\nUtf16BEEncoder.prototype.write = function(str) {\n    var buf = Buffer.from(str, 'ucs2');\n    for (var i = 0; i < buf.length; i += 2) {\n        var tmp = buf[i]; buf[i] = buf[i+1]; buf[i+1] = tmp;\n    }\n    return buf;\n}\n\nUtf16BEEncoder.prototype.end = function() {\n}\n\n\n// -- Decoding\n\nfunction Utf16BEDecoder() {\n    this.overflowByte = -1;\n}\n\nUtf16BEDecoder.prototype.write = function(buf) {\n    if (buf.length == 0)\n        return '';\n\n    var buf2 = Buffer.alloc(buf.length + 1),\n        i = 0, j = 0;\n\n    if (this.overflowByte !== -1) {\n        buf2[0] = buf[0];\n        buf2[1] = this.overflowByte;\n        i = 1; j = 2;\n    }\n\n    for (; i < buf.length-1; i += 2, j+= 2) {\n        buf2[j] = buf[i+1];\n        buf2[j+1] = buf[i];\n    }\n\n    this.overflowByte = (i == buf.length-1) ? buf[buf.length-1] : -1;\n\n    return buf2.slice(0, j).toString('ucs2');\n}\n\nUtf16BEDecoder.prototype.end = function() {\n    this.overflowByte = -1;\n}\n\n\n// == UTF-16 codec =============================================================\n// Decoder chooses automatically from UTF-16LE and UTF-16BE using BOM and space-based heuristic.\n// Defaults to UTF-16LE, as it's prevalent and default in Node.\n// http://en.wikipedia.org/wiki/UTF-16 and http://encoding.spec.whatwg.org/#utf-16le\n// Decoder default can be changed: iconv.decode(buf, 'utf16', {defaultEncoding: 'utf-16be'});\n\n// Encoder uses UTF-16LE and prepends BOM (which can be overridden with addBOM: false).\n\nexports.utf16 = Utf16Codec;\nfunction Utf16Codec(codecOptions, iconv) {\n    this.iconv = iconv;\n}\n\nUtf16Codec.prototype.encoder = Utf16Encoder;\nUtf16Codec.prototype.decoder = Utf16Decoder;\n\n\n// -- Encoding (pass-through)\n\nfunction Utf16Encoder(options, codec) {\n    options = options || {};\n    if (options.addBOM === undefined)\n        options.addBOM = true;\n    this.encoder = codec.iconv.getEncoder('utf-16le', options);\n}\n\nUtf16Encoder.prototype.write = function(str) {\n    return this.encoder.write(str);\n}\n\nUtf16Encoder.prototype.end = function() {\n    return this.encoder.end();\n}\n\n\n// -- Decoding\n\nfunction Utf16Decoder(options, codec) {\n    this.decoder = null;\n    this.initialBufs = [];\n    this.initialBufsLen = 0;\n\n    this.options = options || {};\n    this.iconv = codec.iconv;\n}\n\nUtf16Decoder.prototype.write = function(buf) {\n    if (!this.decoder) {\n        // Codec is not chosen yet. Accumulate initial bytes.\n        this.initialBufs.push(buf);\n        this.initialBufsLen += buf.length;\n        \n        if (this.initialBufsLen < 16) // We need more bytes to use space heuristic (see below)\n            return '';\n\n        // We have enough bytes -> detect endianness.\n        var encoding = detectEncoding(this.initialBufs, this.options.defaultEncoding);\n        this.decoder = this.iconv.getDecoder(encoding, this.options);\n\n        var resStr = '';\n        for (var i = 0; i < this.initialBufs.length; i++)\n            resStr += this.decoder.write(this.initialBufs[i]);\n\n        this.initialBufs.length = this.initialBufsLen = 0;\n        return resStr;\n    }\n\n    return this.decoder.write(buf);\n}\n\nUtf16Decoder.prototype.end = function() {\n    if (!this.decoder) {\n        var encoding = detectEncoding(this.initialBufs, this.options.defaultEncoding);\n        this.decoder = this.iconv.getDecoder(encoding, this.options);\n\n        var resStr = '';\n        for (var i = 0; i < this.initialBufs.length; i++)\n            resStr += this.decoder.write(this.initialBufs[i]);\n\n        var trail = this.decoder.end();\n        if (trail)\n            resStr += trail;\n\n        this.initialBufs.length = this.initialBufsLen = 0;\n        return resStr;\n    }\n    return this.decoder.end();\n}\n\nfunction detectEncoding(bufs, defaultEncoding) {\n    var b = [];\n    var charsProcessed = 0;\n    var asciiCharsLE = 0, asciiCharsBE = 0; // Number of ASCII chars when decoded as LE or BE.\n\n    outer_loop:\n    for (var i = 0; i < bufs.length; i++) {\n        var buf = bufs[i];\n        for (var j = 0; j < buf.length; j++) {\n            b.push(buf[j]);\n            if (b.length === 2) {\n                if (charsProcessed === 0) {\n                    // Check BOM first.\n                    if (b[0] === 0xFF && b[1] === 0xFE) return 'utf-16le';\n                    if (b[0] === 0xFE && b[1] === 0xFF) return 'utf-16be';\n                }\n\n                if (b[0] === 0 && b[1] !== 0) asciiCharsBE++;\n                if (b[0] !== 0 && b[1] === 0) asciiCharsLE++;\n\n                b.length = 0;\n                charsProcessed++;\n\n                if (charsProcessed >= 100) {\n                    break outer_loop;\n                }\n            }\n        }\n    }\n\n    // Make decisions.\n    // Most of the time, the content has ASCII chars (U+00**), but the opposite (U+**00) is uncommon.\n    // So, we count ASCII as if it was LE or BE, and decide from that.\n    if (asciiCharsBE > asciiCharsLE) return 'utf-16be';\n    if (asciiCharsBE < asciiCharsLE) return 'utf-16le';\n\n    // Couldn't decide (likely all zeros or not enough data).\n    return defaultEncoding || 'utf-16le';\n}\n\n\n","'use strict';\n\nvar Buffer = require('safer-buffer').Buffer;\n\n// == UTF32-LE/BE codec. ==========================================================\n\nexports._utf32 = Utf32Codec;\n\nfunction Utf32Codec(codecOptions, iconv) {\n    this.iconv = iconv;\n    this.bomAware = true;\n    this.isLE = codecOptions.isLE;\n}\n\nexports.utf32le = { type: '_utf32', isLE: true };\nexports.utf32be = { type: '_utf32', isLE: false };\n\n// Aliases\nexports.ucs4le = 'utf32le';\nexports.ucs4be = 'utf32be';\n\nUtf32Codec.prototype.encoder = Utf32Encoder;\nUtf32Codec.prototype.decoder = Utf32Decoder;\n\n// -- Encoding\n\nfunction Utf32Encoder(options, codec) {\n    this.isLE = codec.isLE;\n    this.highSurrogate = 0;\n}\n\nUtf32Encoder.prototype.write = function(str) {\n    var src = Buffer.from(str, 'ucs2');\n    var dst = Buffer.alloc(src.length * 2);\n    var write32 = this.isLE ? dst.writeUInt32LE : dst.writeUInt32BE;\n    var offset = 0;\n\n    for (var i = 0; i < src.length; i += 2) {\n        var code = src.readUInt16LE(i);\n        var isHighSurrogate = (0xD800 <= code && code < 0xDC00);\n        var isLowSurrogate = (0xDC00 <= code && code < 0xE000);\n\n        if (this.highSurrogate) {\n            if (isHighSurrogate || !isLowSurrogate) {\n                // There shouldn't be two high surrogates in a row, nor a high surrogate which isn't followed by a low\n                // surrogate. If this happens, keep the pending high surrogate as a stand-alone semi-invalid character\n                // (technically wrong, but expected by some applications, like Windows file names).\n                write32.call(dst, this.highSurrogate, offset);\n                offset += 4;\n            }\n            else {\n                // Create 32-bit value from high and low surrogates;\n                var codepoint = (((this.highSurrogate - 0xD800) << 10) | (code - 0xDC00)) + 0x10000;\n\n                write32.call(dst, codepoint, offset);\n                offset += 4;\n                this.highSurrogate = 0;\n\n                continue;\n            }\n        }\n\n        if (isHighSurrogate)\n            this.highSurrogate = code;\n        else {\n            // Even if the current character is a low surrogate, with no previous high surrogate, we'll\n            // encode it as a semi-invalid stand-alone character for the same reasons expressed above for\n            // unpaired high surrogates.\n            write32.call(dst, code, offset);\n            offset += 4;\n            this.highSurrogate = 0;\n        }\n    }\n\n    if (offset < dst.length)\n        dst = dst.slice(0, offset);\n\n    return dst;\n};\n\nUtf32Encoder.prototype.end = function() {\n    // Treat any leftover high surrogate as a semi-valid independent character.\n    if (!this.highSurrogate)\n        return;\n\n    var buf = Buffer.alloc(4);\n\n    if (this.isLE)\n        buf.writeUInt32LE(this.highSurrogate, 0);\n    else\n        buf.writeUInt32BE(this.highSurrogate, 0);\n\n    this.highSurrogate = 0;\n\n    return buf;\n};\n\n// -- Decoding\n\nfunction Utf32Decoder(options, codec) {\n    this.isLE = codec.isLE;\n    this.badChar = codec.iconv.defaultCharUnicode.charCodeAt(0);\n    this.overflow = [];\n}\n\nUtf32Decoder.prototype.write = function(src) {\n    if (src.length === 0)\n        return '';\n\n    var i = 0;\n    var codepoint = 0;\n    var dst = Buffer.alloc(src.length + 4);\n    var offset = 0;\n    var isLE = this.isLE;\n    var overflow = this.overflow;\n    var badChar = this.badChar;\n\n    if (overflow.length > 0) {\n        for (; i < src.length && overflow.length < 4; i++)\n            overflow.push(src[i]);\n        \n        if (overflow.length === 4) {\n            // NOTE: codepoint is a signed int32 and can be negative.\n            // NOTE: We copied this block from below to help V8 optimize it (it works with array, not buffer).\n            if (isLE) {\n                codepoint = overflow[i] | (overflow[i+1] << 8) | (overflow[i+2] << 16) | (overflow[i+3] << 24);\n            } else {\n                codepoint = overflow[i+3] | (overflow[i+2] << 8) | (overflow[i+1] << 16) | (overflow[i] << 24);\n            }\n            overflow.length = 0;\n\n            offset = _writeCodepoint(dst, offset, codepoint, badChar);\n        }\n    }\n\n    // Main loop. Should be as optimized as possible.\n    for (; i < src.length - 3; i += 4) {\n        // NOTE: codepoint is a signed int32 and can be negative.\n        if (isLE) {\n            codepoint = src[i] | (src[i+1] << 8) | (src[i+2] << 16) | (src[i+3] << 24);\n        } else {\n            codepoint = src[i+3] | (src[i+2] << 8) | (src[i+1] << 16) | (src[i] << 24);\n        }\n        offset = _writeCodepoint(dst, offset, codepoint, badChar);\n    }\n\n    // Keep overflowing bytes.\n    for (; i < src.length; i++) {\n        overflow.push(src[i]);\n    }\n\n    return dst.slice(0, offset).toString('ucs2');\n};\n\nfunction _writeCodepoint(dst, offset, codepoint, badChar) {\n    // NOTE: codepoint is signed int32 and can be negative. We keep it that way to help V8 with optimizations.\n    if (codepoint < 0 || codepoint > 0x10FFFF) {\n        // Not a valid Unicode codepoint\n        codepoint = badChar;\n    } \n\n    // Ephemeral Planes: Write high surrogate.\n    if (codepoint >= 0x10000) {\n        codepoint -= 0x10000;\n\n        var high = 0xD800 | (codepoint >> 10);\n        dst[offset++] = high & 0xff;\n        dst[offset++] = high >> 8;\n\n        // Low surrogate is written below.\n        var codepoint = 0xDC00 | (codepoint & 0x3FF);\n    }\n\n    // Write BMP char or low surrogate.\n    dst[offset++] = codepoint & 0xff;\n    dst[offset++] = codepoint >> 8;\n\n    return offset;\n};\n\nUtf32Decoder.prototype.end = function() {\n    this.overflow.length = 0;\n};\n\n// == UTF-32 Auto codec =============================================================\n// Decoder chooses automatically from UTF-32LE and UTF-32BE using BOM and space-based heuristic.\n// Defaults to UTF-32LE. http://en.wikipedia.org/wiki/UTF-32\n// Encoder/decoder default can be changed: iconv.decode(buf, 'utf32', {defaultEncoding: 'utf-32be'});\n\n// Encoder prepends BOM (which can be overridden with (addBOM: false}).\n\nexports.utf32 = Utf32AutoCodec;\nexports.ucs4 = 'utf32';\n\nfunction Utf32AutoCodec(options, iconv) {\n    this.iconv = iconv;\n}\n\nUtf32AutoCodec.prototype.encoder = Utf32AutoEncoder;\nUtf32AutoCodec.prototype.decoder = Utf32AutoDecoder;\n\n// -- Encoding\n\nfunction Utf32AutoEncoder(options, codec) {\n    options = options || {};\n\n    if (options.addBOM === undefined)\n        options.addBOM = true;\n\n    this.encoder = codec.iconv.getEncoder(options.defaultEncoding || 'utf-32le', options);\n}\n\nUtf32AutoEncoder.prototype.write = function(str) {\n    return this.encoder.write(str);\n};\n\nUtf32AutoEncoder.prototype.end = function() {\n    return this.encoder.end();\n};\n\n// -- Decoding\n\nfunction Utf32AutoDecoder(options, codec) {\n    this.decoder = null;\n    this.initialBufs = [];\n    this.initialBufsLen = 0;\n    this.options = options || {};\n    this.iconv = codec.iconv;\n}\n\nUtf32AutoDecoder.prototype.write = function(buf) {\n    if (!this.decoder) { \n        // Codec is not chosen yet. Accumulate initial bytes.\n        this.initialBufs.push(buf);\n        this.initialBufsLen += buf.length;\n\n        if (this.initialBufsLen < 32) // We need more bytes to use space heuristic (see below)\n            return '';\n\n        // We have enough bytes -> detect endianness.\n        var encoding = detectEncoding(this.initialBufs, this.options.defaultEncoding);\n        this.decoder = this.iconv.getDecoder(encoding, this.options);\n\n        var resStr = '';\n        for (var i = 0; i < this.initialBufs.length; i++)\n            resStr += this.decoder.write(this.initialBufs[i]);\n\n        this.initialBufs.length = this.initialBufsLen = 0;\n        return resStr;\n    }\n\n    return this.decoder.write(buf);\n};\n\nUtf32AutoDecoder.prototype.end = function() {\n    if (!this.decoder) {\n        var encoding = detectEncoding(this.initialBufs, this.options.defaultEncoding);\n        this.decoder = this.iconv.getDecoder(encoding, this.options);\n\n        var resStr = '';\n        for (var i = 0; i < this.initialBufs.length; i++)\n            resStr += this.decoder.write(this.initialBufs[i]);\n\n        var trail = this.decoder.end();\n        if (trail)\n            resStr += trail;\n\n        this.initialBufs.length = this.initialBufsLen = 0;\n        return resStr;\n    }\n\n    return this.decoder.end();\n};\n\nfunction detectEncoding(bufs, defaultEncoding) {\n    var b = [];\n    var charsProcessed = 0;\n    var invalidLE = 0, invalidBE = 0;   // Number of invalid chars when decoded as LE or BE.\n    var bmpCharsLE = 0, bmpCharsBE = 0; // Number of BMP chars when decoded as LE or BE.\n\n    outer_loop:\n    for (var i = 0; i < bufs.length; i++) {\n        var buf = bufs[i];\n        for (var j = 0; j < buf.length; j++) {\n            b.push(buf[j]);\n            if (b.length === 4) {\n                if (charsProcessed === 0) {\n                    // Check BOM first.\n                    if (b[0] === 0xFF && b[1] === 0xFE && b[2] === 0 && b[3] === 0) {\n                        return 'utf-32le';\n                    }\n                    if (b[0] === 0 && b[1] === 0 && b[2] === 0xFE && b[3] === 0xFF) {\n                        return 'utf-32be';\n                    }\n                }\n\n                if (b[0] !== 0 || b[1] > 0x10) invalidBE++;\n                if (b[3] !== 0 || b[2] > 0x10) invalidLE++;\n\n                if (b[0] === 0 && b[1] === 0 && (b[2] !== 0 || b[3] !== 0)) bmpCharsBE++;\n                if ((b[0] !== 0 || b[1] !== 0) && b[2] === 0 && b[3] === 0) bmpCharsLE++;\n\n                b.length = 0;\n                charsProcessed++;\n\n                if (charsProcessed >= 100) {\n                    break outer_loop;\n                }\n            }\n        }\n    }\n\n    // Make decisions.\n    if (bmpCharsBE - invalidBE > bmpCharsLE - invalidLE)  return 'utf-32be';\n    if (bmpCharsBE - invalidBE < bmpCharsLE - invalidLE)  return 'utf-32le';\n\n    // Couldn't decide (likely all zeros or not enough data).\n    return defaultEncoding || 'utf-32le';\n}\n","\"use strict\";\nvar Buffer = require(\"safer-buffer\").Buffer;\n\n// UTF-7 codec, according to https://tools.ietf.org/html/rfc2152\n// See also below a UTF-7-IMAP codec, according to http://tools.ietf.org/html/rfc3501#section-5.1.3\n\nexports.utf7 = Utf7Codec;\nexports.unicode11utf7 = 'utf7'; // Alias UNICODE-1-1-UTF-7\nfunction Utf7Codec(codecOptions, iconv) {\n    this.iconv = iconv;\n};\n\nUtf7Codec.prototype.encoder = Utf7Encoder;\nUtf7Codec.prototype.decoder = Utf7Decoder;\nUtf7Codec.prototype.bomAware = true;\n\n\n// -- Encoding\n\nvar nonDirectChars = /[^A-Za-z0-9'\\(\\),-\\.\\/:\\? \\n\\r\\t]+/g;\n\nfunction Utf7Encoder(options, codec) {\n    this.iconv = codec.iconv;\n}\n\nUtf7Encoder.prototype.write = function(str) {\n    // Naive implementation.\n    // Non-direct chars are encoded as \"+<base64>-\"; single \"+\" char is encoded as \"+-\".\n    return Buffer.from(str.replace(nonDirectChars, function(chunk) {\n        return \"+\" + (chunk === '+' ? '' : \n            this.iconv.encode(chunk, 'utf16-be').toString('base64').replace(/=+$/, '')) \n            + \"-\";\n    }.bind(this)));\n}\n\nUtf7Encoder.prototype.end = function() {\n}\n\n\n// -- Decoding\n\nfunction Utf7Decoder(options, codec) {\n    this.iconv = codec.iconv;\n    this.inBase64 = false;\n    this.base64Accum = '';\n}\n\nvar base64Regex = /[A-Za-z0-9\\/+]/;\nvar base64Chars = [];\nfor (var i = 0; i < 256; i++)\n    base64Chars[i] = base64Regex.test(String.fromCharCode(i));\n\nvar plusChar = '+'.charCodeAt(0), \n    minusChar = '-'.charCodeAt(0),\n    andChar = '&'.charCodeAt(0);\n\nUtf7Decoder.prototype.write = function(buf) {\n    var res = \"\", lastI = 0,\n        inBase64 = this.inBase64,\n        base64Accum = this.base64Accum;\n\n    // The decoder is more involved as we must handle chunks in stream.\n\n    for (var i = 0; i < buf.length; i++) {\n        if (!inBase64) { // We're in direct mode.\n            // Write direct chars until '+'\n            if (buf[i] == plusChar) {\n                res += this.iconv.decode(buf.slice(lastI, i), \"ascii\"); // Write direct chars.\n                lastI = i+1;\n                inBase64 = true;\n            }\n        } else { // We decode base64.\n            if (!base64Chars[buf[i]]) { // Base64 ended.\n                if (i == lastI && buf[i] == minusChar) {// \"+-\" -> \"+\"\n                    res += \"+\";\n                } else {\n                    var b64str = base64Accum + this.iconv.decode(buf.slice(lastI, i), \"ascii\");\n                    res += this.iconv.decode(Buffer.from(b64str, 'base64'), \"utf16-be\");\n                }\n\n                if (buf[i] != minusChar) // Minus is absorbed after base64.\n                    i--;\n\n                lastI = i+1;\n                inBase64 = false;\n                base64Accum = '';\n            }\n        }\n    }\n\n    if (!inBase64) {\n        res += this.iconv.decode(buf.slice(lastI), \"ascii\"); // Write direct chars.\n    } else {\n        var b64str = base64Accum + this.iconv.decode(buf.slice(lastI), \"ascii\");\n\n        var canBeDecoded = b64str.length - (b64str.length % 8); // Minimal chunk: 2 quads -> 2x3 bytes -> 3 chars.\n        base64Accum = b64str.slice(canBeDecoded); // The rest will be decoded in future.\n        b64str = b64str.slice(0, canBeDecoded);\n\n        res += this.iconv.decode(Buffer.from(b64str, 'base64'), \"utf16-be\");\n    }\n\n    this.inBase64 = inBase64;\n    this.base64Accum = base64Accum;\n\n    return res;\n}\n\nUtf7Decoder.prototype.end = function() {\n    var res = \"\";\n    if (this.inBase64 && this.base64Accum.length > 0)\n        res = this.iconv.decode(Buffer.from(this.base64Accum, 'base64'), \"utf16-be\");\n\n    this.inBase64 = false;\n    this.base64Accum = '';\n    return res;\n}\n\n\n// UTF-7-IMAP codec.\n// RFC3501 Sec. 5.1.3 Modified UTF-7 (http://tools.ietf.org/html/rfc3501#section-5.1.3)\n// Differences:\n//  * Base64 part is started by \"&\" instead of \"+\"\n//  * Direct characters are 0x20-0x7E, except \"&\" (0x26)\n//  * In Base64, \",\" is used instead of \"/\"\n//  * Base64 must not be used to represent direct characters.\n//  * No implicit shift back from Base64 (should always end with '-')\n//  * String must end in non-shifted position.\n//  * \"-&\" while in base64 is not allowed.\n\n\nexports.utf7imap = Utf7IMAPCodec;\nfunction Utf7IMAPCodec(codecOptions, iconv) {\n    this.iconv = iconv;\n};\n\nUtf7IMAPCodec.prototype.encoder = Utf7IMAPEncoder;\nUtf7IMAPCodec.prototype.decoder = Utf7IMAPDecoder;\nUtf7IMAPCodec.prototype.bomAware = true;\n\n\n// -- Encoding\n\nfunction Utf7IMAPEncoder(options, codec) {\n    this.iconv = codec.iconv;\n    this.inBase64 = false;\n    this.base64Accum = Buffer.alloc(6);\n    this.base64AccumIdx = 0;\n}\n\nUtf7IMAPEncoder.prototype.write = function(str) {\n    var inBase64 = this.inBase64,\n        base64Accum = this.base64Accum,\n        base64AccumIdx = this.base64AccumIdx,\n        buf = Buffer.alloc(str.length*5 + 10), bufIdx = 0;\n\n    for (var i = 0; i < str.length; i++) {\n        var uChar = str.charCodeAt(i);\n        if (0x20 <= uChar && uChar <= 0x7E) { // Direct character or '&'.\n            if (inBase64) {\n                if (base64AccumIdx > 0) {\n                    bufIdx += buf.write(base64Accum.slice(0, base64AccumIdx).toString('base64').replace(/\\//g, ',').replace(/=+$/, ''), bufIdx);\n                    base64AccumIdx = 0;\n                }\n\n                buf[bufIdx++] = minusChar; // Write '-', then go to direct mode.\n                inBase64 = false;\n            }\n\n            if (!inBase64) {\n                buf[bufIdx++] = uChar; // Write direct character\n\n                if (uChar === andChar)  // Ampersand -> '&-'\n                    buf[bufIdx++] = minusChar;\n            }\n\n        } else { // Non-direct character\n            if (!inBase64) {\n                buf[bufIdx++] = andChar; // Write '&', then go to base64 mode.\n                inBase64 = true;\n            }\n            if (inBase64) {\n                base64Accum[base64AccumIdx++] = uChar >> 8;\n                base64Accum[base64AccumIdx++] = uChar & 0xFF;\n\n                if (base64AccumIdx == base64Accum.length) {\n                    bufIdx += buf.write(base64Accum.toString('base64').replace(/\\//g, ','), bufIdx);\n                    base64AccumIdx = 0;\n                }\n            }\n        }\n    }\n\n    this.inBase64 = inBase64;\n    this.base64AccumIdx = base64AccumIdx;\n\n    return buf.slice(0, bufIdx);\n}\n\nUtf7IMAPEncoder.prototype.end = function() {\n    var buf = Buffer.alloc(10), bufIdx = 0;\n    if (this.inBase64) {\n        if (this.base64AccumIdx > 0) {\n            bufIdx += buf.write(this.base64Accum.slice(0, this.base64AccumIdx).toString('base64').replace(/\\//g, ',').replace(/=+$/, ''), bufIdx);\n            this.base64AccumIdx = 0;\n        }\n\n        buf[bufIdx++] = minusChar; // Write '-', then go to direct mode.\n        this.inBase64 = false;\n    }\n\n    return buf.slice(0, bufIdx);\n}\n\n\n// -- Decoding\n\nfunction Utf7IMAPDecoder(options, codec) {\n    this.iconv = codec.iconv;\n    this.inBase64 = false;\n    this.base64Accum = '';\n}\n\nvar base64IMAPChars = base64Chars.slice();\nbase64IMAPChars[','.charCodeAt(0)] = true;\n\nUtf7IMAPDecoder.prototype.write = function(buf) {\n    var res = \"\", lastI = 0,\n        inBase64 = this.inBase64,\n        base64Accum = this.base64Accum;\n\n    // The decoder is more involved as we must handle chunks in stream.\n    // It is forgiving, closer to standard UTF-7 (for example, '-' is optional at the end).\n\n    for (var i = 0; i < buf.length; i++) {\n        if (!inBase64) { // We're in direct mode.\n            // Write direct chars until '&'\n            if (buf[i] == andChar) {\n                res += this.iconv.decode(buf.slice(lastI, i), \"ascii\"); // Write direct chars.\n                lastI = i+1;\n                inBase64 = true;\n            }\n        } else { // We decode base64.\n            if (!base64IMAPChars[buf[i]]) { // Base64 ended.\n                if (i == lastI && buf[i] == minusChar) { // \"&-\" -> \"&\"\n                    res += \"&\";\n                } else {\n                    var b64str = base64Accum + this.iconv.decode(buf.slice(lastI, i), \"ascii\").replace(/,/g, '/');\n                    res += this.iconv.decode(Buffer.from(b64str, 'base64'), \"utf16-be\");\n                }\n\n                if (buf[i] != minusChar) // Minus may be absorbed after base64.\n                    i--;\n\n                lastI = i+1;\n                inBase64 = false;\n                base64Accum = '';\n            }\n        }\n    }\n\n    if (!inBase64) {\n        res += this.iconv.decode(buf.slice(lastI), \"ascii\"); // Write direct chars.\n    } else {\n        var b64str = base64Accum + this.iconv.decode(buf.slice(lastI), \"ascii\").replace(/,/g, '/');\n\n        var canBeDecoded = b64str.length - (b64str.length % 8); // Minimal chunk: 2 quads -> 2x3 bytes -> 3 chars.\n        base64Accum = b64str.slice(canBeDecoded); // The rest will be decoded in future.\n        b64str = b64str.slice(0, canBeDecoded);\n\n        res += this.iconv.decode(Buffer.from(b64str, 'base64'), \"utf16-be\");\n    }\n\n    this.inBase64 = inBase64;\n    this.base64Accum = base64Accum;\n\n    return res;\n}\n\nUtf7IMAPDecoder.prototype.end = function() {\n    var res = \"\";\n    if (this.inBase64 && this.base64Accum.length > 0)\n        res = this.iconv.decode(Buffer.from(this.base64Accum, 'base64'), \"utf16-be\");\n\n    this.inBase64 = false;\n    this.base64Accum = '';\n    return res;\n}\n\n\n","\"use strict\";\n\nvar BOMChar = '\\uFEFF';\n\nexports.PrependBOM = PrependBOMWrapper\nfunction PrependBOMWrapper(encoder, options) {\n    this.encoder = encoder;\n    this.addBOM = true;\n}\n\nPrependBOMWrapper.prototype.write = function(str) {\n    if (this.addBOM) {\n        str = BOMChar + str;\n        this.addBOM = false;\n    }\n\n    return this.encoder.write(str);\n}\n\nPrependBOMWrapper.prototype.end = function() {\n    return this.encoder.end();\n}\n\n\n//------------------------------------------------------------------------------\n\nexports.StripBOM = StripBOMWrapper;\nfunction StripBOMWrapper(decoder, options) {\n    this.decoder = decoder;\n    this.pass = false;\n    this.options = options || {};\n}\n\nStripBOMWrapper.prototype.write = function(buf) {\n    var res = this.decoder.write(buf);\n    if (this.pass || !res)\n        return res;\n\n    if (res[0] === BOMChar) {\n        res = res.slice(1);\n        if (typeof this.options.stripBOM === 'function')\n            this.options.stripBOM();\n    }\n\n    this.pass = true;\n    return res;\n}\n\nStripBOMWrapper.prototype.end = function() {\n    return this.decoder.end();\n}\n\n","\"use strict\";\n\nvar Buffer = require(\"safer-buffer\").Buffer;\n\nvar bomHandling = require(\"./bom-handling\"),\n    iconv = module.exports;\n\n// All codecs and aliases are kept here, keyed by encoding name/alias.\n// They are lazy loaded in `iconv.getCodec` from `encodings/index.js`.\niconv.encodings = null;\n\n// Characters emitted in case of error.\niconv.defaultCharUnicode = '�';\niconv.defaultCharSingleByte = '?';\n\n// Public API.\niconv.encode = function encode(str, encoding, options) {\n    str = \"\" + (str || \"\"); // Ensure string.\n\n    var encoder = iconv.getEncoder(encoding, options);\n\n    var res = encoder.write(str);\n    var trail = encoder.end();\n    \n    return (trail && trail.length > 0) ? Buffer.concat([res, trail]) : res;\n}\n\niconv.decode = function decode(buf, encoding, options) {\n    if (typeof buf === 'string') {\n        if (!iconv.skipDecodeWarning) {\n            console.error('Iconv-lite warning: decode()-ing strings is deprecated. Refer to https://github.com/ashtuchkin/iconv-lite/wiki/Use-Buffers-when-decoding');\n            iconv.skipDecodeWarning = true;\n        }\n\n        buf = Buffer.from(\"\" + (buf || \"\"), \"binary\"); // Ensure buffer.\n    }\n\n    var decoder = iconv.getDecoder(encoding, options);\n\n    var res = decoder.write(buf);\n    var trail = decoder.end();\n\n    return trail ? (res + trail) : res;\n}\n\niconv.encodingExists = function encodingExists(enc) {\n    try {\n        iconv.getCodec(enc);\n        return true;\n    } catch (e) {\n        return false;\n    }\n}\n\n// Legacy aliases to convert functions\niconv.toEncoding = iconv.encode;\niconv.fromEncoding = iconv.decode;\n\n// Search for a codec in iconv.encodings. Cache codec data in iconv._codecDataCache.\niconv._codecDataCache = {};\niconv.getCodec = function getCodec(encoding) {\n    if (!iconv.encodings)\n        iconv.encodings = require(\"../encodings\"); // Lazy load all encoding definitions.\n    \n    // Canonicalize encoding name: strip all non-alphanumeric chars and appended year.\n    var enc = iconv._canonicalizeEncoding(encoding);\n\n    // Traverse iconv.encodings to find actual codec.\n    var codecOptions = {};\n    while (true) {\n        var codec = iconv._codecDataCache[enc];\n        if (codec)\n            return codec;\n\n        var codecDef = iconv.encodings[enc];\n\n        switch (typeof codecDef) {\n            case \"string\": // Direct alias to other encoding.\n                enc = codecDef;\n                break;\n\n            case \"object\": // Alias with options. Can be layered.\n                for (var key in codecDef)\n                    codecOptions[key] = codecDef[key];\n\n                if (!codecOptions.encodingName)\n                    codecOptions.encodingName = enc;\n                \n                enc = codecDef.type;\n                break;\n\n            case \"function\": // Codec itself.\n                if (!codecOptions.encodingName)\n                    codecOptions.encodingName = enc;\n\n                // The codec function must load all tables and return object with .encoder and .decoder methods.\n                // It'll be called only once (for each different options object).\n                codec = new codecDef(codecOptions, iconv);\n\n                iconv._codecDataCache[codecOptions.encodingName] = codec; // Save it to be reused later.\n                return codec;\n\n            default:\n                throw new Error(\"Encoding not recognized: '\" + encoding + \"' (searched as: '\"+enc+\"')\");\n        }\n    }\n}\n\niconv._canonicalizeEncoding = function(encoding) {\n    // Canonicalize encoding name: strip all non-alphanumeric chars and appended year.\n    return (''+encoding).toLowerCase().replace(/:\\d{4}$|[^0-9a-z]/g, \"\");\n}\n\niconv.getEncoder = function getEncoder(encoding, options) {\n    var codec = iconv.getCodec(encoding),\n        encoder = new codec.encoder(options, codec);\n\n    if (codec.bomAware && options && options.addBOM)\n        encoder = new bomHandling.PrependBOM(encoder, options);\n\n    return encoder;\n}\n\niconv.getDecoder = function getDecoder(encoding, options) {\n    var codec = iconv.getCodec(encoding),\n        decoder = new codec.decoder(options, codec);\n\n    if (codec.bomAware && !(options && options.stripBOM === false))\n        decoder = new bomHandling.StripBOM(decoder, options);\n\n    return decoder;\n}\n\n// Streaming API\n// NOTE: Streaming API naturally depends on 'stream' module from Node.js. Unfortunately in browser environments this module can add\n// up to 100Kb to the output bundle. To avoid unnecessary code bloat, we don't enable Streaming API in browser by default.\n// If you would like to enable it explicitly, please add the following code to your app:\n// > iconv.enableStreamingAPI(require('stream'));\niconv.enableStreamingAPI = function enableStreamingAPI(stream_module) {\n    if (iconv.supportsStreams)\n        return;\n\n    // Dependency-inject stream module to create IconvLite stream classes.\n    var streams = require(\"./streams\")(stream_module);\n\n    // Not public API yet, but expose the stream classes.\n    iconv.IconvLiteEncoderStream = streams.IconvLiteEncoderStream;\n    iconv.IconvLiteDecoderStream = streams.IconvLiteDecoderStream;\n\n    // Streaming API.\n    iconv.encodeStream = function encodeStream(encoding, options) {\n        return new iconv.IconvLiteEncoderStream(iconv.getEncoder(encoding, options), options);\n    }\n\n    iconv.decodeStream = function decodeStream(encoding, options) {\n        return new iconv.IconvLiteDecoderStream(iconv.getDecoder(encoding, options), options);\n    }\n\n    iconv.supportsStreams = true;\n}\n\n// Enable Streaming API automatically if 'stream' module is available and non-empty (the majority of environments).\nvar stream_module;\ntry {\n    stream_module = require(\"stream\");\n} catch (e) {}\n\nif (stream_module && stream_module.Transform) {\n    iconv.enableStreamingAPI(stream_module);\n\n} else {\n    // In rare cases where 'stream' module is not available by default, throw a helpful exception.\n    iconv.encodeStream = iconv.decodeStream = function() {\n        throw new Error(\"iconv-lite Streaming API is not enabled. Use iconv.enableStreamingAPI(require('stream')); to enable it.\");\n    };\n}\n\nif (\"Ā\" != \"\\u0100\") {\n    console.error(\"iconv-lite warning: js files use non-utf8 encoding. See https://github.com/ashtuchkin/iconv-lite/wiki/Javascript-source-file-encodings for more info.\");\n}\n","\"use strict\";\n\nvar Buffer = require(\"safer-buffer\").Buffer;\n\n// NOTE: Due to 'stream' module being pretty large (~100Kb, significant in browser environments), \n// we opt to dependency-inject it instead of creating a hard dependency.\nmodule.exports = function(stream_module) {\n    var Transform = stream_module.Transform;\n\n    // == Encoder stream =======================================================\n\n    function IconvLiteEncoderStream(conv, options) {\n        this.conv = conv;\n        options = options || {};\n        options.decodeStrings = false; // We accept only strings, so we don't need to decode them.\n        Transform.call(this, options);\n    }\n\n    IconvLiteEncoderStream.prototype = Object.create(Transform.prototype, {\n        constructor: { value: IconvLiteEncoderStream }\n    });\n\n    IconvLiteEncoderStream.prototype._transform = function(chunk, encoding, done) {\n        if (typeof chunk != 'string')\n            return done(new Error(\"Iconv encoding stream needs strings as its input.\"));\n        try {\n            var res = this.conv.write(chunk);\n            if (res && res.length) this.push(res);\n            done();\n        }\n        catch (e) {\n            done(e);\n        }\n    }\n\n    IconvLiteEncoderStream.prototype._flush = function(done) {\n        try {\n            var res = this.conv.end();\n            if (res && res.length) this.push(res);\n            done();\n        }\n        catch (e) {\n            done(e);\n        }\n    }\n\n    IconvLiteEncoderStream.prototype.collect = function(cb) {\n        var chunks = [];\n        this.on('error', cb);\n        this.on('data', function(chunk) { chunks.push(chunk); });\n        this.on('end', function() {\n            cb(null, Buffer.concat(chunks));\n        });\n        return this;\n    }\n\n\n    // == Decoder stream =======================================================\n\n    function IconvLiteDecoderStream(conv, options) {\n        this.conv = conv;\n        options = options || {};\n        options.encoding = this.encoding = 'utf8'; // We output strings.\n        Transform.call(this, options);\n    }\n\n    IconvLiteDecoderStream.prototype = Object.create(Transform.prototype, {\n        constructor: { value: IconvLiteDecoderStream }\n    });\n\n    IconvLiteDecoderStream.prototype._transform = function(chunk, encoding, done) {\n        if (!Buffer.isBuffer(chunk) && !(chunk instanceof Uint8Array))\n            return done(new Error(\"Iconv decoding stream needs buffers as its input.\"));\n        try {\n            var res = this.conv.write(chunk);\n            if (res && res.length) this.push(res, this.encoding);\n            done();\n        }\n        catch (e) {\n            done(e);\n        }\n    }\n\n    IconvLiteDecoderStream.prototype._flush = function(done) {\n        try {\n            var res = this.conv.end();\n            if (res && res.length) this.push(res, this.encoding);                \n            done();\n        }\n        catch (e) {\n            done(e);\n        }\n    }\n\n    IconvLiteDecoderStream.prototype.collect = function(cb) {\n        var res = '';\n        this.on('error', cb);\n        this.on('data', function(chunk) { res += chunk; });\n        this.on('end', function() {\n            cb(null, res);\n        });\n        return this;\n    }\n\n    return {\n        IconvLiteEncoderStream: IconvLiteEncoderStream,\n        IconvLiteDecoderStream: IconvLiteDecoderStream,\n    };\n};\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\n/*!\n * is-plain-object <https://github.com/jonschlinkert/is-plain-object>\n *\n * Copyright (c) 2014-2017, Jon Schlinkert.\n * Released under the MIT License.\n */\n\nfunction isObject(o) {\n  return Object.prototype.toString.call(o) === '[object Object]';\n}\n\nfunction isPlainObject(o) {\n  var ctor,prot;\n\n  if (isObject(o) === false) return false;\n\n  // If has modified constructor\n  ctor = o.constructor;\n  if (ctor === undefined) return true;\n\n  // If has modified prototype\n  prot = ctor.prototype;\n  if (isObject(prot) === false) return false;\n\n  // If constructor does not have an Object-specific method\n  if (prot.hasOwnProperty('isPrototypeOf') === false) {\n    return false;\n  }\n\n  // Most likely a plain Object\n  return true;\n}\n\nexports.isPlainObject = isPlainObject;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nfunction _interopDefault (ex) { return (ex && (typeof ex === 'object') && 'default' in ex) ? ex['default'] : ex; }\n\nvar Stream = _interopDefault(require('stream'));\nvar http = _interopDefault(require('http'));\nvar Url = _interopDefault(require('url'));\nvar https = _interopDefault(require('https'));\nvar zlib = _interopDefault(require('zlib'));\n\n// Based on https://github.com/tmpvar/jsdom/blob/aa85b2abf07766ff7bf5c1f6daafb3726f2f2db5/lib/jsdom/living/blob.js\n\n// fix for \"Readable\" isn't a named export issue\nconst Readable = Stream.Readable;\n\nconst BUFFER = Symbol('buffer');\nconst TYPE = Symbol('type');\n\nclass Blob {\n\tconstructor() {\n\t\tthis[TYPE] = '';\n\n\t\tconst blobParts = arguments[0];\n\t\tconst options = arguments[1];\n\n\t\tconst buffers = [];\n\t\tlet size = 0;\n\n\t\tif (blobParts) {\n\t\t\tconst a = blobParts;\n\t\t\tconst length = Number(a.length);\n\t\t\tfor (let i = 0; i < length; i++) {\n\t\t\t\tconst element = a[i];\n\t\t\t\tlet buffer;\n\t\t\t\tif (element instanceof Buffer) {\n\t\t\t\t\tbuffer = element;\n\t\t\t\t} else if (ArrayBuffer.isView(element)) {\n\t\t\t\t\tbuffer = Buffer.from(element.buffer, element.byteOffset, element.byteLength);\n\t\t\t\t} else if (element instanceof ArrayBuffer) {\n\t\t\t\t\tbuffer = Buffer.from(element);\n\t\t\t\t} else if (element instanceof Blob) {\n\t\t\t\t\tbuffer = element[BUFFER];\n\t\t\t\t} else {\n\t\t\t\t\tbuffer = Buffer.from(typeof element === 'string' ? element : String(element));\n\t\t\t\t}\n\t\t\t\tsize += buffer.length;\n\t\t\t\tbuffers.push(buffer);\n\t\t\t}\n\t\t}\n\n\t\tthis[BUFFER] = Buffer.concat(buffers);\n\n\t\tlet type = options && options.type !== undefined && String(options.type).toLowerCase();\n\t\tif (type && !/[^\\u0020-\\u007E]/.test(type)) {\n\t\t\tthis[TYPE] = type;\n\t\t}\n\t}\n\tget size() {\n\t\treturn this[BUFFER].length;\n\t}\n\tget type() {\n\t\treturn this[TYPE];\n\t}\n\ttext() {\n\t\treturn Promise.resolve(this[BUFFER].toString());\n\t}\n\tarrayBuffer() {\n\t\tconst buf = this[BUFFER];\n\t\tconst ab = buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.byteLength);\n\t\treturn Promise.resolve(ab);\n\t}\n\tstream() {\n\t\tconst readable = new Readable();\n\t\treadable._read = function () {};\n\t\treadable.push(this[BUFFER]);\n\t\treadable.push(null);\n\t\treturn readable;\n\t}\n\ttoString() {\n\t\treturn '[object Blob]';\n\t}\n\tslice() {\n\t\tconst size = this.size;\n\n\t\tconst start = arguments[0];\n\t\tconst end = arguments[1];\n\t\tlet relativeStart, relativeEnd;\n\t\tif (start === undefined) {\n\t\t\trelativeStart = 0;\n\t\t} else if (start < 0) {\n\t\t\trelativeStart = Math.max(size + start, 0);\n\t\t} else {\n\t\t\trelativeStart = Math.min(start, size);\n\t\t}\n\t\tif (end === undefined) {\n\t\t\trelativeEnd = size;\n\t\t} else if (end < 0) {\n\t\t\trelativeEnd = Math.max(size + end, 0);\n\t\t} else {\n\t\t\trelativeEnd = Math.min(end, size);\n\t\t}\n\t\tconst span = Math.max(relativeEnd - relativeStart, 0);\n\n\t\tconst buffer = this[BUFFER];\n\t\tconst slicedBuffer = buffer.slice(relativeStart, relativeStart + span);\n\t\tconst blob = new Blob([], { type: arguments[2] });\n\t\tblob[BUFFER] = slicedBuffer;\n\t\treturn blob;\n\t}\n}\n\nObject.defineProperties(Blob.prototype, {\n\tsize: { enumerable: true },\n\ttype: { enumerable: true },\n\tslice: { enumerable: true }\n});\n\nObject.defineProperty(Blob.prototype, Symbol.toStringTag, {\n\tvalue: 'Blob',\n\twritable: false,\n\tenumerable: false,\n\tconfigurable: true\n});\n\n/**\n * fetch-error.js\n *\n * FetchError interface for operational errors\n */\n\n/**\n * Create FetchError instance\n *\n * @param   String      message      Error message for human\n * @param   String      type         Error type for machine\n * @param   String      systemError  For Node.js system error\n * @return  FetchError\n */\nfunction FetchError(message, type, systemError) {\n  Error.call(this, message);\n\n  this.message = message;\n  this.type = type;\n\n  // when err.type is `system`, err.code contains system error code\n  if (systemError) {\n    this.code = this.errno = systemError.code;\n  }\n\n  // hide custom error implementation details from end-users\n  Error.captureStackTrace(this, this.constructor);\n}\n\nFetchError.prototype = Object.create(Error.prototype);\nFetchError.prototype.constructor = FetchError;\nFetchError.prototype.name = 'FetchError';\n\nlet convert;\ntry {\n\tconvert = require('encoding').convert;\n} catch (e) {}\n\nconst INTERNALS = Symbol('Body internals');\n\n// fix an issue where \"PassThrough\" isn't a named export for node <10\nconst PassThrough = Stream.PassThrough;\n\n/**\n * Body mixin\n *\n * Ref: https://fetch.spec.whatwg.org/#body\n *\n * @param   Stream  body  Readable stream\n * @param   Object  opts  Response options\n * @return  Void\n */\nfunction Body(body) {\n\tvar _this = this;\n\n\tvar _ref = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {},\n\t    _ref$size = _ref.size;\n\n\tlet size = _ref$size === undefined ? 0 : _ref$size;\n\tvar _ref$timeout = _ref.timeout;\n\tlet timeout = _ref$timeout === undefined ? 0 : _ref$timeout;\n\n\tif (body == null) {\n\t\t// body is undefined or null\n\t\tbody = null;\n\t} else if (isURLSearchParams(body)) {\n\t\t// body is a URLSearchParams\n\t\tbody = Buffer.from(body.toString());\n\t} else if (isBlob(body)) ; else if (Buffer.isBuffer(body)) ; else if (Object.prototype.toString.call(body) === '[object ArrayBuffer]') {\n\t\t// body is ArrayBuffer\n\t\tbody = Buffer.from(body);\n\t} else if (ArrayBuffer.isView(body)) {\n\t\t// body is ArrayBufferView\n\t\tbody = Buffer.from(body.buffer, body.byteOffset, body.byteLength);\n\t} else if (body instanceof Stream) ; else {\n\t\t// none of the above\n\t\t// coerce to string then buffer\n\t\tbody = Buffer.from(String(body));\n\t}\n\tthis[INTERNALS] = {\n\t\tbody,\n\t\tdisturbed: false,\n\t\terror: null\n\t};\n\tthis.size = size;\n\tthis.timeout = timeout;\n\n\tif (body instanceof Stream) {\n\t\tbody.on('error', function (err) {\n\t\t\tconst error = err.name === 'AbortError' ? err : new FetchError(`Invalid response body while trying to fetch ${_this.url}: ${err.message}`, 'system', err);\n\t\t\t_this[INTERNALS].error = error;\n\t\t});\n\t}\n}\n\nBody.prototype = {\n\tget body() {\n\t\treturn this[INTERNALS].body;\n\t},\n\n\tget bodyUsed() {\n\t\treturn this[INTERNALS].disturbed;\n\t},\n\n\t/**\n  * Decode response as ArrayBuffer\n  *\n  * @return  Promise\n  */\n\tarrayBuffer() {\n\t\treturn consumeBody.call(this).then(function (buf) {\n\t\t\treturn buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.byteLength);\n\t\t});\n\t},\n\n\t/**\n  * Return raw response as Blob\n  *\n  * @return Promise\n  */\n\tblob() {\n\t\tlet ct = this.headers && this.headers.get('content-type') || '';\n\t\treturn consumeBody.call(this).then(function (buf) {\n\t\t\treturn Object.assign(\n\t\t\t// Prevent copying\n\t\t\tnew Blob([], {\n\t\t\t\ttype: ct.toLowerCase()\n\t\t\t}), {\n\t\t\t\t[BUFFER]: buf\n\t\t\t});\n\t\t});\n\t},\n\n\t/**\n  * Decode response as json\n  *\n  * @return  Promise\n  */\n\tjson() {\n\t\tvar _this2 = this;\n\n\t\treturn consumeBody.call(this).then(function (buffer) {\n\t\t\ttry {\n\t\t\t\treturn JSON.parse(buffer.toString());\n\t\t\t} catch (err) {\n\t\t\t\treturn Body.Promise.reject(new FetchError(`invalid json response body at ${_this2.url} reason: ${err.message}`, 'invalid-json'));\n\t\t\t}\n\t\t});\n\t},\n\n\t/**\n  * Decode response as text\n  *\n  * @return  Promise\n  */\n\ttext() {\n\t\treturn consumeBody.call(this).then(function (buffer) {\n\t\t\treturn buffer.toString();\n\t\t});\n\t},\n\n\t/**\n  * Decode response as buffer (non-spec api)\n  *\n  * @return  Promise\n  */\n\tbuffer() {\n\t\treturn consumeBody.call(this);\n\t},\n\n\t/**\n  * Decode response as text, while automatically detecting the encoding and\n  * trying to decode to UTF-8 (non-spec api)\n  *\n  * @return  Promise\n  */\n\ttextConverted() {\n\t\tvar _this3 = this;\n\n\t\treturn consumeBody.call(this).then(function (buffer) {\n\t\t\treturn convertBody(buffer, _this3.headers);\n\t\t});\n\t}\n};\n\n// In browsers, all properties are enumerable.\nObject.defineProperties(Body.prototype, {\n\tbody: { enumerable: true },\n\tbodyUsed: { enumerable: true },\n\tarrayBuffer: { enumerable: true },\n\tblob: { enumerable: true },\n\tjson: { enumerable: true },\n\ttext: { enumerable: true }\n});\n\nBody.mixIn = function (proto) {\n\tfor (const name of Object.getOwnPropertyNames(Body.prototype)) {\n\t\t// istanbul ignore else: future proof\n\t\tif (!(name in proto)) {\n\t\t\tconst desc = Object.getOwnPropertyDescriptor(Body.prototype, name);\n\t\t\tObject.defineProperty(proto, name, desc);\n\t\t}\n\t}\n};\n\n/**\n * Consume and convert an entire Body to a Buffer.\n *\n * Ref: https://fetch.spec.whatwg.org/#concept-body-consume-body\n *\n * @return  Promise\n */\nfunction consumeBody() {\n\tvar _this4 = this;\n\n\tif (this[INTERNALS].disturbed) {\n\t\treturn Body.Promise.reject(new TypeError(`body used already for: ${this.url}`));\n\t}\n\n\tthis[INTERNALS].disturbed = true;\n\n\tif (this[INTERNALS].error) {\n\t\treturn Body.Promise.reject(this[INTERNALS].error);\n\t}\n\n\tlet body = this.body;\n\n\t// body is null\n\tif (body === null) {\n\t\treturn Body.Promise.resolve(Buffer.alloc(0));\n\t}\n\n\t// body is blob\n\tif (isBlob(body)) {\n\t\tbody = body.stream();\n\t}\n\n\t// body is buffer\n\tif (Buffer.isBuffer(body)) {\n\t\treturn Body.Promise.resolve(body);\n\t}\n\n\t// istanbul ignore if: should never happen\n\tif (!(body instanceof Stream)) {\n\t\treturn Body.Promise.resolve(Buffer.alloc(0));\n\t}\n\n\t// body is stream\n\t// get ready to actually consume the body\n\tlet accum = [];\n\tlet accumBytes = 0;\n\tlet abort = false;\n\n\treturn new Body.Promise(function (resolve, reject) {\n\t\tlet resTimeout;\n\n\t\t// allow timeout on slow response body\n\t\tif (_this4.timeout) {\n\t\t\tresTimeout = setTimeout(function () {\n\t\t\t\tabort = true;\n\t\t\t\treject(new FetchError(`Response timeout while trying to fetch ${_this4.url} (over ${_this4.timeout}ms)`, 'body-timeout'));\n\t\t\t}, _this4.timeout);\n\t\t}\n\n\t\t// handle stream errors\n\t\tbody.on('error', function (err) {\n\t\t\tif (err.name === 'AbortError') {\n\t\t\t\t// if the request was aborted, reject with this Error\n\t\t\t\tabort = true;\n\t\t\t\treject(err);\n\t\t\t} else {\n\t\t\t\t// other errors, such as incorrect content-encoding\n\t\t\t\treject(new FetchError(`Invalid response body while trying to fetch ${_this4.url}: ${err.message}`, 'system', err));\n\t\t\t}\n\t\t});\n\n\t\tbody.on('data', function (chunk) {\n\t\t\tif (abort || chunk === null) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tif (_this4.size && accumBytes + chunk.length > _this4.size) {\n\t\t\t\tabort = true;\n\t\t\t\treject(new FetchError(`content size at ${_this4.url} over limit: ${_this4.size}`, 'max-size'));\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\taccumBytes += chunk.length;\n\t\t\taccum.push(chunk);\n\t\t});\n\n\t\tbody.on('end', function () {\n\t\t\tif (abort) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tclearTimeout(resTimeout);\n\n\t\t\ttry {\n\t\t\t\tresolve(Buffer.concat(accum, accumBytes));\n\t\t\t} catch (err) {\n\t\t\t\t// handle streams that have accumulated too much data (issue #414)\n\t\t\t\treject(new FetchError(`Could not create Buffer from response body for ${_this4.url}: ${err.message}`, 'system', err));\n\t\t\t}\n\t\t});\n\t});\n}\n\n/**\n * Detect buffer encoding and convert to target encoding\n * ref: http://www.w3.org/TR/2011/WD-html5-20110113/parsing.html#determining-the-character-encoding\n *\n * @param   Buffer  buffer    Incoming buffer\n * @param   String  encoding  Target encoding\n * @return  String\n */\nfunction convertBody(buffer, headers) {\n\tif (typeof convert !== 'function') {\n\t\tthrow new Error('The package `encoding` must be installed to use the textConverted() function');\n\t}\n\n\tconst ct = headers.get('content-type');\n\tlet charset = 'utf-8';\n\tlet res, str;\n\n\t// header\n\tif (ct) {\n\t\tres = /charset=([^;]*)/i.exec(ct);\n\t}\n\n\t// no charset in content type, peek at response body for at most 1024 bytes\n\tstr = buffer.slice(0, 1024).toString();\n\n\t// html5\n\tif (!res && str) {\n\t\tres = /<meta.+?charset=(['\"])(.+?)\\1/i.exec(str);\n\t}\n\n\t// html4\n\tif (!res && str) {\n\t\tres = /<meta[\\s]+?http-equiv=(['\"])content-type\\1[\\s]+?content=(['\"])(.+?)\\2/i.exec(str);\n\t\tif (!res) {\n\t\t\tres = /<meta[\\s]+?content=(['\"])(.+?)\\1[\\s]+?http-equiv=(['\"])content-type\\3/i.exec(str);\n\t\t\tif (res) {\n\t\t\t\tres.pop(); // drop last quote\n\t\t\t}\n\t\t}\n\n\t\tif (res) {\n\t\t\tres = /charset=(.*)/i.exec(res.pop());\n\t\t}\n\t}\n\n\t// xml\n\tif (!res && str) {\n\t\tres = /<\\?xml.+?encoding=(['\"])(.+?)\\1/i.exec(str);\n\t}\n\n\t// found charset\n\tif (res) {\n\t\tcharset = res.pop();\n\n\t\t// prevent decode issues when sites use incorrect encoding\n\t\t// ref: https://hsivonen.fi/encoding-menu/\n\t\tif (charset === 'gb2312' || charset === 'gbk') {\n\t\t\tcharset = 'gb18030';\n\t\t}\n\t}\n\n\t// turn raw buffers into a single utf-8 buffer\n\treturn convert(buffer, 'UTF-8', charset).toString();\n}\n\n/**\n * Detect a URLSearchParams object\n * ref: https://github.com/bitinn/node-fetch/issues/296#issuecomment-307598143\n *\n * @param   Object  obj     Object to detect by type or brand\n * @return  String\n */\nfunction isURLSearchParams(obj) {\n\t// Duck-typing as a necessary condition.\n\tif (typeof obj !== 'object' || typeof obj.append !== 'function' || typeof obj.delete !== 'function' || typeof obj.get !== 'function' || typeof obj.getAll !== 'function' || typeof obj.has !== 'function' || typeof obj.set !== 'function') {\n\t\treturn false;\n\t}\n\n\t// Brand-checking and more duck-typing as optional condition.\n\treturn obj.constructor.name === 'URLSearchParams' || Object.prototype.toString.call(obj) === '[object URLSearchParams]' || typeof obj.sort === 'function';\n}\n\n/**\n * Check if `obj` is a W3C `Blob` object (which `File` inherits from)\n * @param  {*} obj\n * @return {boolean}\n */\nfunction isBlob(obj) {\n\treturn typeof obj === 'object' && typeof obj.arrayBuffer === 'function' && typeof obj.type === 'string' && typeof obj.stream === 'function' && typeof obj.constructor === 'function' && typeof obj.constructor.name === 'string' && /^(Blob|File)$/.test(obj.constructor.name) && /^(Blob|File)$/.test(obj[Symbol.toStringTag]);\n}\n\n/**\n * Clone body given Res/Req instance\n *\n * @param   Mixed  instance  Response or Request instance\n * @return  Mixed\n */\nfunction clone(instance) {\n\tlet p1, p2;\n\tlet body = instance.body;\n\n\t// don't allow cloning a used body\n\tif (instance.bodyUsed) {\n\t\tthrow new Error('cannot clone body after it is used');\n\t}\n\n\t// check that body is a stream and not form-data object\n\t// note: we can't clone the form-data object without having it as a dependency\n\tif (body instanceof Stream && typeof body.getBoundary !== 'function') {\n\t\t// tee instance body\n\t\tp1 = new PassThrough();\n\t\tp2 = new PassThrough();\n\t\tbody.pipe(p1);\n\t\tbody.pipe(p2);\n\t\t// set instance body to teed body and return the other teed body\n\t\tinstance[INTERNALS].body = p1;\n\t\tbody = p2;\n\t}\n\n\treturn body;\n}\n\n/**\n * Performs the operation \"extract a `Content-Type` value from |object|\" as\n * specified in the specification:\n * https://fetch.spec.whatwg.org/#concept-bodyinit-extract\n *\n * This function assumes that instance.body is present.\n *\n * @param   Mixed  instance  Any options.body input\n */\nfunction extractContentType(body) {\n\tif (body === null) {\n\t\t// body is null\n\t\treturn null;\n\t} else if (typeof body === 'string') {\n\t\t// body is string\n\t\treturn 'text/plain;charset=UTF-8';\n\t} else if (isURLSearchParams(body)) {\n\t\t// body is a URLSearchParams\n\t\treturn 'application/x-www-form-urlencoded;charset=UTF-8';\n\t} else if (isBlob(body)) {\n\t\t// body is blob\n\t\treturn body.type || null;\n\t} else if (Buffer.isBuffer(body)) {\n\t\t// body is buffer\n\t\treturn null;\n\t} else if (Object.prototype.toString.call(body) === '[object ArrayBuffer]') {\n\t\t// body is ArrayBuffer\n\t\treturn null;\n\t} else if (ArrayBuffer.isView(body)) {\n\t\t// body is ArrayBufferView\n\t\treturn null;\n\t} else if (typeof body.getBoundary === 'function') {\n\t\t// detect form data input from form-data module\n\t\treturn `multipart/form-data;boundary=${body.getBoundary()}`;\n\t} else if (body instanceof Stream) {\n\t\t// body is stream\n\t\t// can't really do much about this\n\t\treturn null;\n\t} else {\n\t\t// Body constructor defaults other things to string\n\t\treturn 'text/plain;charset=UTF-8';\n\t}\n}\n\n/**\n * The Fetch Standard treats this as if \"total bytes\" is a property on the body.\n * For us, we have to explicitly get it with a function.\n *\n * ref: https://fetch.spec.whatwg.org/#concept-body-total-bytes\n *\n * @param   Body    instance   Instance of Body\n * @return  Number?            Number of bytes, or null if not possible\n */\nfunction getTotalBytes(instance) {\n\tconst body = instance.body;\n\n\n\tif (body === null) {\n\t\t// body is null\n\t\treturn 0;\n\t} else if (isBlob(body)) {\n\t\treturn body.size;\n\t} else if (Buffer.isBuffer(body)) {\n\t\t// body is buffer\n\t\treturn body.length;\n\t} else if (body && typeof body.getLengthSync === 'function') {\n\t\t// detect form data input from form-data module\n\t\tif (body._lengthRetrievers && body._lengthRetrievers.length == 0 || // 1.x\n\t\tbody.hasKnownLength && body.hasKnownLength()) {\n\t\t\t// 2.x\n\t\t\treturn body.getLengthSync();\n\t\t}\n\t\treturn null;\n\t} else {\n\t\t// body is stream\n\t\treturn null;\n\t}\n}\n\n/**\n * Write a Body to a Node.js WritableStream (e.g. http.Request) object.\n *\n * @param   Body    instance   Instance of Body\n * @return  Void\n */\nfunction writeToStream(dest, instance) {\n\tconst body = instance.body;\n\n\n\tif (body === null) {\n\t\t// body is null\n\t\tdest.end();\n\t} else if (isBlob(body)) {\n\t\tbody.stream().pipe(dest);\n\t} else if (Buffer.isBuffer(body)) {\n\t\t// body is buffer\n\t\tdest.write(body);\n\t\tdest.end();\n\t} else {\n\t\t// body is stream\n\t\tbody.pipe(dest);\n\t}\n}\n\n// expose Promise\nBody.Promise = global.Promise;\n\n/**\n * headers.js\n *\n * Headers class offers convenient helpers\n */\n\nconst invalidTokenRegex = /[^\\^_`a-zA-Z\\-0-9!#$%&'*+.|~]/;\nconst invalidHeaderCharRegex = /[^\\t\\x20-\\x7e\\x80-\\xff]/;\n\nfunction validateName(name) {\n\tname = `${name}`;\n\tif (invalidTokenRegex.test(name) || name === '') {\n\t\tthrow new TypeError(`${name} is not a legal HTTP header name`);\n\t}\n}\n\nfunction validateValue(value) {\n\tvalue = `${value}`;\n\tif (invalidHeaderCharRegex.test(value)) {\n\t\tthrow new TypeError(`${value} is not a legal HTTP header value`);\n\t}\n}\n\n/**\n * Find the key in the map object given a header name.\n *\n * Returns undefined if not found.\n *\n * @param   String  name  Header name\n * @return  String|Undefined\n */\nfunction find(map, name) {\n\tname = name.toLowerCase();\n\tfor (const key in map) {\n\t\tif (key.toLowerCase() === name) {\n\t\t\treturn key;\n\t\t}\n\t}\n\treturn undefined;\n}\n\nconst MAP = Symbol('map');\nclass Headers {\n\t/**\n  * Headers class\n  *\n  * @param   Object  headers  Response headers\n  * @return  Void\n  */\n\tconstructor() {\n\t\tlet init = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : undefined;\n\n\t\tthis[MAP] = Object.create(null);\n\n\t\tif (init instanceof Headers) {\n\t\t\tconst rawHeaders = init.raw();\n\t\t\tconst headerNames = Object.keys(rawHeaders);\n\n\t\t\tfor (const headerName of headerNames) {\n\t\t\t\tfor (const value of rawHeaders[headerName]) {\n\t\t\t\t\tthis.append(headerName, value);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn;\n\t\t}\n\n\t\t// We don't worry about converting prop to ByteString here as append()\n\t\t// will handle it.\n\t\tif (init == null) ; else if (typeof init === 'object') {\n\t\t\tconst method = init[Symbol.iterator];\n\t\t\tif (method != null) {\n\t\t\t\tif (typeof method !== 'function') {\n\t\t\t\t\tthrow new TypeError('Header pairs must be iterable');\n\t\t\t\t}\n\n\t\t\t\t// sequence<sequence<ByteString>>\n\t\t\t\t// Note: per spec we have to first exhaust the lists then process them\n\t\t\t\tconst pairs = [];\n\t\t\t\tfor (const pair of init) {\n\t\t\t\t\tif (typeof pair !== 'object' || typeof pair[Symbol.iterator] !== 'function') {\n\t\t\t\t\t\tthrow new TypeError('Each header pair must be iterable');\n\t\t\t\t\t}\n\t\t\t\t\tpairs.push(Array.from(pair));\n\t\t\t\t}\n\n\t\t\t\tfor (const pair of pairs) {\n\t\t\t\t\tif (pair.length !== 2) {\n\t\t\t\t\t\tthrow new TypeError('Each header pair must be a name/value tuple');\n\t\t\t\t\t}\n\t\t\t\t\tthis.append(pair[0], pair[1]);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t// record<ByteString, ByteString>\n\t\t\t\tfor (const key of Object.keys(init)) {\n\t\t\t\t\tconst value = init[key];\n\t\t\t\t\tthis.append(key, value);\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tthrow new TypeError('Provided initializer must be an object');\n\t\t}\n\t}\n\n\t/**\n  * Return combined header value given name\n  *\n  * @param   String  name  Header name\n  * @return  Mixed\n  */\n\tget(name) {\n\t\tname = `${name}`;\n\t\tvalidateName(name);\n\t\tconst key = find(this[MAP], name);\n\t\tif (key === undefined) {\n\t\t\treturn null;\n\t\t}\n\n\t\treturn this[MAP][key].join(', ');\n\t}\n\n\t/**\n  * Iterate over all headers\n  *\n  * @param   Function  callback  Executed for each item with parameters (value, name, thisArg)\n  * @param   Boolean   thisArg   `this` context for callback function\n  * @return  Void\n  */\n\tforEach(callback) {\n\t\tlet thisArg = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : undefined;\n\n\t\tlet pairs = getHeaders(this);\n\t\tlet i = 0;\n\t\twhile (i < pairs.length) {\n\t\t\tvar _pairs$i = pairs[i];\n\t\t\tconst name = _pairs$i[0],\n\t\t\t      value = _pairs$i[1];\n\n\t\t\tcallback.call(thisArg, value, name, this);\n\t\t\tpairs = getHeaders(this);\n\t\t\ti++;\n\t\t}\n\t}\n\n\t/**\n  * Overwrite header values given name\n  *\n  * @param   String  name   Header name\n  * @param   String  value  Header value\n  * @return  Void\n  */\n\tset(name, value) {\n\t\tname = `${name}`;\n\t\tvalue = `${value}`;\n\t\tvalidateName(name);\n\t\tvalidateValue(value);\n\t\tconst key = find(this[MAP], name);\n\t\tthis[MAP][key !== undefined ? key : name] = [value];\n\t}\n\n\t/**\n  * Append a value onto existing header\n  *\n  * @param   String  name   Header name\n  * @param   String  value  Header value\n  * @return  Void\n  */\n\tappend(name, value) {\n\t\tname = `${name}`;\n\t\tvalue = `${value}`;\n\t\tvalidateName(name);\n\t\tvalidateValue(value);\n\t\tconst key = find(this[MAP], name);\n\t\tif (key !== undefined) {\n\t\t\tthis[MAP][key].push(value);\n\t\t} else {\n\t\t\tthis[MAP][name] = [value];\n\t\t}\n\t}\n\n\t/**\n  * Check for header name existence\n  *\n  * @param   String   name  Header name\n  * @return  Boolean\n  */\n\thas(name) {\n\t\tname = `${name}`;\n\t\tvalidateName(name);\n\t\treturn find(this[MAP], name) !== undefined;\n\t}\n\n\t/**\n  * Delete all header values given name\n  *\n  * @param   String  name  Header name\n  * @return  Void\n  */\n\tdelete(name) {\n\t\tname = `${name}`;\n\t\tvalidateName(name);\n\t\tconst key = find(this[MAP], name);\n\t\tif (key !== undefined) {\n\t\t\tdelete this[MAP][key];\n\t\t}\n\t}\n\n\t/**\n  * Return raw headers (non-spec api)\n  *\n  * @return  Object\n  */\n\traw() {\n\t\treturn this[MAP];\n\t}\n\n\t/**\n  * Get an iterator on keys.\n  *\n  * @return  Iterator\n  */\n\tkeys() {\n\t\treturn createHeadersIterator(this, 'key');\n\t}\n\n\t/**\n  * Get an iterator on values.\n  *\n  * @return  Iterator\n  */\n\tvalues() {\n\t\treturn createHeadersIterator(this, 'value');\n\t}\n\n\t/**\n  * Get an iterator on entries.\n  *\n  * This is the default iterator of the Headers object.\n  *\n  * @return  Iterator\n  */\n\t[Symbol.iterator]() {\n\t\treturn createHeadersIterator(this, 'key+value');\n\t}\n}\nHeaders.prototype.entries = Headers.prototype[Symbol.iterator];\n\nObject.defineProperty(Headers.prototype, Symbol.toStringTag, {\n\tvalue: 'Headers',\n\twritable: false,\n\tenumerable: false,\n\tconfigurable: true\n});\n\nObject.defineProperties(Headers.prototype, {\n\tget: { enumerable: true },\n\tforEach: { enumerable: true },\n\tset: { enumerable: true },\n\tappend: { enumerable: true },\n\thas: { enumerable: true },\n\tdelete: { enumerable: true },\n\tkeys: { enumerable: true },\n\tvalues: { enumerable: true },\n\tentries: { enumerable: true }\n});\n\nfunction getHeaders(headers) {\n\tlet kind = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 'key+value';\n\n\tconst keys = Object.keys(headers[MAP]).sort();\n\treturn keys.map(kind === 'key' ? function (k) {\n\t\treturn k.toLowerCase();\n\t} : kind === 'value' ? function (k) {\n\t\treturn headers[MAP][k].join(', ');\n\t} : function (k) {\n\t\treturn [k.toLowerCase(), headers[MAP][k].join(', ')];\n\t});\n}\n\nconst INTERNAL = Symbol('internal');\n\nfunction createHeadersIterator(target, kind) {\n\tconst iterator = Object.create(HeadersIteratorPrototype);\n\titerator[INTERNAL] = {\n\t\ttarget,\n\t\tkind,\n\t\tindex: 0\n\t};\n\treturn iterator;\n}\n\nconst HeadersIteratorPrototype = Object.setPrototypeOf({\n\tnext() {\n\t\t// istanbul ignore if\n\t\tif (!this || Object.getPrototypeOf(this) !== HeadersIteratorPrototype) {\n\t\t\tthrow new TypeError('Value of `this` is not a HeadersIterator');\n\t\t}\n\n\t\tvar _INTERNAL = this[INTERNAL];\n\t\tconst target = _INTERNAL.target,\n\t\t      kind = _INTERNAL.kind,\n\t\t      index = _INTERNAL.index;\n\n\t\tconst values = getHeaders(target, kind);\n\t\tconst len = values.length;\n\t\tif (index >= len) {\n\t\t\treturn {\n\t\t\t\tvalue: undefined,\n\t\t\t\tdone: true\n\t\t\t};\n\t\t}\n\n\t\tthis[INTERNAL].index = index + 1;\n\n\t\treturn {\n\t\t\tvalue: values[index],\n\t\t\tdone: false\n\t\t};\n\t}\n}, Object.getPrototypeOf(Object.getPrototypeOf([][Symbol.iterator]())));\n\nObject.defineProperty(HeadersIteratorPrototype, Symbol.toStringTag, {\n\tvalue: 'HeadersIterator',\n\twritable: false,\n\tenumerable: false,\n\tconfigurable: true\n});\n\n/**\n * Export the Headers object in a form that Node.js can consume.\n *\n * @param   Headers  headers\n * @return  Object\n */\nfunction exportNodeCompatibleHeaders(headers) {\n\tconst obj = Object.assign({ __proto__: null }, headers[MAP]);\n\n\t// http.request() only supports string as Host header. This hack makes\n\t// specifying custom Host header possible.\n\tconst hostHeaderKey = find(headers[MAP], 'Host');\n\tif (hostHeaderKey !== undefined) {\n\t\tobj[hostHeaderKey] = obj[hostHeaderKey][0];\n\t}\n\n\treturn obj;\n}\n\n/**\n * Create a Headers object from an object of headers, ignoring those that do\n * not conform to HTTP grammar productions.\n *\n * @param   Object  obj  Object of headers\n * @return  Headers\n */\nfunction createHeadersLenient(obj) {\n\tconst headers = new Headers();\n\tfor (const name of Object.keys(obj)) {\n\t\tif (invalidTokenRegex.test(name)) {\n\t\t\tcontinue;\n\t\t}\n\t\tif (Array.isArray(obj[name])) {\n\t\t\tfor (const val of obj[name]) {\n\t\t\t\tif (invalidHeaderCharRegex.test(val)) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif (headers[MAP][name] === undefined) {\n\t\t\t\t\theaders[MAP][name] = [val];\n\t\t\t\t} else {\n\t\t\t\t\theaders[MAP][name].push(val);\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (!invalidHeaderCharRegex.test(obj[name])) {\n\t\t\theaders[MAP][name] = [obj[name]];\n\t\t}\n\t}\n\treturn headers;\n}\n\nconst INTERNALS$1 = Symbol('Response internals');\n\n// fix an issue where \"STATUS_CODES\" aren't a named export for node <10\nconst STATUS_CODES = http.STATUS_CODES;\n\n/**\n * Response class\n *\n * @param   Stream  body  Readable stream\n * @param   Object  opts  Response options\n * @return  Void\n */\nclass Response {\n\tconstructor() {\n\t\tlet body = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : null;\n\t\tlet opts = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n\n\t\tBody.call(this, body, opts);\n\n\t\tconst status = opts.status || 200;\n\t\tconst headers = new Headers(opts.headers);\n\n\t\tif (body != null && !headers.has('Content-Type')) {\n\t\t\tconst contentType = extractContentType(body);\n\t\t\tif (contentType) {\n\t\t\t\theaders.append('Content-Type', contentType);\n\t\t\t}\n\t\t}\n\n\t\tthis[INTERNALS$1] = {\n\t\t\turl: opts.url,\n\t\t\tstatus,\n\t\t\tstatusText: opts.statusText || STATUS_CODES[status],\n\t\t\theaders,\n\t\t\tcounter: opts.counter\n\t\t};\n\t}\n\n\tget url() {\n\t\treturn this[INTERNALS$1].url || '';\n\t}\n\n\tget status() {\n\t\treturn this[INTERNALS$1].status;\n\t}\n\n\t/**\n  * Convenience property representing if the request ended normally\n  */\n\tget ok() {\n\t\treturn this[INTERNALS$1].status >= 200 && this[INTERNALS$1].status < 300;\n\t}\n\n\tget redirected() {\n\t\treturn this[INTERNALS$1].counter > 0;\n\t}\n\n\tget statusText() {\n\t\treturn this[INTERNALS$1].statusText;\n\t}\n\n\tget headers() {\n\t\treturn this[INTERNALS$1].headers;\n\t}\n\n\t/**\n  * Clone this response\n  *\n  * @return  Response\n  */\n\tclone() {\n\t\treturn new Response(clone(this), {\n\t\t\turl: this.url,\n\t\t\tstatus: this.status,\n\t\t\tstatusText: this.statusText,\n\t\t\theaders: this.headers,\n\t\t\tok: this.ok,\n\t\t\tredirected: this.redirected\n\t\t});\n\t}\n}\n\nBody.mixIn(Response.prototype);\n\nObject.defineProperties(Response.prototype, {\n\turl: { enumerable: true },\n\tstatus: { enumerable: true },\n\tok: { enumerable: true },\n\tredirected: { enumerable: true },\n\tstatusText: { enumerable: true },\n\theaders: { enumerable: true },\n\tclone: { enumerable: true }\n});\n\nObject.defineProperty(Response.prototype, Symbol.toStringTag, {\n\tvalue: 'Response',\n\twritable: false,\n\tenumerable: false,\n\tconfigurable: true\n});\n\nconst INTERNALS$2 = Symbol('Request internals');\n\n// fix an issue where \"format\", \"parse\" aren't a named export for node <10\nconst parse_url = Url.parse;\nconst format_url = Url.format;\n\nconst streamDestructionSupported = 'destroy' in Stream.Readable.prototype;\n\n/**\n * Check if a value is an instance of Request.\n *\n * @param   Mixed   input\n * @return  Boolean\n */\nfunction isRequest(input) {\n\treturn typeof input === 'object' && typeof input[INTERNALS$2] === 'object';\n}\n\nfunction isAbortSignal(signal) {\n\tconst proto = signal && typeof signal === 'object' && Object.getPrototypeOf(signal);\n\treturn !!(proto && proto.constructor.name === 'AbortSignal');\n}\n\n/**\n * Request class\n *\n * @param   Mixed   input  Url or Request instance\n * @param   Object  init   Custom options\n * @return  Void\n */\nclass Request {\n\tconstructor(input) {\n\t\tlet init = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n\n\t\tlet parsedURL;\n\n\t\t// normalize input\n\t\tif (!isRequest(input)) {\n\t\t\tif (input && input.href) {\n\t\t\t\t// in order to support Node.js' Url objects; though WHATWG's URL objects\n\t\t\t\t// will fall into this branch also (since their `toString()` will return\n\t\t\t\t// `href` property anyway)\n\t\t\t\tparsedURL = parse_url(input.href);\n\t\t\t} else {\n\t\t\t\t// coerce input to a string before attempting to parse\n\t\t\t\tparsedURL = parse_url(`${input}`);\n\t\t\t}\n\t\t\tinput = {};\n\t\t} else {\n\t\t\tparsedURL = parse_url(input.url);\n\t\t}\n\n\t\tlet method = init.method || input.method || 'GET';\n\t\tmethod = method.toUpperCase();\n\n\t\tif ((init.body != null || isRequest(input) && input.body !== null) && (method === 'GET' || method === 'HEAD')) {\n\t\t\tthrow new TypeError('Request with GET/HEAD method cannot have body');\n\t\t}\n\n\t\tlet inputBody = init.body != null ? init.body : isRequest(input) && input.body !== null ? clone(input) : null;\n\n\t\tBody.call(this, inputBody, {\n\t\t\ttimeout: init.timeout || input.timeout || 0,\n\t\t\tsize: init.size || input.size || 0\n\t\t});\n\n\t\tconst headers = new Headers(init.headers || input.headers || {});\n\n\t\tif (inputBody != null && !headers.has('Content-Type')) {\n\t\t\tconst contentType = extractContentType(inputBody);\n\t\t\tif (contentType) {\n\t\t\t\theaders.append('Content-Type', contentType);\n\t\t\t}\n\t\t}\n\n\t\tlet signal = isRequest(input) ? input.signal : null;\n\t\tif ('signal' in init) signal = init.signal;\n\n\t\tif (signal != null && !isAbortSignal(signal)) {\n\t\t\tthrow new TypeError('Expected signal to be an instanceof AbortSignal');\n\t\t}\n\n\t\tthis[INTERNALS$2] = {\n\t\t\tmethod,\n\t\t\tredirect: init.redirect || input.redirect || 'follow',\n\t\t\theaders,\n\t\t\tparsedURL,\n\t\t\tsignal\n\t\t};\n\n\t\t// node-fetch-only options\n\t\tthis.follow = init.follow !== undefined ? init.follow : input.follow !== undefined ? input.follow : 20;\n\t\tthis.compress = init.compress !== undefined ? init.compress : input.compress !== undefined ? input.compress : true;\n\t\tthis.counter = init.counter || input.counter || 0;\n\t\tthis.agent = init.agent || input.agent;\n\t}\n\n\tget method() {\n\t\treturn this[INTERNALS$2].method;\n\t}\n\n\tget url() {\n\t\treturn format_url(this[INTERNALS$2].parsedURL);\n\t}\n\n\tget headers() {\n\t\treturn this[INTERNALS$2].headers;\n\t}\n\n\tget redirect() {\n\t\treturn this[INTERNALS$2].redirect;\n\t}\n\n\tget signal() {\n\t\treturn this[INTERNALS$2].signal;\n\t}\n\n\t/**\n  * Clone this request\n  *\n  * @return  Request\n  */\n\tclone() {\n\t\treturn new Request(this);\n\t}\n}\n\nBody.mixIn(Request.prototype);\n\nObject.defineProperty(Request.prototype, Symbol.toStringTag, {\n\tvalue: 'Request',\n\twritable: false,\n\tenumerable: false,\n\tconfigurable: true\n});\n\nObject.defineProperties(Request.prototype, {\n\tmethod: { enumerable: true },\n\turl: { enumerable: true },\n\theaders: { enumerable: true },\n\tredirect: { enumerable: true },\n\tclone: { enumerable: true },\n\tsignal: { enumerable: true }\n});\n\n/**\n * Convert a Request to Node.js http request options.\n *\n * @param   Request  A Request instance\n * @return  Object   The options object to be passed to http.request\n */\nfunction getNodeRequestOptions(request) {\n\tconst parsedURL = request[INTERNALS$2].parsedURL;\n\tconst headers = new Headers(request[INTERNALS$2].headers);\n\n\t// fetch step 1.3\n\tif (!headers.has('Accept')) {\n\t\theaders.set('Accept', '*/*');\n\t}\n\n\t// Basic fetch\n\tif (!parsedURL.protocol || !parsedURL.hostname) {\n\t\tthrow new TypeError('Only absolute URLs are supported');\n\t}\n\n\tif (!/^https?:$/.test(parsedURL.protocol)) {\n\t\tthrow new TypeError('Only HTTP(S) protocols are supported');\n\t}\n\n\tif (request.signal && request.body instanceof Stream.Readable && !streamDestructionSupported) {\n\t\tthrow new Error('Cancellation of streamed requests with AbortSignal is not supported in node < 8');\n\t}\n\n\t// HTTP-network-or-cache fetch steps 2.4-2.7\n\tlet contentLengthValue = null;\n\tif (request.body == null && /^(POST|PUT)$/i.test(request.method)) {\n\t\tcontentLengthValue = '0';\n\t}\n\tif (request.body != null) {\n\t\tconst totalBytes = getTotalBytes(request);\n\t\tif (typeof totalBytes === 'number') {\n\t\t\tcontentLengthValue = String(totalBytes);\n\t\t}\n\t}\n\tif (contentLengthValue) {\n\t\theaders.set('Content-Length', contentLengthValue);\n\t}\n\n\t// HTTP-network-or-cache fetch step 2.11\n\tif (!headers.has('User-Agent')) {\n\t\theaders.set('User-Agent', 'node-fetch/1.0 (+https://github.com/bitinn/node-fetch)');\n\t}\n\n\t// HTTP-network-or-cache fetch step 2.15\n\tif (request.compress && !headers.has('Accept-Encoding')) {\n\t\theaders.set('Accept-Encoding', 'gzip,deflate');\n\t}\n\n\tlet agent = request.agent;\n\tif (typeof agent === 'function') {\n\t\tagent = agent(parsedURL);\n\t}\n\n\tif (!headers.has('Connection') && !agent) {\n\t\theaders.set('Connection', 'close');\n\t}\n\n\t// HTTP-network fetch step 4.2\n\t// chunked encoding is handled by Node.js\n\n\treturn Object.assign({}, parsedURL, {\n\t\tmethod: request.method,\n\t\theaders: exportNodeCompatibleHeaders(headers),\n\t\tagent\n\t});\n}\n\n/**\n * abort-error.js\n *\n * AbortError interface for cancelled requests\n */\n\n/**\n * Create AbortError instance\n *\n * @param   String      message      Error message for human\n * @return  AbortError\n */\nfunction AbortError(message) {\n  Error.call(this, message);\n\n  this.type = 'aborted';\n  this.message = message;\n\n  // hide custom error implementation details from end-users\n  Error.captureStackTrace(this, this.constructor);\n}\n\nAbortError.prototype = Object.create(Error.prototype);\nAbortError.prototype.constructor = AbortError;\nAbortError.prototype.name = 'AbortError';\n\n// fix an issue where \"PassThrough\", \"resolve\" aren't a named export for node <10\nconst PassThrough$1 = Stream.PassThrough;\nconst resolve_url = Url.resolve;\n\n/**\n * Fetch function\n *\n * @param   Mixed    url   Absolute url or Request instance\n * @param   Object   opts  Fetch options\n * @return  Promise\n */\nfunction fetch(url, opts) {\n\n\t// allow custom promise\n\tif (!fetch.Promise) {\n\t\tthrow new Error('native promise missing, set fetch.Promise to your favorite alternative');\n\t}\n\n\tBody.Promise = fetch.Promise;\n\n\t// wrap http.request into fetch\n\treturn new fetch.Promise(function (resolve, reject) {\n\t\t// build request object\n\t\tconst request = new Request(url, opts);\n\t\tconst options = getNodeRequestOptions(request);\n\n\t\tconst send = (options.protocol === 'https:' ? https : http).request;\n\t\tconst signal = request.signal;\n\n\t\tlet response = null;\n\n\t\tconst abort = function abort() {\n\t\t\tlet error = new AbortError('The user aborted a request.');\n\t\t\treject(error);\n\t\t\tif (request.body && request.body instanceof Stream.Readable) {\n\t\t\t\trequest.body.destroy(error);\n\t\t\t}\n\t\t\tif (!response || !response.body) return;\n\t\t\tresponse.body.emit('error', error);\n\t\t};\n\n\t\tif (signal && signal.aborted) {\n\t\t\tabort();\n\t\t\treturn;\n\t\t}\n\n\t\tconst abortAndFinalize = function abortAndFinalize() {\n\t\t\tabort();\n\t\t\tfinalize();\n\t\t};\n\n\t\t// send request\n\t\tconst req = send(options);\n\t\tlet reqTimeout;\n\n\t\tif (signal) {\n\t\t\tsignal.addEventListener('abort', abortAndFinalize);\n\t\t}\n\n\t\tfunction finalize() {\n\t\t\treq.abort();\n\t\t\tif (signal) signal.removeEventListener('abort', abortAndFinalize);\n\t\t\tclearTimeout(reqTimeout);\n\t\t}\n\n\t\tif (request.timeout) {\n\t\t\treq.once('socket', function (socket) {\n\t\t\t\treqTimeout = setTimeout(function () {\n\t\t\t\t\treject(new FetchError(`network timeout at: ${request.url}`, 'request-timeout'));\n\t\t\t\t\tfinalize();\n\t\t\t\t}, request.timeout);\n\t\t\t});\n\t\t}\n\n\t\treq.on('error', function (err) {\n\t\t\treject(new FetchError(`request to ${request.url} failed, reason: ${err.message}`, 'system', err));\n\t\t\tfinalize();\n\t\t});\n\n\t\treq.on('response', function (res) {\n\t\t\tclearTimeout(reqTimeout);\n\n\t\t\tconst headers = createHeadersLenient(res.headers);\n\n\t\t\t// HTTP fetch step 5\n\t\t\tif (fetch.isRedirect(res.statusCode)) {\n\t\t\t\t// HTTP fetch step 5.2\n\t\t\t\tconst location = headers.get('Location');\n\n\t\t\t\t// HTTP fetch step 5.3\n\t\t\t\tconst locationURL = location === null ? null : resolve_url(request.url, location);\n\n\t\t\t\t// HTTP fetch step 5.5\n\t\t\t\tswitch (request.redirect) {\n\t\t\t\t\tcase 'error':\n\t\t\t\t\t\treject(new FetchError(`uri requested responds with a redirect, redirect mode is set to error: ${request.url}`, 'no-redirect'));\n\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\treturn;\n\t\t\t\t\tcase 'manual':\n\t\t\t\t\t\t// node-fetch-specific step: make manual redirect a bit easier to use by setting the Location header value to the resolved URL.\n\t\t\t\t\t\tif (locationURL !== null) {\n\t\t\t\t\t\t\t// handle corrupted header\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\theaders.set('Location', locationURL);\n\t\t\t\t\t\t\t} catch (err) {\n\t\t\t\t\t\t\t\t// istanbul ignore next: nodejs server prevent invalid response headers, we can't test this through normal request\n\t\t\t\t\t\t\t\treject(err);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase 'follow':\n\t\t\t\t\t\t// HTTP-redirect fetch step 2\n\t\t\t\t\t\tif (locationURL === null) {\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 5\n\t\t\t\t\t\tif (request.counter >= request.follow) {\n\t\t\t\t\t\t\treject(new FetchError(`maximum redirect reached at: ${request.url}`, 'max-redirect'));\n\t\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 6 (counter increment)\n\t\t\t\t\t\t// Create a new Request object.\n\t\t\t\t\t\tconst requestOpts = {\n\t\t\t\t\t\t\theaders: new Headers(request.headers),\n\t\t\t\t\t\t\tfollow: request.follow,\n\t\t\t\t\t\t\tcounter: request.counter + 1,\n\t\t\t\t\t\t\tagent: request.agent,\n\t\t\t\t\t\t\tcompress: request.compress,\n\t\t\t\t\t\t\tmethod: request.method,\n\t\t\t\t\t\t\tbody: request.body,\n\t\t\t\t\t\t\tsignal: request.signal,\n\t\t\t\t\t\t\ttimeout: request.timeout,\n\t\t\t\t\t\t\tsize: request.size\n\t\t\t\t\t\t};\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 9\n\t\t\t\t\t\tif (res.statusCode !== 303 && request.body && getTotalBytes(request) === null) {\n\t\t\t\t\t\t\treject(new FetchError('Cannot follow redirect with body being a readable stream', 'unsupported-redirect'));\n\t\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 11\n\t\t\t\t\t\tif (res.statusCode === 303 || (res.statusCode === 301 || res.statusCode === 302) && request.method === 'POST') {\n\t\t\t\t\t\t\trequestOpts.method = 'GET';\n\t\t\t\t\t\t\trequestOpts.body = undefined;\n\t\t\t\t\t\t\trequestOpts.headers.delete('content-length');\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 15\n\t\t\t\t\t\tresolve(fetch(new Request(locationURL, requestOpts)));\n\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// prepare response\n\t\t\tres.once('end', function () {\n\t\t\t\tif (signal) signal.removeEventListener('abort', abortAndFinalize);\n\t\t\t});\n\t\t\tlet body = res.pipe(new PassThrough$1());\n\n\t\t\tconst response_options = {\n\t\t\t\turl: request.url,\n\t\t\t\tstatus: res.statusCode,\n\t\t\t\tstatusText: res.statusMessage,\n\t\t\t\theaders: headers,\n\t\t\t\tsize: request.size,\n\t\t\t\ttimeout: request.timeout,\n\t\t\t\tcounter: request.counter\n\t\t\t};\n\n\t\t\t// HTTP-network fetch step 12.1.1.3\n\t\t\tconst codings = headers.get('Content-Encoding');\n\n\t\t\t// HTTP-network fetch step 12.1.1.4: handle content codings\n\n\t\t\t// in following scenarios we ignore compression support\n\t\t\t// 1. compression support is disabled\n\t\t\t// 2. HEAD request\n\t\t\t// 3. no Content-Encoding header\n\t\t\t// 4. no content response (204)\n\t\t\t// 5. content not modified response (304)\n\t\t\tif (!request.compress || request.method === 'HEAD' || codings === null || res.statusCode === 204 || res.statusCode === 304) {\n\t\t\t\tresponse = new Response(body, response_options);\n\t\t\t\tresolve(response);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// For Node v6+\n\t\t\t// Be less strict when decoding compressed responses, since sometimes\n\t\t\t// servers send slightly invalid responses that are still accepted\n\t\t\t// by common browsers.\n\t\t\t// Always using Z_SYNC_FLUSH is what cURL does.\n\t\t\tconst zlibOptions = {\n\t\t\t\tflush: zlib.Z_SYNC_FLUSH,\n\t\t\t\tfinishFlush: zlib.Z_SYNC_FLUSH\n\t\t\t};\n\n\t\t\t// for gzip\n\t\t\tif (codings == 'gzip' || codings == 'x-gzip') {\n\t\t\t\tbody = body.pipe(zlib.createGunzip(zlibOptions));\n\t\t\t\tresponse = new Response(body, response_options);\n\t\t\t\tresolve(response);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// for deflate\n\t\t\tif (codings == 'deflate' || codings == 'x-deflate') {\n\t\t\t\t// handle the infamous raw deflate response from old servers\n\t\t\t\t// a hack for old IIS and Apache servers\n\t\t\t\tconst raw = res.pipe(new PassThrough$1());\n\t\t\t\traw.once('data', function (chunk) {\n\t\t\t\t\t// see http://stackoverflow.com/questions/37519828\n\t\t\t\t\tif ((chunk[0] & 0x0F) === 0x08) {\n\t\t\t\t\t\tbody = body.pipe(zlib.createInflate());\n\t\t\t\t\t} else {\n\t\t\t\t\t\tbody = body.pipe(zlib.createInflateRaw());\n\t\t\t\t\t}\n\t\t\t\t\tresponse = new Response(body, response_options);\n\t\t\t\t\tresolve(response);\n\t\t\t\t});\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// for br\n\t\t\tif (codings == 'br' && typeof zlib.createBrotliDecompress === 'function') {\n\t\t\t\tbody = body.pipe(zlib.createBrotliDecompress());\n\t\t\t\tresponse = new Response(body, response_options);\n\t\t\t\tresolve(response);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// otherwise, use response as-is\n\t\t\tresponse = new Response(body, response_options);\n\t\t\tresolve(response);\n\t\t});\n\n\t\twriteToStream(req, request);\n\t});\n}\n/**\n * Redirect code matching\n *\n * @param   Number   code  Status code\n * @return  Boolean\n */\nfetch.isRedirect = function (code) {\n\treturn code === 301 || code === 302 || code === 303 || code === 307 || code === 308;\n};\n\n// expose Promise\nfetch.Promise = global.Promise;\n\nmodule.exports = exports = fetch;\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.default = exports;\nexports.Headers = Headers;\nexports.Request = Request;\nexports.Response = Response;\nexports.FetchError = FetchError;\n","var wrappy = require('wrappy')\nmodule.exports = wrappy(once)\nmodule.exports.strict = wrappy(onceStrict)\n\nonce.proto = once(function () {\n  Object.defineProperty(Function.prototype, 'once', {\n    value: function () {\n      return once(this)\n    },\n    configurable: true\n  })\n\n  Object.defineProperty(Function.prototype, 'onceStrict', {\n    value: function () {\n      return onceStrict(this)\n    },\n    configurable: true\n  })\n})\n\nfunction once (fn) {\n  var f = function () {\n    if (f.called) return f.value\n    f.called = true\n    return f.value = fn.apply(this, arguments)\n  }\n  f.called = false\n  return f\n}\n\nfunction onceStrict (fn) {\n  var f = function () {\n    if (f.called)\n      throw new Error(f.onceError)\n    f.called = true\n    return f.value = fn.apply(this, arguments)\n  }\n  var name = fn.name || 'Function wrapped with `once`'\n  f.onceError = name + \" shouldn't be called more than once\"\n  f.called = false\n  return f\n}\n","/* eslint-disable node/no-deprecated-api */\n\n'use strict'\n\nvar buffer = require('buffer')\nvar Buffer = buffer.Buffer\n\nvar safer = {}\n\nvar key\n\nfor (key in buffer) {\n  if (!buffer.hasOwnProperty(key)) continue\n  if (key === 'SlowBuffer' || key === 'Buffer') continue\n  safer[key] = buffer[key]\n}\n\nvar Safer = safer.Buffer = {}\nfor (key in Buffer) {\n  if (!Buffer.hasOwnProperty(key)) continue\n  if (key === 'allocUnsafe' || key === 'allocUnsafeSlow') continue\n  Safer[key] = Buffer[key]\n}\n\nsafer.Buffer.prototype = Buffer.prototype\n\nif (!Safer.from || Safer.from === Uint8Array.from) {\n  Safer.from = function (value, encodingOrOffset, length) {\n    if (typeof value === 'number') {\n      throw new TypeError('The \"value\" argument must not be of type number. Received type ' + typeof value)\n    }\n    if (value && typeof value.length === 'undefined') {\n      throw new TypeError('The first argument must be one of type string, Buffer, ArrayBuffer, Array, or Array-like Object. Received type ' + typeof value)\n    }\n    return Buffer(value, encodingOrOffset, length)\n  }\n}\n\nif (!Safer.alloc) {\n  Safer.alloc = function (size, fill, encoding) {\n    if (typeof size !== 'number') {\n      throw new TypeError('The \"size\" argument must be of type number. Received type ' + typeof size)\n    }\n    if (size < 0 || size >= 2 * (1 << 30)) {\n      throw new RangeError('The value \"' + size + '\" is invalid for option \"size\"')\n    }\n    var buf = Buffer(size)\n    if (!fill || fill.length === 0) {\n      buf.fill(0)\n    } else if (typeof encoding === 'string') {\n      buf.fill(fill, encoding)\n    } else {\n      buf.fill(fill)\n    }\n    return buf\n  }\n}\n\nif (!safer.kStringMaxLength) {\n  try {\n    safer.kStringMaxLength = process.binding('buffer').kStringMaxLength\n  } catch (e) {\n    // we can't determine kStringMaxLength in environments where process.binding\n    // is unsupported, so let's not set it\n  }\n}\n\nif (!safer.constants) {\n  safer.constants = {\n    MAX_LENGTH: safer.kMaxLength\n  }\n  if (safer.kStringMaxLength) {\n    safer.constants.MAX_STRING_LENGTH = safer.kStringMaxLength\n  }\n}\n\nmodule.exports = safer\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nfunction getUserAgent() {\n  if (typeof navigator === \"object\" && \"userAgent\" in navigator) {\n    return navigator.userAgent;\n  }\n\n  if (typeof process === \"object\" && \"version\" in process) {\n    return `Node.js/${process.version.substr(1)} (${process.platform}; ${process.arch})`;\n  }\n\n  return \"<environment undetectable>\";\n}\n\nexports.getUserAgent = getUserAgent;\n//# sourceMappingURL=index.js.map\n","// Returns a wrapper function that returns a wrapped callback\n// The wrapper function should do some stuff, and return a\n// presumably different callback function.\n// This makes sure that own properties are retained, so that\n// decorations and such are not lost along the way.\nmodule.exports = wrappy\nfunction wrappy (fn, cb) {\n  if (fn && cb) return wrappy(fn)(cb)\n\n  if (typeof fn !== 'function')\n    throw new TypeError('need wrapper function')\n\n  Object.keys(fn).forEach(function (k) {\n    wrapper[k] = fn[k]\n  })\n\n  return wrapper\n\n  function wrapper() {\n    var args = new Array(arguments.length)\n    for (var i = 0; i < args.length; i++) {\n      args[i] = arguments[i]\n    }\n    var ret = fn.apply(this, args)\n    var cb = args[args.length-1]\n    if (typeof ret === 'function' && ret !== cb) {\n      Object.keys(cb).forEach(function (k) {\n        ret[k] = cb[k]\n      })\n    }\n    return ret\n  }\n}\n",null,"module.exports = require(\"buffer\");","module.exports = require(\"crypto\");","module.exports = require(\"fs\");","module.exports = require(\"http\");","module.exports = require(\"https\");","module.exports = require(\"os\");","module.exports = require(\"path\");","module.exports = require(\"stream\");","module.exports = require(\"string_decoder\");","module.exports = require(\"url\");","module.exports = require(\"zlib\");","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tif(__webpack_module_cache__[moduleId]) {\n\t\treturn __webpack_module_cache__[moduleId].exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\tvar threw = true;\n\ttry {\n\t\t__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\t\tthrew = false;\n\t} finally {\n\t\tif(threw) delete __webpack_module_cache__[moduleId];\n\t}\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n","\n__webpack_require__.ab = __dirname + \"/\";","// module exports must be returned from runtime so entry inlining is disabled\n// startup\n// Load entry module and return exports\nreturn __webpack_require__(2932);\n"],"mappings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tSA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC1CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC5BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AClDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AChLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACvYA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACrHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACjJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC1uCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACxDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AC/JA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AC9tBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACtRA;AACA;AACA;AACA;A;;;;;ACHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AClGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AChCA;AACA;AACA;AACA;A;;;;;ACHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AC1KA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACxIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACnCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACrFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACb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hTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACnZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AC1DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AC/CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AC5BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACpFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACtlBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC7LA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACvMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACzEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACncA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACpLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACtMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AChUA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACnSA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACrDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACnLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC9GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;ACvCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AClnDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC3CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;;AC9EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;A;;;;;AClCA;AACA;AACA;A;;;;;;;;A;;;;;;;;A;;;;;;;;A;;;;;;;;A;;;;;;;;A;;;;;;;;A;;;;;;;;A;;;;;;;;A;;;;;;ACFA;AACA;A;;;;;;ACDA;AACA;A;;;;;;ACDA;AACA;A;;;;;;ACDA;AACA;A;;;;;;ACDA;AACA;A;;;;;;ACDA;AACA;A;;;;;;ACDA;AACA;A;;;;;;ACDA;AACA;A;;;;;;ACDA;AACA;A;;;;;;ACDA;AACA;A;;;;;;ACDA;AACA;A;;;;ACDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AC5BA;AACA;ACDA;AACA;AACA;AACA;;A","sourceRoot":""}